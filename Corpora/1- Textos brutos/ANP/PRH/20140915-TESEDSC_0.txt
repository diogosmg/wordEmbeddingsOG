 

 

 

 

 

 

CLASSIFICAÇÃO FUZZY APLICADA A DADOS DE GEOQUÍMICA DE  

SUPERFÍCIE DA BACIA DE SANTOS 

 

 

 

 

 

Jean Romei Heckmann 

 

 

 

 

Tese  de  Doutorado  apresentada  ao  Programa  de 

Pós-graduação em Engenharia Civil, COPPE, da 

Universidade  Federal  do  Rio  de  Janeiro,  como 

parte  dos  requisitos  necessários  à  obtenção  do 

título de Doutor em Engenharia Civil.  

Orientadores: Débora de Almeida Azevedo 

Luiz Landau 

Rio de Janeiro 

Junho de 2013

 

 

 

 

 

CLASSIFICAÇÃO FUZZY APLICADA A DADOS DE GEOQUÍMICA DE 

SUPERFÍCIE DA BACIA DE SANTOS 

 

 

 

Jean Romei Heckmann 

 

 

TESE  SUBMETIDA  AO  CORPO  DOCENTE  DO  INSTITUTO  ALBERTO  LUIZ 

COIMBRA DE PÓS-GRADUAÇÃO E PESQUISA DE ENGENHARIA (COPPE) DA 

UNIVERSIDADE  FEDERAL  DO  RIO  DE  JANEIRO  COMO  PARTE  DOS 

REQUISITOS NECESSÁRIOS PARA A OBTENÇÃO DO GRAU DE DOUTOR EM 

CIÊNCIAS EM ENGENHARIA CIVIL. 

 

 

Examinada por: 

 

 

_____________________________________________ 

Profª. Débora de Almeida Azevedo, D.Sc. 

 

_____________________________________________ 

Prof. Luiz Landau, D.Sc. 

 

_____________________________________________ 

Prof. Alexandre Gonçalves Evsukoff, D.Sc. 

 

_____________________________________________ 

Dr. Eugênio Vaz Santos Neto, Ph.D. 

 

_____________________________________________ 

Dr. Félix Thadeu Teixeira Gonçalves, D.Sc. 

 

 

RIO DE JANEIRO, RJ - BRASIL 

JUNHO DE 2013

 

 

 

 

 

 

 

 

Heckmann, Jean Romei 

Classificação fuzzy aplicada a dados de geoquímica de 

superfície da Bacia de Santos / Jean Romei Heckmann. – 

Rio de Janeiro: UFRJ/COPPE, 2013. 

XIII, 99 p.: il.; 29,7 cm. 

Orientadores:  Débora de Almeida Azevedo  

Luiz Landau. 

Tese  (doutorado)  –  UFRJ/  COPPE/  Programa  de 

Engenharia Civil, 2013. 

 Referências Bibliográficas: p. 95-99. 

1.  Geoquímica  de  Superfície.  2.  Lógica  Fuzzy.  3. 

Anomalias Geoquímicas. I. Azevedo, Débora de Almeida 

et al. II. Universidade Federal do Rio de Janeiro, COPPE, 

Programa de Engenharia Civil. III. Título. 

 

 

 

iii 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Dedico esta tese a três pessoas essenciais na minha vida: 

minha mãe Edla e os meus irmãos Jacques e Doriane. 

iv 

 

 

A Deus, pela vida. 

 

AGRADECIMENTOS 

 

À minha mãe e irmãos pelo apoio incondicional, pela motivação e por me incentivarem 

em momentos de incerteza. 

 

A  Liliane  Pequeno  de  Araújo  pela  compreensão  e  apoio  nos  momentos  mais  difíceis 

para vencer mais esta etapa importante em minha vida. 

 

Ao  Professor  Luiz  Landau  pela  dedicação  em  garantir  um  curso  de  destaque, 

infraestrutura,  qualidade  e  para  cada  pessoa  que  compõe  sua  equipe  no  LAMCE  - 

Laboratório de Métodos Computacionais em Engenharia. 

 
Agradecimento pela orientação à Profa. Débora Azevedo pela incondicional dedicação e 
pelas sinceras e importantes observações. 

 

A ANP/PRH02 pelo apoio financeiro indispensável à realização deste trabalho. 

 

Aos funcionários do LAMCE e da Secretaria de Pós-Graduação da COPPE, em especial 

à Mônica, Sérgio, Jairo e Beth. 

 

À  amiga  Ana  Cristina  Serra  pela  amizade  e  apoio  acadêmico  no  desenvolvimento  da 

tese. 

 

Aos membros da banca, Eugênio Vaz Santos Neto, Félix Thadeu Teixeira Gonçalves e 

Alexandre Gonçalves Evsukoff. 

 

Gostaria  de  agradecer  àquelas  pessoas  que,  de  forma  direta  ou  indireta,  tornaram 

possível com o seu apoio e incentivo a concretização desta tese. 

 

v 

 

Resumo  da  Tese  apresentada  à  COPPE/UFRJ  como  parte  dos  requisitos  necessários 

para a obtenção do grau de Doutor em Ciências (D.Sc.) 

 

CLASSIFICAÇÃO FUZZY APLICADA A DADOS DE GEOQUÍMICA DE 

SUPERFÍCIE DA BACIA DE SANTOS 

 

 

Jean Romei Heckmann 

 

Junho/2013 

 

Orientadores:  Débora de Almeida Azevedo 

Luiz Landau 

 
Programa: Engenharia Civil 

 

Neste estudo, em um primeiro momento foi realizada a avaliação geoestatística 

da  distribuição  de  dados  geoquímicos  de  superfície,  identificação  dos  dados  outliers 

usando-se  vários  métodos  de  interpolação:  determinísticos  e  geoestatísticos.  As 

avaliações  mostraram  que  os  dados  de  hidrocarbonetos  gasosos  não  seguem  em  geral 

uma distribuição normal ou lognormal. Foi realizada também a aplicação de ferramentas 

soft computing, técnicas computacionais para mineração de dados, para a interpretação 

de  dados  geoquímicos  de  superfície  de  bacia  sedimentar  brasileira,  buscando,  de 

maneira geral, avaliar a potencial geração de hidrocarbonetos de subsuperfície. Para o 

desenvolvimento deste, foi escolhida a bacia sedimentar de Santos por possuir mais de 

um  Sistema  Petrolífero  conhecido.  Neste  trabalho  foi  utilizado  um  método  de 

geoprocessamento  fuzzy  (nebuloso)  para  dados  geoquímicos  de  superfície.  Em  um 

primeiro  passo,  os  grupos  de  dados  de  geoquímica  de  superfície  semelhantes,  foram 

calculados  por  uma  análise  de  agrupamento  fuzzy  com  o  algoritmo  FCM.  Os  dados 

geológicos estudados resultaram em três agrupamentos bem resolvidos com os valores 

de  piston  core  com  características  semelhantes.  Os  agrupamentos  Fuzzy  c-Means 

gerados foram utilizados para avaliar as anomalias geoquímicas de superfície da bacia 

de  Santos.  Os  resultados  obtidos  poderão  ser  usados  como  ferramenta  auxiliar  no 

processo de tomada de decisões exploratórias na bacia estudada. 

 

vi 

 

Abstract  of  Thesis  presented  to  COPPE/UFRJ  as  a  partial  fulfillment  of  the 

requirements for the degree of Doctor of Science (D.Sc.) 

 

 

 

 

FUZZY CLASSIFICATION APPLIED TO SURFACE GEOCHEMISTRY DATA OF 

SANTOS BASIN 

 

Jean Romei Heckmann 

Jun/2013 

Advisors:  Débora de Almeida Azevedo 

   Luiz Landau 

 

Department: Civil Engineering 

 

In this study, was carried out a statistical evaluation of the distribution of surface 

geochemical data, identification of outliers, using various methods, and comparison of 

deterministic  and  geostatistical  interpolation  methods.  Statistical  evaluations  showed 

that  data  of  gas  hydrocarbon  do  not  follow,  in  general,  a  lognormal  or  a  normal 

distribution.  Like  was  also  performed,  application  of  soft  computing  tools,  the 

computational 

techniques 

to  data  surveying, 

to 

the 

interpretation  of  surface 

geochemistry  data  in  Brazilian  sedimentary  basin,  seeking  to  evaluate  subsurface 

hydrocarbon  generation and entrapment. To develop this, was chosen the sedimentary 

basin of Santos for having more than one known Petroleum System. In this study was 

used  a  geo-processing  method  for  fuzzy  surface  geochemical  data.  Firstly,  groups  of 

similar data geochemistry were calculated by a fuzzy logic clustering analysis with the 

Fuzzy  c-Means  algorithm.  The  surface  geological  data  resulted  in  three  groups  with 

well  resolved  values  piston  core  with  similar  characteristics.  The  Fuzzy  c-Means 

clusters  generated  were  used  to  evaluate  the  surface  geochemical  anomalies  of  the 

Santos  Basin.  Thus,  the  results  can  be  used  as  auxiliary  tool  in  exploratory  decision 

making in the studied basin. 

 

vii 

 

 

SUMÁRIO 

1 

INTRODUÇÃO .................................................................................................... 

1.1  CONSIDERAÇÕES GERAIS .......................................................................... 

1.2  MOTIVAÇÃO ................................................................................................. 

1.3  OBJETIVO ....................................................................................................... 
2  MATERIAIS E MÉTODOS ............................................................................ 
2.1  DEFINIÇÕES GEOLÓGICAS ......................................................................... 

2.2  BACIA DE SANTOS ....................................................................................... 

2.3  FLUORESCÊNCIA TOTAL ............................................................................. 

2.4  C15 + HIDROCARBONETOS E UCM .............................................................. 
2.5  COMPOSIÇÕES MOLECULARES DE GASES INTERSTICIAIS ................. 

2.6  ANÁLISE ESTATÍSTICA MULTIVARIADA ................................................ 
2.6.1  Análise de componente principal ................................................................... 

3 

INTELIGÊNCIA COMPUTACIONAL .......................................................... 

3.1 

INTRODUÇÃO ............................................................................................... 

3.2  CLASSIFICAÇÃO DOS DADOS ..................................................................... 

3.3  LÓGICA FUZZY ................................................................................................. 

3.4  MÉTODOS DE AGRUPAMENTO FUZZY ...................................................... 

3.5  ALGORITMOS ………………………...……………………………………… 

3.6  FORMULAÇÃO MATEMÁTICA …………………………………………… 
4.  GEOQUÍMICA DE SUPERFÍCIE .................................................................... 

4.1 

INTRODUÇÃO ................................................................................................. 

4.2  OBJETIVOS DA GEOQUÍMICA DE SUPERFÍCIE ........................................ 

4.3  PROSPECÇÃO NA GEOQUÍMICA DE SUPERFÍCIE .................................... 
4.3.1  Etapas do levantamento geoquímico de superfície ...................................... 

4.3.2  Amostragem geoquímica ................................................................................ 

4.3.2.1 

Planejamento ................................................................................................ 

4.3.2.2  Logística ....................................................................................................... 

4.3.2.3 
Ferramentas de coleta ................................................................................... 
4.3.3  Análise geoquímica ......................................................................................... 

4.3.3.1  Cromatografia gasosa .................................................................................. 
4.3.4  Interpretação dos dados de Geoquímica de Superfície ............................... 

 

1 

1 

3 

3 

5 

5 

6 

7 

7 

8 

8 

8 

11 

11 

13 

15 

16 

17 

19 

22 

22 

23 

23 

23 

24 

24 

25 

25 

27 

27 

28 

 

viii 

 

4.4  BENEFÍCIOS DA GEOQUÍMICA DE SUPERFÍCIE ....................................... 

4.5  ANÁLISE GEOESTATÍSTICA ........................................................................ 

4.6  COMPARAÇÃO ENTRE OS MÉTODOS DE INTERPOLAÇÃO .................. 
5  RESULTADOS E DISCUSSÃO ......................................................................... 
5.1  BASE DE DADOS - ANÁLISE EXPLORATÓRIA .......................................... 

5.1.1  Dados originais ……………………………………………………………… 
5.1.2  Dados transformados (ln) …………………………………………………... 

5.1.3  Interpolação por krigagem ordinária, curvatura mínima e inverso do 

quadrado da distância .................................................................................... 

5.1.4  Comparação entre métodos de interpolação ................................................ 

5.2  AVALIAÇÃO DA CLUSTERIZAÇÃO FUZZY C-MEANS (FCMC) ............... 

5.3  CLASSIFICAÇÃO DOS RESULTADOS ......................................................... 
6  CONCLUSÕES .................................................................................................... 
7  RECOMENDAÇÕES .......................................................................................... 
REFERÊNCIAS ........................................................................................................ 

 

 

29 

30 

41 

33 

33 

33 

46 

 
52 

78 

79 

83 

93 

94 

95 

 

ix 

 

 

Figura 1 

Figura 2 

Figura 3 

Figura 4 

Figura 5 

Figura 6 

Figura 7 

Figura 8 

Figura 9 

Figura 10 

LISTA DE FIGURAS 

 

Mapa de localização das amostras piston core da Bacia de Santos ............. 

Representação gráfica em três dimensões do processo de decomposição 
da análise da ACP, apud Wiedemann, 2006 ............................................ 

Etapas do Knowledge Discovery in Databases (KDD), adaptado de HAN 
e KAMBER (2001) ………………………………………………….…… 
Classificação como tarefa de mapear um conjunto de atributos x no seu 
rótulo de classe y ..................................................................................... 
Função trapezoidal de um conjunto fuzzy (crisp) ..................................... 

Técnica do Headspace (MELLO, 2003) ................................................... 

Matriz de correlação dos dados piston core da Bacia de Santos ................ 

Variância  Explicada  -  Componentes  Principais  (n  +1)  versus  X  - 
Variância Percentual ................................................................................. 
Gráfico  de  distribuição  dos  pesos  aos  parâmetros  piston  core  para  a 
Componente Principal 1 versus Componente Principal 2 ........................ 
Histograma de frequência para as variáveis originais .............................. 

Figura 11 

Boxplot para as variáveis originais .......................................................... 

Figura 12 

Gráfico de probabilidade para as variáveis originais .................................. 

Figura 13a  Histograma  de  frequência  para  as  variáveis 

transformadas  (ln): 
Intensidade  da  Fluorescência  (nm),  TSF  R1  (nm),  Etano  (ppm)  e 
Propano (ppm) ....................................................................................... 

Figura 13b  Boxplot  para  as  variáveis 

transformadas 

(ln): 

Intensidade  da 

Fluorescência (nm), TSF R1 (nm), Etano (ppm) e Propano (ppm) ......... 

Figura 13c  Gráfico  de  probabilidade  para  as  variáveis 

transformadas  (ln): 
Intensidade  da  Fluorescência  (nm),  TSF  R1  (nm),  Etano  (ppm)  e 
Propano (ppm) ......................................................................................... 

Figura 14a  Bloco  diagrama  interpolado  para  a  intensidade  da  fluorescência  (nm) 
pelos  métodos:  (a)  krigagem  ordinária,  (b)  curvatura  mínima  e  (c) 
inverso do quadrado da distância ............................................................. 

Figura 14b  Mapas  para  a  intensidade  da  fluorescência  (nm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................. 

Figura 15a  Bloco diagrama interpolado para a emissão máx (nm) pelos métodos: (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância ................................................................................................... 

Figura 15b  Mapas  para  emissão  máx  (nm)  pelos  métodos:  (a)  krigagem  ordinária, 

 

(b) curvatura mínima e (c) inverso do quadrado da distância .................. 

Figura 16a  Bloco  diagrama  interpolado  para  a  excitação  máx  (nm)  pelos  métodos: 
(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado 
da distância .............................................................................................. 

Figura 16b  Mapas para excitação máx (nm) pelos métodos: (a) krigagem ordinária, 
(b) curvatura mínima e (c) inverso do quadrado da distância .................... 
Figura 17a  Bloco  diagrama  interpolado  para  a  TSF  R1  (nm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 

 

 

x 

5 

 
9 

 
12 
 
14 
16 

26 

34 

 
35 
 
36 
40 

42 

44 

 
 
49 
 
50 
 
 
51 
 
 
54 
 
 
55 
 
 
56 

57 
 
 
58 

59 
 
 

 

distância ..................................................................................................... 
Figura 17b  Mapas  para  TSF  R1  (nm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 

curvatura mínima e (c) inverso do quadrado da distância ........................ 

Figura 18a  Bloco  diagrama  interpolado  para  UCM  total  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................. 

Figura 18b  Mapas para UCM total (ppm) pelos métodos: (a) krigagem ordinária, (b) 
curvatura mínima e (c) inverso do quadrado da distância ......................... 
Figura 19a  Bloco diagrama interpolado para alcanos totais (ppb) pelos métodos: (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância ................................................................................................... 

Figura 19b  Mapas para alcanos totais (ppb) pelos métodos: (a) krigagem ordinária, 
(b) curvatura mínima e (c) inverso do quadrado da distância .................... 
Figura 20a  Bloco  diagrama  interpolado  para  metano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................. 

Figura 20b  Mapas  para  metano  (ppm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 
curvatura mínima e (c) inverso do quadrado da distância .......................... 
Figura 21a  Bloco  diagrama  interpolado  para  etano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................... 

 

 

 

 

 

 

Figura 21b  Mapas  para  etano  (ppm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 

 

curvatura mínima e (c) inverso do quadrado da distância ........................ 

Figura 22a  Bloco  diagrama  interpolado  para  propano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................... 

Figura 22b  Mapas  para  propano  (ppm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 
curvatura mínima e (c) inverso do quadrado da distância .......................... 
Figura 23a  Bloco  diagrama  interpolado  para  i-butano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância ..................................................................................................... 
Figura 23b  Mapas  para  i-butano  (ppm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 
curvatura mínima e (c) inverso do quadrado da distância ......................... 
Figura 24a  Bloco  diagrama  interpolado  para  n-butano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................. 

Figura 24b  Mapas  para  n-butano  (ppm)  pelos  métodos:  (a)  krigagem  ordinária,  (b) 
curvatura mínima e (c) inverso do quadrado da distância ......................... 
Figura 25a  Bloco  diagrama  interpolado  para  n-pentano  (ppm)  pelos  métodos:  (a) 
krigagem ordinária, (b)  curvatura mínima e (c) inverso do quadrado da 
distância .................................................................................................. 

Figura 25b  Mapas para n-pentano (ppm) pelos métodos: (a) krigagem ordinária, (b) 
curvatura mínima e (c) inverso do quadrado da distância ......................... 
Figura 26  Mapa  de  Função  de  Pertinência  FCM,  CP1  versus  CP2  (Componente 
Principal  1  versus  Componente  Principal  2),  ilustrando  três  clusters 
formados pelo valores da função de pertinência “m = 1.2” ...................... 
Figura 27  Mapa  de  Função  de  Pertinência  FCM,  CP1  versus  CP2  (Componente 
Principal  1  versus  Componente  Principal  2),  ilustrando  três  clusters 
formados pelo valores da função de pertinência “m = 1.6” ....................... 
Figura 28  Mapa  de  Função  de  Pertinência  FCM,  CP1  versus  CP2  (Componente 

 

 

 

 

60 

61 

 
62 

63 
 
 
64 

65 
 
 
66 

67 
 
 
68 

69 
 
 
70 

71 
 
 
72 

73 
 
 
74 

75 
 
 
76 

77 
 
 
82 
 
 
82 
 

 

xi 

 

 

Principal  1  versus  Componente  Principal  2),  ilustrando  três  clusters 
formados pelo valores da função de pertinência “m = 2.0” ....................... 
Figura 29  Mapa do Cluster 1, longitude versus latitude, ilustrando áreas anômalas 

para o cluster 1 ......................................................................................... 

Figura 30a  Mapa do Cluster 2, longitude versus latitude, ilustrando áreas anômalas 
para o cluster 2 .......................................................................................... 
Figura 30b  Mapa do Cluster 3, longitude versus latitude, ilustrando áreas anômalas 
para o cluster 3 ........................................................................................... 
Figura 31  Mapa  do  Cluster  1,  longitude  versus  latitude,  ilustrando  campos 

identificados em produção para o cluster 1 .............................................. 

Figura 32  Mapa  do  Cluster  2,  longitude  versus  latitude,  ilustrando  campos 

identificados em produção para o cluster 2 .............................................. 

Figura 33  Mapa  do  Cluster  3,  longitude  versus  latitude,  ilustrando  campos 

identificados em produção para o cluster 3 .............................................. 
 

 
83 
 
84 
 
85 
 
86 
 
89 
 
90 
 
91 

 

xii 

 

 

Tabela 1 

Tabela 2 

Tabela 3 

Tabela 4 

Tabela 5 

Tabela 6 

Tabela 7 

Tabela 8 

Tabela 9 

LISTA DE TABELAS 

 

Análise estatística descritiva das amostras com os valores originais (não 
transformados) 
Testes formais de normalidade Kolmogorov-Smirnov (K-S) para os dados 
originais ........................................................................................................  
Análise estatística descritiva das amostras transformadas (ln) ................. 

Testes formais de normalidade Kolmogorov-Smirnov (K-S) para os dados 
transformados ............................................................................................ 
Testes  formais  de  normalidade  Kolmogorov-Smirnov  (K-S)  para  dados 
originais e transformados (ln, log10 e Sqrt) .............................................. 
Resultados  obtidos  para  o  quadrado  médio  do  erro  (QME)  para 
interpoladores usados na distribuição espacial das variáveis .................... 
Determinação  do  número  de  clusters.  Como  pode  ser  visto,  para  alguns 
valores do parâmetro de fuzzificação “m”, o índice de validação indica 3 
clusters para o banco de dados piston core ...............................................  
Valores  piston  core  nos  centros  dos  clusters.  A  interpretação  de  cada 
cluster pode ser realizada pelos centros de suas respectivas coordenadas. 
As  linhas  indicam  os  parâmetros  piston  core  que  foram  utilizados  para 
expressar as avaliações dos clusters pelas suas unidades ............................ 
Número de amostras de cada cluster. Os clusters podem ser agrupados de 
acordo com sua maior participação em cada cluster, em valores absolutos 
e relativos .................................................................................................... 

 
38 
 
39 
47 

 
48 
 
52 
 
79 
 
 
81 
 
 
 
87 
 
 
92 

 

  

 

xiii 

1 

 

1– INTRODUÇÃO 
 

 

1.1 CONSIDERAÇÕES GERAIS 
 

 
A geoquímica orgânica é uma importante ferramenta na exploração petrolífera. 

Ela  visa  principalmente  minimizar  os  riscos  exploratórios,  tornando-se  assim  uma 

importante ferramenta na indústria petrolífera. 

Os  métodos  de  geoquímica  de  superfície  utilizam  dados  de  ocorrências  de 

hidrocarbonetos  como  indícios  para  a  localização  de  acumulações  de  óleo  e  gás.  A 

migração  de  gases  exsudados  a  partir  do  subsolo  para  perto  da  superfície  encontra-se 

bem documentada (SCHUMACHER, 2000; MELLO, 2003. A detecção  e medição de 

gases  de  hidrocarbonetos  migrados  próximos  da  superfície  tornou-se  um  método 

relativamente rotineiro na indústria de exploração do petróleo (ABRAMS; DAHDAH, 

2010; EVSUKOFF et al., 2004). Estes métodos têm sido utilizados por mais de 70 anos, 

principalmente para identificar a presença de possíveis rochas geradoras maturas, para 

delimitar  acumulações  de  petróleo  no  subsolo  e  inferir  qual  o  tipo  mais  provável  de 

hidrocarbonetos (LOGAN et al., 2010). Entende-se a Geoquímica de Superfície  como 

uma série de observações a partir da identificação de vestígios ou mudanças induzidas 

de hidrocarbonetos (DEMBICKI, 2010). 

Na  exploração  geoquímica  de  superfície  pressupõe-se  que  os  hidrocarbonetos 

são  gerados  e  /  ou  armazenados  em  profundidade  e  diferentes  quantidades  de 

exsudações  podem  vir  a  ser  detectáveis,  porém  em  superfície  (EVSUKOFF  et  al., 

2004). As associações de falhas produtivas com anomalias geoquímicas de superfície, 

fairways, tornam a perspectivas específicas bem conhecidas. Assume-se ainda, ou pelo 

menos  implicitamente,  que  a  anomalia  na  superfície  de  hidrocarbonetos  gasosos  pode 

ser  seguramente  relacionada  com  uma  acumulação  em  profundidade  ou  ao  fluxo  de 

acumulações através da rocha sedimentar sendo absorvido pelas partículas do solo. 

Tornam-se  muitas  vezes  complexas  as  relações  entre  geração,  migração  e 

aprisionamento de hidrocarbonetos leves, devido a os mesmos apresentarem alterações 

nas  taxas  de  exsudação,  continuarem  no  espaço  poroso  do  sedimento,  e  também  a 

processos próximos à superfície (ABRAMS; DAHDAH, 2010). 

Em  função  das  constantes  evoluções  tecnológicas  exploracionais,  houve  um 

acréscimo  considerável  no  volume  de  dados  geoquímicos  para  serem  avaliados.  Para 

tanto, a aplicação de inteligência computacional vem a facilitar este processo, no qual se 

 

 

2 

 

faz  muito  relevante.  Desta  maneira,  aumenta  a  confiabilidade  da  avaliação  de  dados 

geoquímicos  de  superfície  minimizando  os  riscos  exploratórios,  a  redução  de  custo 

computacional, entre outros. 

Assim, verifica-se a importância do uso de inteligência computacional, que vem 

a  facilitar  de  maneira  substancial  a  avaliação  dos  dados  deste  trabalho.  Entre  outras 

técnicas  computacionais  destaca-se  a  “Mineração  de  Dados”  (KDD  -  Knowledge 

Discovery  in  Data  Base),  que,  segundo  FAYYAD  et  al.  (1996),  pode  ser  considerada 

como  o  processo  da  descoberta  de  informações  substanciais,  como,  por  exemplo, 

associações,  anomalias  e  estruturas,  de  uma  dada  quantidade  robusta  de  dados 

armazenados  em  banco  de  dados  e  repositórios  de  informação.  Desta  feita,  pelo 

aumento da quantidade de dados geoquímicos de superfície, e pela otimização do tempo 

para  obter  as  informações  e  conhecimentos  úteis  na  avaliação  exploratória,  KDD  é 

aceito como sinônimo de descoberta de conhecimento em banco de dados. 

Para o sucesso da “Extração de Conhecimento de Bases de Dados”, tem como 

objetivo evidenciar qual seria o conhecimento pelo determinado número de conjunto de 

dados para fins de aplicação em um processo decisório. 

Destacam-se em KDD algumas técnicas de mineração de dados, como a lógica 

fuzzy, a classificação bayesiana, a árvore de decisão, as redes neurais, entre outras. 

Assim  sendo,  o  uso  de  ferramentas  computacionais  (soft  computing)  pode  ser 

um  ponto-chave  que  irá  facilitar,  de  forma  substancial,  a  pesquisa  deste  conjunto  de 

dados  (CHERKASSKY;  MULLER,  2007).  Nesta  tese  entre  as  ferramentas  de 

mineração  de  dados  será  aplicada  a  lógica  fuzzy,  devido  à  sua  maior  aplicação  em 

estudos  geoquímicos,  pela  possibilidade  da  generalização  e  interpretação  de  banco  de 

dados robustos. 

Os grupos gerados são mostrados pela descoberta de conhecimento de banco de 

dados.  Primeiramente,  os  clusters  com  valores  geoquímicos  semelhantes  são 

computados  pelo  algoritmo  fuzzy,  sem  considerar  a  localização  das  amostras.  Na 

segunda  etapa,  um  classificador  fuzzy  é  programado  para  fazer  uma  interpretação  do 

grupo  gerado  pela  análise  de  cluster.  As  entradas  amostradas  para  o  classificador  são 

geradas e coordenadas para cobrir todo o domínio e o classificador fuzzy é usado para 

mapear os clusters na rede. 

 

 

 

3 

 

1.2 MOTIVAÇÃO 
 
 

Recentemente se nota que houve um considerável aumento no volume de dados 

para  serem  devidamente  avaliados  na  geoquímica  orgânica  e,  consequentemente,  a 

necessidade do desenvolvimento de novos métodos analíticos. Desta maneira, a grande 

dificuldade para avaliar o imenso volume de dados e solucionar problemas na área de 

exploração  e  produção  requer  a  aplicação  de  tecnologias  computacionais  avançadas 

aliadas  a  métodos  estatísticos  não  convencionais.  Como  exemplo,  destacam-se  alguns 

métodos,  entre  outros:  reconhecimento  de  padrões,  árvores  de  decisão,  redes  neurais, 

lógica fuzzy. 

Os  trabalhos  desenvolvidos  em  Inteligência  Artificial  para  a  Geoquímica 

Orgânica, até o presente, têm sido realizados de forma pontual (ABRAMS; DAHDAH, 

2010;  KLUSMAN,  2002;  LOGAN  et  al.,  2010;  ZUO,  2011).  Estas  pesquisas  são 

baseadas em grandes volumes de dados na área de Geoquímica Orgânica, as quais vêm 

sendo norteadas a partir de uma perspectiva descritiva e preditiva, na qual a estatística é 

a ferramenta de fundamental importância. 

Exemplificando, os resultados obtidos por Rantitsch (2000) são utilizados para 

investigar uma técnica de mapeamento geoquímico que permite tirar conclusões sobre a 

concentração background anômalas. Nele a lógica fuzzy é apresentada por um conjunto 

de regras matemáticas para manipular a probabilidade, por vezes incompatível com as 

leis da probabilidade tradicionais, como são popularmente entendidas. 

Desta  forma,  a  partir  desse  nível  do  conhecimento  tem-se  como  motivação  a 

aplicação da mineração de dados com classificação fuzzy aos dados de geoquímica de 

superfície da Bacia de Santos. 

 

 
1.3 OBJETIVOS 
 
 

Testar  a  premissa  de  que  os  dados  geoquímicos  de  superfície  apresentam  uma 

distribuição  lognormal,  ou  normal,  conforme  descrito  na  literatura  (ABRAMS; 

DAHDAH, 2010; KLUSMAN, 2002; LOGAN et al., 2010; ZUO, 2011). 

Aplicar  a  metodologia  geoestatística  para  avaliar  a  variabilidade  dos  dados 

geoquímicos piston core, as características qualitativas ligadas à estrutura do fenômeno 

natural  que  elas  representam  (localização,  continuidade  espacial,  anisotropia  e  a 

 

 

4 

 

estrutura de correlação  existente) entre valores tomados em dois pontos adjacentes no 

espaço. No caso de dependência superficial, comparar as interpolações pelos métodos: 

krigagem geoestatística, inverso do quadrado da distância e curvatura mínima. 

Demonstrar  a  utilidade  da  aplicação  da  lógica  Fuzzy  c-Means  Clustering 

(FCMC) para classificar dados de parâmetros geoquímicos de superfície piston core da 

Bacia de Santos cedidos pela ANP / BDEP (Agência Nacional do Petróleo, Gás Natural 

e Biocombustíveis / Banco de Dados de Exploração e Produção). 

 

 

 

2 MATERIAIS E MÉTODOS 
 
 
2.1 DEFINIÇÕES GEOLÓGICAS 
 
 
 

Figura 1 - Mapa de localização das amostras piston core da Bacia de Santos 

 

 

5 

 

 

6 

 

O  conjunto  de  dados  de  geoquímica  de  superfície  (piston  core)  da  Bacia  de 

Santos  –obtidos a partir da ANP/BDEP (Agência Nacional do Petróleo, Gás Natural e 

Biocombustíveis / Banco de Dados de Exploração e Produção) – é composto de n = 500 

amostras e dos seguintes parâmetros: Intensidade da Fluorescência (nm), Emissão Máx. 

(nm); Excitação Máx. (nm), TSF R1 (nm), UCM Total (ppm),  Alcanos Totais (ppm), 

Metano  (ppm),  Etano  (ppm),  Propano  (ppm),  i-Butano  (ppm),  n-Butano  (ppm)  e  n-

Pentano (ppm). 

 

 

2.2 BACIA DE SANTOS 
 
 

A  Bacia  de  Santos  está  localizada  na  porção  sudeste  da  margem  continental 

brasileira no litoral sul do Rio de Janeiro, São Paulo, Paraná e norte de Santa Catarina. 
Recobre uma área de aproximadamente 206.000 km2, sendo que 150.300 km2 (73%) se 
encontram em lâmina d’água de até 400 m e 55.700 km2 (27%) entre as cotas de 400 e 
2.000 m (MOREIRA et al., 2007). 

O  desenvolvimento  de  seu  arcabouço  tectono-estatigráfico  compreende  três 

supersequências ou fases principais, (MOREIRA et al., 2007): 

Primeiro estágio (fase rift): compreende os sedimentos do Neocomiano e 

• 
do Barremiano depositados discordantemente sobre rochas vulcânicas básicas de 

idade aproximada de 121 Ma; 
• 
Aptiano  (Andares  Rio  da  Serra-Jiquiá  Inferior)  e  caracteriza-se  pela  deposição 

Segundo  estágio  (fase  transicional):  compreende  os  sedimentos  do 

de evaporitos de ambiente marinho restrito; 
• 
siliciclásticas  e  carbonáticas  do  Eo-Mesoalbiana,  que  posteriormente  foram 

Terceiro  estágio  (fase  drift):  compreende  os  sedimentos  das  seqüências 

recobertas por sistemas transgressivos clástico/carbonáticos do Neo-Albiano ao 

Eo-Cenomiano.  O  subsequente  aprofundamento  da  bacia  (subsidência  térmica) 

resultou  na  implantação  de  um  ambiente  marinho  transgressivo  até  o  Meso-

Turoniano,  seguido  por  fortes  eventos  regressivos  a  partir  do  Maastrichtiano, 

resultando num sensível avanço para offshore da linha de costa. O Terciário na 

bacia  é  representado  pelo  sistema  Iguape/Marambaia,  com  dominância  de 

plataformas  carbonáticas  na  porção  centro-sul  e  forte  influxo  de  clásticos 

 

 

grosseiros na porção norte. A sedimentação culmina com a deposição de areias e 

folhelhos pleistocênicos da Formação Sepetiba. 

7 

 

 

 

2.3 FLUORESCÊNCIA TOTAL 
 
 

A digitalização da fluorescência de sedimentos totais (TSF) é medida a partir da 

amostragem de sedimentos das seções de piston core, congelados e recuperados do mar. 

O sedimento é seco a 40 °C, moído até que tenha sido reduzido a pó, extraído 15 g de 

sedimento  em  pó  (após  adicionados  os  padrões  substitutos  em  cromatografia  gasosa) 

com hexano de alta pureza. É realizada a remoção de enxofre dos extratos com cobre, 

reduzindo  o  volume  do  extrato  para  a  colocação  num  fluorímetro  do  tipo  cuvette.  A 

digitalização da amostra cuvetted é feita com um fluorímetro ao longo de um intervalo 

específico  de  comprimentos  de  excitação  de  onda,  medindo  as  intensidades  de 

fluorescência  resultante  ao  longo  de  um  intervalo  específico  de  comprimentos  de 

emissão  de  onda,  para  após  relatar  a  intensidade  máxima  (TSF  Max  Int)  na  faixa  de 

emissões  relacionadas  com  hidrocarbonetos  e  o  valor  R1  (razão  de  intensidades) 

(ABRAMS; DAHDAH, 2010; LOGAN et al., 2010). 

 

 

2.4 C15 + HIDROCARBONETOS E UCM 
 
 

Os hidrocarbonetos (alcanos) são compostos por 15 ou mais átomos de carbono 

(C15  +),  os  quais  são  determinados  por:  extração  de  volume  reduzido  (100  ml)  para  a 
determinação  de  fluorescência  (diluir  quando  necessário),  acrescentando  padrões 

internos,  injetando  em  uma  coluna  de  cromatografia  gasosa  (GC)  através  de  uma 

entrada  split  com  controle  eletrônico  de  pressão,  com  um  detector  de  ionização  de 

chama (FID), com relatórios de n-alcanos e isoprenoides com concentrações de ng / g 

de  sedimento  seco  e  valores  de  mistura  complexa  sem  solução  (UCM)  de  mg  /  g  de 

sedimento seco. 

 

 

 

 

 

 

8 

 

2.5 COMPOSIÇÕES MOLECULARES DE GASES INTERSTICIAIS 
 
 

A  avaliação  de  gás  intersticial  refere-se  à  determinação  de  gases  leves  de 

hidrocarbonetos,  incluindo  metano,  etano,  propano,  i-butano,  n-butano  e  n-pentano 

intersticiais em sedimentos marinhos. Às vezes, o dióxido de carbono também pode ser 

determinado. Os gases de hidrocarbonetos leves não são muito solúveis em água. Para 

que possam ser extraídas as amostras do sedimento, necessita-se utilizar um gás inerte, 

como  o  nitrogênio,  realizando-se  o  particionamento.  As  amostras  de  sedimento  são 

enlatadas  imediatamente  após  a  recuperação  de  piston  core  para  as  determinações  de 

gás intersticial por cromatografia gasosa (GC), utilizando um detector de ionização de 

chama (FID). 

 

 

2.6 ANÁLISE ESTATÍSTICA MULTIVARIADA 

 
 
A  análise  multivariada  de  dados  permite  obter  informações  a  partir  do  cálculo 

vetorial  de  uma  grande  quantidade  de  dados,  em  que  estes  dados  devem  estar 

organizados  na  forma  de  matriz.  Geralmente  se  colocam  os  registros  nas  linhas  e  as 

variáveis  nas  colunas.  Destaca-se  entre  as  várias  aplicações  da  análise  multivariada  a 

análise  exploratória  de  dados  utilizando  a  técnica  de  Análise  por  Componentes 

Principais (ACP). 

 

 
2.6.1 Análise de componente principal 

 
 
A  análise  de  componente  principal  é  um  tratamento  matemático  da  matriz  de 

dados  com  o  objetivo  de  reduzir  a  dimensionalidade  original  da  mesma  e  está 

fundamentada na correlação entre as variáveis. 

Pode  ser  resumida  como  sendo  uma  transformação  linear  ortogonal  de  um 

espaço  dimensional  com  X  variáveis  medidas  (variáveis  manifestas)  para  um  espaço 

dimensional com novas  k variáveis (variáveis latentes), podendo k ser igual ou menor 

que  x.  Como  resultado  desta  transformação,  as  variáveis  obtidas  são  combinações 

lineares das variáveis originais, independentes, e estão ordenadas em uma sequência que 

vai  daquela  com  maior  explicação  de  variação  dos  dados  (primeira  componente 

 

 

9 

 

principal) para a que tem menor explicação da variação dos dados (última componente 

principal). Isto cria a possibilidade de decomposição da matriz de dados em “estrutura” 

e  “ruído”,  ou,  em  outras  palavras,  em  variáveis  latentes  significativas  e  não 

significativas,  para  a  explicação  da  variação  dos  dados  (MASSART  et  al.,  1997, 

CHRISTENSEN et al., 2005; PASADAKIS et al., 2004). 

O processo da análise por componentes principais se inicia com a organização 

dos dados em uma matriz Z com n objetos e m variáveis, tendo como objetivo separar as 

informações que descrevem a estrutura dos dados daquelas que não descrevem, que são 

classificadas  como  ruídos.  Sendo  assim,  a  matriz  de  dados  é  decomposta  em  dois 

conjuntos.  O  primeiro  contém  as  informações  que  explicam  a  estrutura  formada  por 

duas  matrizes:  matriz  T  ou  matriz  de  escore,  que  são  as  coordenadas  dos  objetos  no 

novo  espaço  dimensional,  e  matriz  P  ou  matriz  de  pesos  que  são  as  projeções  das 

variáveis  manifestas  no  novo  espaço  dimensional.  O  segundo  conjunto  é  a  matriz  E, 

conhecida como matriz de resíduos, que representa a parte da informação que pode ser 

descartada por ser ruído ou simplesmente considerada desnecessária para a análise. 

Este  processo  é  uma  sequência  de  decomposição  dos  dados,  na  qual  as 

componentes  principais  são  determinadas  uma  a  uma,  indo  da  primeira  com  maior 

explicação da variação dos dados, para a última, com a menor explicação da variação 

dos dados. 

Pode  ser  mais  bem  visualizado  por  meio  dos  gráficos  realizados  em  três 

dimensões (3D), que são ilustrados na Figura 2: 

Figura 2 - Representação gráfica em três dimensões do processo  
de decomposição da análise da ACP, apud WIEDEMANN, 2006. 

 

 

 

10 

 

(a) Dados originais; 

(b) É determinada a primeira componente principal - PC1, onde é encontrado o maior 

sentido da variância distribuição dos dados; 

(c) É determinada a segunda componente principal - PC2, onde é encontrado o maior 

sentido da variância da distribuição dos dados em relação a um eixo ortogonal a PC1; 

(d)  É  determinada  a  terceira  componente  principal  -  PC3,  onde  é  encontrado  o  maior 

sentido da variância da distribuição dos dados em relação a um eixo ortogonal a PC1 e 

PC2. 

A grande potencialidade da análise das componentes principais está justificada 

no  fato  de  que,  a  partir  dela,  é  possível  reduzir  a  dimensão  da  matriz  de  dados  pela 

eliminação  das  variáveis  pouco  significativas  (ruído),  identificar  a  existência  de 

combinações  lineares  e  de  correlações  entre  as  variáveis,  selecionar  fatores  mais 

importantes para um determinado efeito, identificar variáveis ocultas ou não explícitas, 

identificar grupos de objetos, e classificar novos objetos. 

 

 

11 

 

3 INTELIGÊNCIA COMPUTACIONAL 

 
 

3.1 INTRODUÇÃO 
 
 

A  partir  da  evolução  da  computação  observou-se  um  grande  aumento  na 

capacitação  e  armazenamento  de  dados.  As  informações  e  conhecimentos  extraídos 

podem ser usados em aplicações de gerenciamento de negócios, controle de produção e 

análises de mercado, na engenharia e exploração da ciência. A tarefa de descoberta do 

conhecimento em bases de dados é definida como um conjunto de processos voltados à 

identificação  de  padrões  válidos,  novos,  potencialmente  úteis  e  compreensíveis  em 

conjunto de dados. 

O  processo  de  descoberta  de  conhecimento  em  bases  de  dados,  ou  Knowledge 

Discovery in Databases (KDD), é o processo de busca e extração de conhecimento em 

grandes  volumes  de  dados  (HAN;  KAMBER,  2001).  KDD  consiste  em  um  processo 

não trivial, que busca gerar conhecimento potencialmente útil para aumentar os ganhos, 

reduzir  os  custos  ou  melhorar  o  desempenho  dos  negócios,  por  meio  da  procura  e  da 

identificação  de  padrões  em  dados  armazenados  em  bases  muitas  vezes  dispersas  e 

inexploradas. 

O  KDD  pode  ser  resumido  em  seis  etapas:  seleção  de  dados,  limpeza, 

enriquecimento, transformação ou codificação, data mining e construção dos relatórios 

de apresentação (HAN; KAMBER, 2001). 

Na primeira etapa, que corresponde à seleção dos dados, os itens específicos são 

selecionados para o processo de descoberta do conhecimento. Geralmente, as bases de 

dados  são  incompletas,  redundantes,  ruidosas  e  esparsas,  necessitando  de  um  pré-

processamento. Nesta fase é realizada a correção das inconsistências encontradas para 

garantir a confiabilidade na avaliação dos dados.  

A  etapa  seguinte,  ou  seja,  o  processo  de  enriquecimento  ou  transformação, 

compreende o passo em que a quantidade de dados é reduzida, agrupando valores em 

outras categorias sumarizadas, adicionando novos dados e agregando-os aos existentes.  

Na etapa de data mining, a busca por conhecimento deve acontecer após todo o 

pré-processamento. Esta etapa visa localizar padrões por meio da aplicação de processos 

de  generalização,  o  que  é  conhecido  como  indução.  Os  objetivos  de  Data  Mining  se 

enquadram nas seguintes classes: predição, identificação, classificação e otimização. A 

predição  são  projeções  feitas  para  identificar  o  comportamento  de  certos  atributos  no 

 

 

 

futuro;  já  a  identificação  corresponde  a  padrões  de  dados  que  possam  identificar  a 

presença  de  um  item,  um  evento  ou  uma  atividade.  A  partição  dos  dados,  na  qual  as 

classes  ou  categorias  podem  ser  identificadas  pela  combinação  de  parâmetros,  é 

12 

chamada de classificação.  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Figura 3 - Etapas do Knowledge Discovery in Databases (KDD), adaptado de HAN  

e KAMBER (2001) 

 

A mineração de dados deve ser realizada, utilizando entre as técnicas disponíveis 

a que melhor se aplica ao tipo de informação a ser encontrada. Não existe uma técnica 

que solucione todos os problemas de mineração de dados. Diferentes métodos servem 

para diferentes propósitos, cada método oferece suas vantagens e desvantagens (HAN; 

KAMBER, 2001).  

As técnicas de mineração de dados são aplicadas em sistemas de descoberta de 

conhecimento em bancos de dados com o objetivo de extrair informações estratégicas 

escondidas em grandes bancos de dados, por meio da pesquisa dessas informações e da 

determinação de padrões, classificações e associações. 

São  inúmeras  as  tarefas  da  mineração  de  dados  apresentadas  na  literatura.  As 

mais comuns são: Regressão, Classificação, Agrupamento (Clustering), Modelagem das 

dependências, Análise das ligações (Associations), Visualização do modelo, Análise de 

dados exploratórios (ADE) e Análise de desvios.  

 

 

 

A seguir será discutida sucintamente a tarefa de classificação por ser de grande 

importância para o desenvolvimento desta tese. 

13 

 

 

3.2 CLASSIFICAÇÃO DOS DADOS 
 
 

A classificação é uma das mais utilizadas técnicas de data mining, simplesmente 

porque é uma das mais realizadas tarefas cognitivas humanas no auxílio à compreensão 

do ambiente onde vivemos. 

A classificação é a tarefa de organizar objetos em uma entre diversas categorias 

pré-definidas, gerando padrões de predição semelhantes à tarefa de regressão, sendo que 

a primeira prediz o valor de um  atributo nominal ou categórico  ao invés de um valor 

real. O atributo alvo da predição é chamado classe. Esta tarefa corresponde ao passo da 

extração de padrões (KECMAN, 2001). 

Diversas 

técnicas  foram  desenvolvidas  para  a  criação  de  modelos  de 

classificação, entre elas: Lógica Fuzzy, Árvores de decisão, k-vizinhos mais próximos, 

Naive Bayes, Support Vector Machine e Redes Neurais Artificiais. Tais técnicas criam 

automaticamente um modelo a partir de um conjunto inicial de registros. Os registros 

devem pertencer a um pequeno grupo de classes pré-definidas. O modelo é composto de 

padrões, essencialmente generalizações em relação aos registros, os quais são utilizados 

para  diferenciar  as  classes.  Uma  vez  obtido  o  modelo,  este  é  usado  pra  classificar 

automaticamente os demais registros (KECMAN, 2001). 

Os  dados  de  entrada  da  tarefa  de  classificação  são  um  conjunto  de  registros. 

Cada registro, também conhecido como uma instância ou exemplo, é caracterizado por 

uma  dupla  (x,y),  onde  x  é  o  conjunto  de  atributos  e  y  o  atributo  especial,  designado 

como  rótulo  da  classe  (também  chamado  de  atributo  alvo  ou  de  categorização). 

Classificação  é  a  tarefa  de  aprender  uma  função  alvo  f  que  mapeie  cada  conjunto  de 

atributos  x  para  um  dos  rótulos  de  classe  pré-determinados.  A  função  alvo  também  é 

conhecida  como  modelo  de  classificação.  Um  modelo  de  classificação  pode  ser 

descritivo ou preditivo. 

A  modelagem  descritiva  serve  como  ferramenta  explicativa  para  se  distinguir 

entre objetos e classes diferentes. Já a modelagem preditiva tem como objetivo prever o 

rótulo  da  classe  de  registros  não  conhecidos.  Conforme  mostrado  na  figura  4,  um 

modelo  de  classificação  pode  ser  tratado  como  uma  “caixa  preta”  que  atribui 

 

 

 

automaticamente  um  rótulo  de  classe  quando  recebe  o  conjunto  de  atributos  de  um 

registro desconhecido. 

14 

 

 

 

 

 

 

 

 

ENTRADA 

 

Conjunto de atributos 

(x) 

Modelo 

de 

Classificação 

SAÍDA 

 

Rótulo de Classe 

(y) 

Figura 4 - Classificação como tarefa de mapear um conjunto de atributos x  

no seu rótulo de classe y. 

A  técnica  de  classificação  é  uma  abordagem  sistemática  para  a  construção  de 

modelos  de  classificação  a  partir  de  um  conjunto  de  dados  de  entrada.  Cada  técnica 

emprega  um  algoritmo  de  aprendizagem  para  identificar  um  modelo  que  seja  mais 

apropriado para o relacionamento entre o conjunto de atributos ao rótulo da classe dos 

dados  de  entrada.  O  modelo  gerado  pelo  algoritmo  de  aprendizagem  deve  se  adaptar 

bem aos dados de entrada e prever corretamente os rótulos das classes de registros com 

que  o  modelo  nunca  tenha  sido  apresentado  antes.  Sendo  assim,  um  dos  principais 

objetivos  do  algoritmo  de  aprendizagem  é  construir  modelos  com  boa  capacidade  de 

generalização (KECMAN, 2001). 

De uma forma geral, para resolver problemas de classificação, primeiro deve-se 

fornecer  um  conjunto  de  treinamento  onde  os  rótulos  dos  registros  sejam  conhecidos. 

Este conjunto de treinamento é usado para construir um modelo de classificação, que é 

subsequentemente aplicado ao conjunto de teste, que consiste de registros com rótulos 

de classes desconhecidos. 

Para avaliar o desempenho de um modelo de classificação, os registros de testes 

previstos corretos e incorretos pelo modelo são contados e tabulados em uma matriz de 

confusão.  Embora  esta  matriz  de  confusão  forneça  as  informações  necessárias  para 

determinar  o  quão  bem  um  modelo  de  classificação  é  executado,  resumir  essas 

informações com um único número tornaria mais conveniente comparar o desempenho 

de diferentes modelos. Isto pode ser feito usando uma métrica de desempenho como a 

precisão, e, de forma equivalente, em termos de sua taxa de erro. A precisão pode ser 

definida  como  a  razão  entre  o  número  de  previsões  corretas  e  o  número  total  de 

 

 

15 

 

previsões,  já  a  taxa  de  erro  é  dada  pela  razão  entre  número  de  previsões  erradas  e  o 

número total de previsões (KECMAN, 2001).  

A maioria dos algoritmos de classificação procura modelos que atinjam a maior 

precisão ou, equivalentemente, a menor taxa de erro quando aplicados ao conjunto de 

testes. 

Muitas  vezes  é  útil  medir  o  desempenho  do  modelo  no  conjunto  de  testes, 

porque  tal  medição  fornece  uma  avaliação  imparcial  do  seu  erro  e  generalização.  A 

precisão ou taxa de erro calculada a partir do conjunto de teste também pode ser usada 

para comparar o desempenho relativo de diferentes classificadores no mesmo domínio. 

Entretanto,  para  fazer  isso,  os  rótulos  de  classe  dos  registros  de  teste  devem  ser 

conhecidos. 

Duas importantes técnicas são bastante utilizadas para estimar a exatidão de um 

modelo. Na primeira, está o método houldout, que se refere a uma técnica simples que 

usa  um  conjunto  de  teste  de  amostras  de  classes.  Estas  amostras  são  selecionadas  ao 

acaso e são independentes das amostras de treinamento. Outra técnica bastante utilizada 

para  estimar  a  exatidão  é  a  validação  cruzada  -  Cross  Validation.  Nesta  técnica  as 

amostras  são  aleatoriamente  divididas  em  k  partições  de  tamanhos  aproximadamente 

iguais. As amostras não presentes em uma dada partição são utilizadas para a geração 

do  modelo  de  classificação.  Este  modelo  é 

testado,  utilizando-se  a  partição 

correspondente. Assim, são gerados k modelos, cada um com sua própria taxa de erro de 

teste a uma dada taxa calculada sobre o conjunto de teste (KECMAN, 2001). 

No  universo  das  técnicas  de  Inteligência  Artificial,  cada  uma  delas  apresenta 

suas  vantagens  e  desvantagens.  Entre  essas,  para  esta  Tese  optou-se  pela  técnica  de 

Lógica Fuzzy, que será discutida com maiores detalhes a seguir. 

 

 
3.3 LÓGICA FUZZY 
 
 

As  técnicas  de  classificação  tradicionais  atribuem  cada  amostra  para  um 

específico ("hard")  cluster, enquanto que em FCMC (Fuzzy  c-Means Clustering) uma 

amostra  pode  pertencer  a  mais  de  um  cluster.  A  probabilidade  de  atribuição  de  uma 
amostra  a  um  cluster  específico  é  descrito  no  FCMC  por  um  valor  de  pertinência  n, 
variando entre 0 a 1. A soma total da participação dos valores de cada amostra é igual a 

1 (RANTITSCH, 2000). 

 

 

16 

 

O algoritmo utilizado neste trabalho é descrito em EVSUKOFF et al. (2004).  

Matlab  (versão  2007)  e  The  Unscramber  (versão  10.1)  foram  usados 

correspondentemente  para  executar  o  algoritmo  de  clusterização  e  análise  de 

componentes principais (ACP), respectivamente. 

Considerando um conjunto fuzzy H pode-se definir, formalmente, uma função de 
pertinência nH : £ → [0,1]. Esta função associa a cada elemento q o grau nH(q), com o 
qual  q pertence  a  H.  A  função de pertinência nH(q) indica o  grau de  compatibilidade 
entre q e o conceito expresso por H. Caso o valor de pertinência nH(q) seja igual a 1, q é 
completamente compatível com A. De modo totalmente inverso, se nH(q) for igual a 0, 
q é completamente incompatível com A. No entanto, se nH(q) estiver entre 0 e 1, q é 
parcialmente  compatível  com  A,  com  grau  nH(q)  (Fig.  5)  (EVSUKOFF  et  al.,  2004; 
KECMAN, 2001). 

 

 

 

 

 
 

Figura 5 - Função trapezoidal de um conjunto fuzzy (crisp) 

 

3.4 MÉTODOS DE AGRUPAMENTO FUZZY 
 

 
A classificação não supervisionada ou análise de agrupamentos é uma atividade 

que  busca  desenvolver  um  modelo  capaz  de  organizar  um  conjunto  de  dados  em 

subconjuntos (clusters) de objetos semelhantes. Para tal, faz-se necessária a construção 

de  um  modelo  de  dados  capaz  de  ser  aplicado  a  dados  não  agrupados,  tendendo  a 

categorizá-los em classes, onde um determinado objeto é examinado e classificado de 

acordo com classes pré-definidas, sendo o grau da associação mais forte entre membros 

do mesmo cluster e fraco entre membros de diferentes clusters. A maioria dos métodos 

de  clusterização  envolve  o  uso  da  distância  entre  os  elementos,  isto  é,  a  medida  da 

similaridade entre todos os pares, normalmente expressa como uma função distância ou 

métrica.  Na  situação  ideal,  deseja-se  que  a  similaridade  entre  os  elementos  de  um 

mesmo  grupo  seja  maximizada  e  que  as  semelhanças  entre  elementos  de  um  grupo  e 

elementos  de  outros  grupos  sejam  minimizadas.  Os  resultados  das  análises  de 

 

 

 

clusterização podem, por exemplo, ser usados para: 

17 

• 
• 
• 
• 

Reconhecer padrões, reduzir modelos e otimizar; 

Ajudar a identificar um esquema de classificação; 

Sugerir um modelo estatístico para descrever um conjunto de dados; 

Indicar  regras  para  atribuir  novos  casos  de  classes  para  identificação, 

escolha de objetivos e diagnósticos; 

Encontrar um caso típico para representar as classes. 

• 
A  análise  de  agrupamentos  pode  ser  baseada,  na  maioria  das  vezes,  de  acordo 

com tais métodos: 

Estatístico; 

Redes Neurais; 

Lógica Fuzzy; 

Algoritmos genéticos. 

• 
• 
• 
• 
 

Cada um desses métodos geralmente trabalha com uma das classes abaixo: 
• 

Divisiva:  todas  as  observações  começam  em  um  único  cluster  e  são 

quebradas em partes; 

Aglomerativa:  todas  as  observações  iniciam  em  clusters  individuais  e, 

posteriormente, são unidos. 

• 

 

 

3.5 ALGORITMOS 

 

Os  algoritmos  de  clusterização  têm  como  principal  característica  apresentar  a 

estruturação  dos  dados  que  não  estejam  bem  definidos,  ou  seja,  pretendem  classificar 

objetos  de  acordo  suas  similaridades,  organizando-os  em  grupos  (clusters),  não 

possuindo  conhecimento  a  priori  sobre  os  mesmos.  Os  métodos  de  agrupamento  são 

classificados de acordo com as características de seus algoritmos em: 

• 

• 

Probabilísticos:  associa  uma  distribuição  de  probabilidade  a  cada 

instância,  onde  cada  distribuição  indica  a  probabilidade  da  instância 

pertencer a cada um dos clusters. Este algoritmo também é chamado EM 

(expectation maximisation); 

Hierárquicos:  agrupa  dados  em  escalas,  criando  uma  árvore  de  grupo. 

 

 

 

18 

Conhecidos  como  algoritmos  aglomerativos,  criam  uma  árvore  que 

representa uma hierarquia de vários níveis, onde os grupos em um nível 

inferior podem ser agrupados como itens de um nível superior; 

• 

Particionais  (k-means):  relaciona  os  dados  a  cada  cluster  (centroide) 

(MCQUEEN,  1967).  A  rotina  deste  algoritmo  é  definida  inicialmente 

com a padronização dos M registros que compõem o conjunto de dados 

(Bx),  seguido  da  definição  do  número  de  clusters  (k  grupos)  e  das 

coordenadas dos centroides (C1, C2, ..., Ck). Em seguida, cada registro é 
agrupado a cada cluster por meio do cálculo da distância do determinado 

registro  entre  cada  centroide.  O  método  encontra  os  centros  (Nx)  de 
forma iterativa através da minimização do critério de erro calculado em 

função de uma métrica de distância (LEE, 1990). O cálculo é finalizado, 

na  maioria  das  vezes,  quando  as  coordenadas  dos  centros  não  variam. 

Este  método  apresenta  pontos  fracos  –  tais  como  fornecimento  a  priori 

do  número  de  clusters  e  inadequação  para  grupos  com  formas  não 

convexas –, por outro lado é simples e eficiente (MCQUEEN, 1967). A 

formulação matemática deste algoritmo tem por objetivo classificar cada 

registro  em  determinado  grupo  e  minimizar  a  soma  quadrada  das 

diferenças  entre  eles.  A  distância  entre  um  ponto  Pi  e  um  conjunto  de 
clusters, dada por  d(Pi,Nx), é definida como sendo a distância do ponto 
ao centro mais próximo dele. 

 

As  métricas  de  distância  podem  medir  certa  proximidade  dos  dados  aos  seus 

possíveis  grupos.  A  escolha  da  melhor  métrica  envolve  certo  conhecimento  da 

aplicação/assunto,  considerando  a  escala  de  medidas  (nominal,  ordinal,  intervalar  e 

proporcional) e a natureza das variáveis (discreta, contínua e binária) (DOMINGUES, 

1982). Considerando um conjunto Bx não vazio e com números reais positivos, pode-se 

caracterizar uma função onde os M registros deste conjunto são descritos em uma matriz 

M x M (métrica em Bx), verificando-se que: 

• 

• 

 

A métrica de distância sobre Bx nas coordenadas a e b da matriz M x M 

são iguais a zero, ou seja, a distância de a a b é igual a zero (onde a é 

igual a b); 

A distância de a a b é igual a distância de b a a; 

 

A distância de a a b é menor ou igual a distância de a a c mais a distância 

de c a b. 

19 

 

• 

 

Existem diversas métricas de distâncias a serem utilizadas, como a Euclidiana, 

Mahalanobis,  Manhatan  ou  Hamming,  Minkowsky,  Gower  e  Gower  (DOMINGUES, 

1982).  Normalmente,  a  métrica  mais  utilizada  é  a  Euclidiana  e,  dependendo  do 

contexto, seguida da Mahalanobis (JAIN; DUBES, 1988). Uma das características mais 

importantes do k-means é a necessidade de fornecer o valor de k antes da execução do 

algoritmo. Regularmente, este valor é arbitrário, ou seja, sem o conhecimento prévio da 

quantidade ótima de  grupos. Há na literatura diferentes índices para validar o número 

ideal  de  clusters  com  o  objetivo  de  encontrar  um  melhor  resultado  nos  algoritmos  de 

agrupamento (MCQUEEN, 1967).  

Índices de validação como PBM, Calinski-Harabasz, Xie-Beni e Partition Index, 

de  maneira  geral,  tentam  avaliar  a  capacidade  intra-cluster  e  a  separação  inter-cluster 

(PAKHIRA et al., 2004).  

O mais utilizado entre eles foi proposto por Pakhira, Bandyopadhyay e Maulik - 

PBM  -  adotando  um  critério  de  maximização  da  separação  entre  dois  grupos, 

contribuindo  para  este  cálculo  a  soma  das  distâncias  até  o  centro  correspondente 

ponderado  pelo  valor  da  função  de  pertinência  e  a  soma  das  distancias  até  o  centro 

correspondente. 

 

 

3.6 FORMULAÇÃO MATEMÁTICA 

 
 
O algoritmo de clusterização k-means rígido, também conhecido como c-Means 

Rígido, é um dos mais populares, mas apresenta máxima rigidez quando relacionado ao 

valor  de  pertinência  {0,  1}  de  um  registro  em  um  agrupamento.  Considerando  a 

sobreposição  entre  grupos  e  utilizando  a  lógica  fuzzy  para  tal,  Bezdek  (KAUFMAN; 

ROUSSEEUW, 1990), propôs uma generalização dos algoritmos k-means, denominado 

Fuzzy  c-Means  -  FCM.  Este  algoritmo  pondera  a  distância  de  um  ponto  ao  centro  do 

agrupamento por um valor de pertinência, sendo possível caracterizar cada ponto sobre 

vários  clusters,  minimizando  a  função  objetivo  (Eq.  1).  O  FCM  tende  a  clusterizar 

diversos  pontos  gerando  partições  quando  necessário.  Esse  processo 

iterativo 

geralmente conduz a um mínimo local. 

 

 

 

onde: 

20 

2)

 

m

)(
t

i

wtxd
i

((

),

(
WmJ

,

 
) ∑ ∑
=
n

=
...1

K

=
...1

t

N

i

Eq. 1 - Função objetivo do FCM 

m = parâmetro de fuzzificação (m > 1); 

tn = vetor com os valores reais não nulos dos centros dos grupos; 
n i= pertinência do elemento ti no grupo i; 
nH(q) = o grau nH associa cada elemento q, com o qual q pertence a H; 

((
iwtxd

),

2)

= distância euclidiana para a amostra x(t) do cluster wi. 

 

Na  função  objetivo  do  FCM  as  pertinências  dos  elementos  aos  grupos  são 

desconhecidas.  Quando  encontradas  (Eq.  2),  formam  uma  matriz  de  partição  com  a 

pertinência de todos os registros a todos os agrupamentos: 

 

n

)(
t

i

=

j

1

(
wtxd
(
i
wtxd

),
),

(
(

j






        
1
,

i

c

1 ,

Nk

 

2
m

(

)1

)
)






∑

=
...1

K

Eq. 2 - Matriz de partição das pertinências 

as linhas representam os valores de pertinência de um elemento a cada 

grupo; 

a soma das linhas da matriz é sempre igual a 1; 

cada elemento deve pertencer a pelo menos um grupo; 

nenhum grupo pode conter todos os registros; 

a  soma  das  colunas  da  matriz  não  poderá  ser  maior  que  quantidade  de 

elementos e menor que zero. 

 

 

onde: 
• 

• 
• 
• 
• 

 

Diferente  do  k-means,  a  função  que  calcula  o  centro  do  grupamento  no  FCM, 

leva em consideração os valores de pertinência (Eq. 3). 

 

 

 

£
£
£
£
-
 

=

t

w
i

n
∑

=
...1

N

i

)(
t
n
∑

i

=
...1

t

N

21 

m

)(
tx

m

)(
t

        
1
,

i

c

 

Eq. 3 - Cálculo dos centroides no FCM 

 

Para  execução  de  um  algoritmo  FCM,  faz-se  necessário  o  recebimento  de  um 

conjunto  de  dados,  o  número  de  agrupamentos  (valor  de  k),  o  parâmetro  responsável 

pela sobreposição dos dados (valor de m > 1), um valor de erro para o critério de parada 

do algoritmo (E > 0) e uma matriz Z. Logo em seguida deve-se atribuir os centroides 

arbitrariamente e repetir do primeiro elemento até o último as rotinas na sequência (até 

que a diferença entre os centroides seja menor que o valor de E): 

• 
• 
• 

calcular os centros (Eq. 3); 

calcular as distâncias dos elementos aos grupos (utilizando uma métrica); 

atualizar a matriz de partição (Eq. 2). 

 

 

£
£
(cid:215)
 

4 GEOQUÍMICA DE SUPERFÍCIE 

 

4.1 INTRODUÇÃO 

 

22 

O  uso  da  geoquímica  de  superfície  na  exploração  de  petróleo  tem  sido 

amplamente  baseado  na  detecção  direta  de  hidrocarbonetos  leves  correspondente  a 

observações diretas de exsudações de óleo e gás, denominadas de macroexsudações ou 

por medidas da reação de produtos de hidrocarbonetos próximos à superfície resultando 

em microexsudações (KLUSMAN, 2002). 

As  pequenas  quantidades  detectadas  por  análises  diretas  de  hidrocarbonetos 

leves  ocorrem  nos  espaços  dos  poros  no  solo  e  são  adsorvidas  nas  porções  dos  grãos 

finos  do  solo,  ou  incorporadas  nos  grãos  deste.  As  observações  de  microexsudações 

próximas  da  superfície  se  utilizam  de  métodos  indiretos  baseadas  em  expressões  de 

moderada a longas faixas (SCHUMACHER, 2000). Tais métodos indiretos ocorrem por 

mudanças 

induzidas  das  microexsudações  para  solo,  sedimento  e  vegetação 

(SCHUMACHER, 2000). 

Desde 1930 os métodos de geoquímica de superfície têm sido usados, mas nas 

últimas décadas o interesse pela geoquímica de exploração se renovou. Esta renovação 

aliada ao desenvolvimento de métodos analíticos e de interpretação tem produzido um 

novo corpo de dados e insight sobre a geoquímica de exploração. 

Levantamentos  geoquímicos  e  estudos  de  pesquisa  documentam  que 

microexsudações de hidrocarbonetos originados a partir de acumulações de óleo e gás 

seguem  alguns  princípios  básicos;  como  são  comuns  e  muito  espalhados,  movem-se 

verticalmente, as acumulações são dinâmicas e os selos imperfeitos. 

Indicações em superfície de exsudações de óleo e gás têm sido observadas por 

milhares  de  anos  e  têm  liderado  a  descoberta  de  importantes  áreas  produtoras  de 

petróleo.  Embora  a  descoberta  de  uma  anomalia  de  geoquímica  de  superfície  não 

assegure  a  descoberta  comercialmente  significativa  de  petróleo,  esta  anomalia 

estabelece  a  presença  de  hidrocarbonetos  na  área  de  interesse.  A  falta  ou  ausência  de 

microexsudações  não  indica  necessariamente  que  a  bacia  é  estéril.  As  exsudações  de 

hidrocarbonetos  em  superfície  podem  representar  o  final  do  caminho  de  migração 

(SCHUMACHER,  2000).  Estas  anomalias  podem  representar  concentrações  de 

hidrocarbonetos  presentes  nos  sedimentos  e  águas,  anomalias  microbiológicas  e 

 

 

 

botânicas,  mudanças  mineralógicas  e  alterações  elétricas,  magnéticas  e  propriedades 

sísmicas próximas à superfície, bem como sedimentos deposicionais (MELLO, 1984). 

23 

 

 

4.2 OBJETIVOS DA GEOQUÍMICA DE SUPERFÍCIE 

 

Os  principais  objetivos  de  um  levantamento  de  geoquímica  de  superfície 

encontrados para a exploração de óleo e gás são (SCHUMACHER, 2000): 

(1) Reconhecer a presença e a tipologia da distribuição de hidrocarbonetos na área 

de interesse de desenvolvimento e de exploração; 

(2)  Determinar  a  provável  carga  de  hidrocarboneto,  somente  inferido  por 

modelagem,  para  especificar  a  exploração  e  a  avaliação  dos  prospectos  na 

atividade de exploração. 

O  objetivo  de  um  levantamento  geoquímico  de  superfície  é  encontrar 

exsudações  e  microexsudações  que  indiquem  a  evidência  direta  de  hidrocarbonetos 

termogênicos, que documentam a presença de um sistema petrolífero ativo e identificam 

as porções da bacia que podem ser mais prospectivas. 

 

 

4.3 PROSPECÇÃO NA GEOQUÍMICA DE SUPERFÍCIE 

 

A  prospecção  na  geoquímica  de  superfície  de  uma  determinada  área  a  ser 

identificada, pode ocorrer em bacias terrestres (bacias onshore) ou em bacias marítimas 

(bacias  offshore).  Nas  bacias  onshore,  as  amostras  de  gases  leves  são  comumente 

detectadas em headspace de solos em áreas ambientais. Já nas offshore, as amostras são 

coletadas por meio de piston core no assoalho marinho (PETERS et al., 2002). 

 

 
4.3.1 Etapas do levantamento geoquímico de superfície 

 

Na  seleção  de  uma  área  prospectável  há  certas  questões  importantes  a  serem 

consideradas. Entre elas, se existe uma área fonte rica em matéria orgânica, se a rocha 

fonte  teria  atingido  uma  temperatura  suficiente  para  gerar  grandes  volumes  de 

hidrocarbonetos (MELLO, 2003), e, por último, conhecer os caminhos de migração dos 

 

 

 

hidrocarbonetos  que  levem  a  uma  trapa.  São  as  seguintes  as  etapas  básicas  de  um 

24 

levantamento geoquímico: 

 

1. Seleção da área a ser estudada 

Esta  etapa  corresponde  a  uma  avaliação  regional  inicial,  que  compreende 

estudos geológicos, geofísicos e sensoriamento remotos. 

 

2. Estudos preliminares 

Neste momento realizam-se avaliações de tendências e prospectos regionais. 

 

3. Seleção do melhor programa geoquímico 

Nesta etapa devem ser aplicadas técnicas de amostragem de campo, e programas 

laboratoriais. 

 

4. Programação de amostragem 

Corresponde à avaliação do programa de amostragem onshore e/ou offshore. 

 

 
4.3.2 Amostragem geoquímica 

 
 
A amostragem geoquímica compreende algumas fases consideradas importantes 

para  a  realização  de  boas  inspeções,  tais  como  o  planejamento,  a  logística  e  as 

ferramentas de coleta (MELLO, 2003). Segue-se o detalhamento destas fases. 

 

 

4.3.2.1 Planejamento 

 

A  fase  de  planejamento  inclui  a  discussão  da  área  a  ser  analisada,  a  malha  de 

amostragem e a escolha de pontos, bem como os tipos de levantamentos. A discussão da 

área corresponde a levantar dados, discutir com o cliente sobre a geologia, a geofísica, 

as estruturas em subsuperfície, a quantidade de amostras, a logística (custos) e definir 

parâmetros  cartográficos  da  área  a  ser  levantada,  tais  como:  datum,  projeção  e  mc 

(meridiano central). A determinação da malha de amostragem e a escolha dos pontos é 

geralmente recomendada para estudos exploratórios, malhas de 500 m, e a distribuição 

 

 

 

de pontos deve ocorrer de forma mais regular possível, com estes pontos direcionados 

em cima de falhamentos e estruturas mapeadas.  Os tipos de levantamentos devem ser 

em carta topográfica ou sísmica (MELLO, 2003). 

25 

 

 

4.3.2.2 Logística 

 
 

Durante  a  fase  de  logística  são  realizados  os  levantamentos  das  necessidades, 

como  materiais  de  escritório,  de  campo  e  os  equipamentos  de  segurança.  Deve  ser 

escolhida uma cidade para servir como área base do levantamento. O controle de custos 

também  é  importante  por  levantar  e  controlar  as  despesas  com  mão  de  obra, 

hospedagem,  aluguel  de  carro,  combustíveis,  alimentação  e  outras.  E,  por  último,  a 

formação de uma equipe de campo (geólogo, técnico ou operador) e a localização dos 

pontos do levantamento são também consideradas necessárias para a realização de um 

bom levantamento geoquímico (MELLO, 2003). 

 
 

4.3.2.3 Ferramentas de coleta 

 

As ferramentas de coleta compreendem tipos de amostragens que podem ser por 

gases 

livres 

(headspace  e  probe),  hidrocarbonetos  oclusos 

(blender)  e/ou 

hidrocarbonetos  adsorvidos  (adsorvidos).  Os  gases  livres  são  altamente  móveis  e 

encontrados em espaços intersticiais ou poros, enquanto os gases sorvidos (adsorvidos 

ou absorvidos) apresentam mobilidade restrita (MELLO, 2003). 

Alguns  tipos  de  ocorrências  e  maneiras  de  amostragem  de  gás  no  solo  e 

exsudações na água são descritos a seguir. 

•  Gases Livres: 
Headspace  (solo):  comumente  empregado  para  análises  de  amostras  que  são 

repassadas  para  recipientes  em  latas.  As  amostras  são  oriundas  de  perfurações  e/ou 

sedimentos rasos. Nesta técnica um volume controlado de sedimento é inserido na lata 

com um volume de salmoura. A lata é então selada e um volume de salmoura medido é 

substituído  pelo  nitrogênio  para  criar  um  volume  de  headspace  conhecido.  Após  o 

equilíbrio  ser  atingido,  a  concentração  de  gases  livres  pode  então  ser  medida  com 

injeção de uma seringa de uma amostra headspace dentro de um cromatógrafo de gás 

 

 

 

equipado com um detector de ionização de chama. A figura seguinte (MELLO, 2003) 

mostra a técnica do Headspace e sua metodologia. 

26 

 

 

Figura 6 - Técnica do Headspace (MELLO, 2003) 

 

Probe: corresponde a uma leitura direta de gases livres e comumente empregada 

em análises que devem ser conduzidas sobre fluidos de perfuração ou amostras de rocha 

recuperada a partir de uma escavação ou furo no solo. Estas escavações profundas quase 

sempre  se  encontram  com  água,  o  que  pode  influenciar  a  coleção  de  gases  livres, 

forçando a análise do conteúdo de algum tipo de gás na água reciclada ou no sistema 

lama no qual é usado para perfurar o buraco. 

Para  tal,  um  pequeno  tubo  concêntrico  selado  é  assentado  no  solo  a  algumas 

profundidades. Com um auxílio de uma seringa usada para evacuar os gases residuais a 

partir do probe antes da amostra de gás no solo ser coletada, a amostra de gás no solo é 

coletada em vidros de 125 ml e evacuada.  

 

Blender  (intersticiais):  empregada  em  análises  em  que  se  utiliza  um  agregador 

de partículas. Os hidrocarbonetos são moídos e desagregados em um liquidificador, em 

seguida, realiza-se por meio de uma seringa, a amostragem que corresponde à injeção 

dos hidrocarbonetos no cromatógrafo e em seguida no interior do blender. 

 
•  Gases Adsorvidos: 
A análise deste gás ou extração ácida captura gases adsorvidos em sedimentos 

finos, seja em inclusões no interior de carbonatos autigênicos ou por águas estruturadas. 

O  gás permanece protegido no interior da estrutura da água e por isso:  1- não  realiza 

trocas com gases livres nos espaços intersticiais; 2- é protegido de ataques microbianos; 

 

 

27 

 

e 3- migra verticalmente segundo handshake migration. A adsorção aumenta quando o 

grânulo adsorvente diminui (aumento da área superficial); pode ser física ou química: 

 

1. Física ou de  Wan  der  Waal: ocorre por energia de adsorção baixa e ligação 

frouxa da substância adsorvida ao adsorvente. 

2.  Química:  ocorre  por  energia  de  adsorção  elevada  e  ligação  firme  da 

substância adsorvida. Pode envolver um cátion ou ânion estranho. 

 

 
4.3.3 Análise geoquímica 

 

 

A análise geoquímica pode ser dividida em duas fases importantes: 

(1)  A  Quantificação  dos  hidrocarbonetos  presentes  (Screening  Analysis),  que 

pode ser realizada em todas as amostras por meio da análise de Cromatografia gasosa, 

Fluorescência Quantitativa e Cromatograma a Gás (Whole Extract-GC). 

(2) A caracterização dos hidrocarbonetos encontrados (Detailed Analysis), que é 

realizada  pelas  análises  de  Biomarcadores  (GM-MS),  Diamantoides  e  Isótopos  de 

Carbono. Esta última será realizada em amostras com alta concentração de gases (acima 

de 500ppm), pela espectrometria de massa com a finalidade de determinar a origem dos 

hidrocarbonetos (MELLO, 2003). 

Nesta  tese  será  descrito  apenas  o  método  de  quantificação  de  cromatografia  a 

gás por ter sido este o único método de análise geoquímica utilizado. 

 

 

4.3.3.1Cromatografia gasosa 

 

Corresponde à análise geoquímica para quantificação dos hidrocarbonetos leves 

(C1  a  C5),  em  que  a  mistura  gasosa  deverá  ser  retirada  dos  recipientes  oriundos  do 
campo  e  injetada  em  cromatógrafos  de  alta  resolução  capazes  de  determinar  e 

quantificar as concentrações em ppm de metano, etano, propano, i-butano, n-butano e n-

pentano. 

 

 

28 

 

O  cromatógrafo  deve  ser  equipado  por  uma  coluna  capilar  e  um  detector  de 

ionização de chama1 (FID ou DIC). 

O  princípio  básico  do  cromatógrafo  ocorre  por  separação  das  misturas  e  por 

interação diferencial dos seus componentes entre uma fase estacionária - FE (líquido ou 
sólido) e uma fase móvel - FM (líquido ou gás).  

Para  que  se  dê  a  separação  destes  constituintes  das  misturas,  estes  devem  ser 
voláteis  ou  evaporáveis,  termicamente  estáveis  e  com  ponto  de  ebulição  até  300oC. 
Assim, as amostras coletadas devem ser injetadas em um vaporizador em uma coluna 

cromatográfica gerando um sinal quando da passagem de substâncias que não o gás de 

arraste. 

A calibração do cromatógrafo deve ser diária, utilizando-se uma mistura gasosa 

contendo  concentrações  conhecidas;  o  cálculo  destas  concentrações  e  a  transferência 

dos  valores  para  o  formato  digital  deverão  ser  automatizados  evitando  assim  erros  de 

transcrição. Os erros analíticos devem ser inferiores a 15%. 

 

 
4.3.4 Interpretação dos dados de Geoquímica de Superfície 

 

Os  dados  de  geoquímica  de  superfície  muitas  vezes  podem  apresentar  ruídos 

(noisy)  (KLUSMAN,  2002).  Isto  tem  constituído  um  grande  problema  para  o  uso  das 

técnicas de geoquímica de superfície, além de ter gerado uma grande responsabilidade 

para  os  analistas  no  que  se  refere  à  interpretação  dos  resultados  de  muitas  inspeções 

geoquímicas. 

A característica da vida de uma população natural determinada em um solo ou 

sedimento irá incluir todos os possíveis membros de uma área de interesse. A população 

amostrada ou amostra estatística engloba amostras individuais ou medidas realizadas no 

campo.  A  população  amostrada  será  então  muito  menor  que  a  população  total, 

requerendo que essa população amostrada deva ser representativa da população total. 

Essa  representatividade  pode  ser  obtida  por  uma  faixa  amostrada,  mas  o  grid 

(malha) amostrado é mais comumente usado em avaliações de lugares específicos que 

devem enfatizar uma área de interesse. 

                                                 
1 Definido como um tipo de detector onde os íons são gerados durante a queima dos eluentes em  uma 
chama de H2 + ar (MELLO, 2003). 
 

 

 

29 

 

O número de amostras ou medidas requeridas depende também dos objetivos de 

um levantamento de geoquímica de superfície, importantes ao longo de um processo de 

planejamento.  Durante  o  reconhecimento  de  um  objetivo  de  uma  avaliação  da 

geoquímica de superfície, em que se deseja determinar se uma bacia é prospectiva ou 

não, poucas amostras são requeridas na identificação dos prospectos. 

A  separação  de  amostras  com  anomalias  de  amostras  background2  é  uma  das 
partes mais críticas dos levantamentos de geoquímica de superfície (KLUSMAN, 2002; 

SCHUMACHER, 2000; SCHUMACHER, 2011 ; SCHUMACHER & CLAVAREAU, 

2011;  SCHUMACHER  &  CLAVAREAU,  2012).  Não  existe  uma  proporção  de 

amostras  com  anomalias  a  ser  distinguida  a  partir  de  amostras  background.  A  prática 

comum  de  considerar  amostras  maiores  que  uma  média  ou  dois  desvios  padrão  como 

anomalias existenciais não tem base científica. Este limiar ou fronteira entre anomalias 

e background deve ser determinado objetivamente usando os dados disponíveis. Em um 

reconhecimento  de  um  levantamento  ou  na  determinação  da  prospectividade  de  uma 

fronteira de uma bacia, muito poucas amostras ou medidas devem ser anomalias. 

 

 

4.4 BENEFÍCIOS DA GEOQUÍMICA DE SUPERFÍCIE 

 

Indicações em superfície de exsudações de óleo e gás são conhecidas há muitos 

anos  como  exsudações  que  têm  liderado  a  descoberta  de  várias  importantes  áreas 

produtoras  de  petróleo  (SCHUMACHER,  2000).  Apesar  de  a  descoberta  de  uma 

superfície  com  anomalias  geoquímicas  não  garantir  uma  descoberta  significativa  de 

petróleo,  isto  estabelece  a  presença  de  hidrocarbonetos  na  área  de  interesse.  As 

exsudações  de  hidrocarbonetos  leves  em  superfície  representam  o  caminho  final  da 

migração.  Trapas  e  estruturas  ao  longo  deste  caminho  devem  ser  considerados 

significativamente  mais  prospectivos  do  que  aqueles  associados  às  anomalias;  assim, 

podem ser apontados como importantes benefícios potenciais para o completo êxito na 

busca  desta  detecção  de  hidrocarbonetos  leves  em  superfície  e,  também,  para  a 

minimização do risco exploratório.  

 

                                                 
2 A amostra background não é um único valor; isto é uma faixa de valores, particularmente para cobrir 
uma ampla área de inspeções ou ter contraste no solo, condições geológicas e ambientais. 

 

 

 

4.5 ANÁLISE GEOESTATÍSTICA 

 

30 

Na geoestatística, a  análise do semivariograma é uma etapa importante,  pois o 

modelo  de  semivariograma  escolhido  é  a  interpretação  da  estrutura  de  correlação 

espacial a ser utilizada nos procedimentos inferenciais da krigagem. A análise completa 

do semivariograma compreende os seguintes passos:  

• 

Levantamento  do  semivariograma  experimental:  o  cálculo  do  valor  do 

semivariograma em cada distância é realizado utilizando os dados amostrais da variável 

regionalizada 

  na  equação  abaixo,  que  é  o  estimador  do  semivariograma.  O 

semivariograma  experimental,  quando  apresenta  dependência  espacial,  é  uma  curva 

irregular  com  flutuações  que  crescem  com  os  valores  de  h.  Os  últimos  pontos  deste 

gráfico  têm  menor  significância  estatística,  pois  envolvem  poucos  pares  de  pontos.  A 

curva experimental obtida é na realidade um estimador do verdadeiro semivariograma 

desconhecido;  este  possui  propriedades  matemáticas  precisas,  fazendo-se  necessário, 

portanto, o ajuste de um modelo teórico que sirva de base para os cálculos posteriores. 

• 

Ajuste a uma família de modelos de semivariogramas: o modelo ajustado 

ao  semivariograma  experimental  está  relacionado  com  o  comportamento  do 

semivariograma na origem e a existência ou não de um patamar. Ao modelo une-se o 

efeito  pepita  por  extrapolação  da  curva.  A  adequação  de  um  modelo  teórico  é 

fundamental, pois a partir dele serão feitas inferências com relação ao semivariograma 

verdadeiro. 

• 

Validação do modelo a ser utilizado nos procedimentos da krigagem: a 

adequada  modelagem  da  estrutura  de  dependência  espacial  valida  qualquer  outro 

procedimento de inferência e interpolação, além de ser um forte subsídio para decisões 

práticas  sobre  o  fenômeno  em  estudo.  Conhecido  o  semivariograma  da  variável  em 

estudo e havendo dependência espacial entre as amostras, o próximo passo consiste na 

obtenção de informações de pontos não amostrados no campo por meio do método de 

interpolação denominado krigagem. 

Os métodos de krigagem são métodos de interpolação que procuram minimizar 

o erro da estimação; na realidade, o erro médio de estimação é nulo. O problema que se 

coloca normalmente é o de estimar o valor de uma variável em locais não amostrados, 

, a partir dos valores de locais amostrados, 

. O estimador de krigagem 

é também um estimador linear que considera a organização espacial da variável: 

 

 

 

 

31 

 

 

, 

. 

em que 

 é o ponderador da distância e 

 

A  krigagem  é  um  método  exato  e  não  viesado,  isto  é,  os  valores  nos  locais 

amostrados são reproduzidos e o erro médio de estimação é nulo. 

Para  avaliar  de  forma  adequada  a  análise  geoestatística,  alguns  autores  têm 

utilizado  o  método  da  validação  cruzada.  Nesta,  assume-se  que  uma  determinada 

amostra não tenha sido coletada, ou seja, elimina-se o seu valor e se estima a partir dos 

dados circundantes. Após essa estimação, o valor real dessa amostra é reintroduzido no 

sistema e o processo é repetido para todas as outras amostras, de forma que para cada 

ponto é possível obter o erro de estimação. Uma estimação terá sido sem bias se o erro 

médio for zero, isto é, se os valores estimados tiverem uma diferença média em relação 

aos valores experimentais igual a zero, e a variância estiver em torno de um.  

É  importante  ressaltar  que  a  análise  geoestatística  não  se  trata  de  um  método 

contínuo  em  uma  direção.  A  análise  geoestatística  consiste  em  ir  e  voltar,  refazer  e 

comparar antes de qualquer decisão definitiva. Várias decisões são tomadas ao longo do 

processo, ou seja, os resultados intermediários e finais não são obtidos de forma única, e 

as  técnicas  descritivas  e  exploratórias  devem  estar  presentes  em  todas  as  fases  do 

processo de análise e não só na fase inicial. 

 

 

4.6 COMPARAÇÃO ENTRE OS MÉTODOS DE INTERPOLAÇÃO 
 

A  krigagem  permite  que  se  faça  uma  validação  cruzada  para  checagem  dos 

dados, ou pelo menos uma comparação entre os erros. Por este método, o ideal seria ter 

um erro médio padronizado dos valores preditos próximo de zero, um quadrado médio 

do erro o mais baixo possível e um quadrado médio do  erro padronizado próximo de 

um. 

No  caso  dos  interpoladores  determinísticos  (i,e.,  curvatura  mínima  e  o  inverso 

quadrado da distância), estes somente fornecem o quadrado médio do erro, e este tem 

que ser o mais baixo possível. O quadrado médio do erro (QME) é dado por: 

 

 

 

 

 

32 

 

Os  resultados  obtidos  para  o  quadrado  médio  do  erro  serão  comparados,  e  o 

método  que  apresentar  o  menor  quadrado  médio  residual  será  o  método  considerado 

como o mais eficiente, isto para que os valores dos pontos no mapa interpolado sejam o 

mais possível parecidos com os valores recolhidos nesses pontos. 

 

 

 

5 RESULTADOS E DISCUSSÕES 
 

5.1 ANÁLISE EXPLORATÓRIA DESCRITIVA 
 

33 

Esta seção apresenta os resultados da aplicação da metodologia proposta como 

estudo de caso em um conjunto de dados piston core da Bacia de Santos, composto por 

n = 500 registros e p = 12 atributos. 

Uma das dificuldades encontradas para o melhor desenvolvimento deste estudo, 

por  ser  inovador  para  geoquímica  de  superfície  brasileira,  foi  a  busca  de  referências 

bibliográficas relacionadas. 

 

 
5.1.1 Dados originais 
 

Os dados piston core da Bacia de Santos foram obtidos a partir da ANP/BDEP 

(Agência  Nacional  do  Petróleo,  Gás  Natural  e  Biocombustíveis  /  Banco  de  Dados  de 

Exploração  e  Produção).  Devido  à  diversidade  de  informações,  foi  necessário  realizar 

um pré-processamento em diversas etapas (dados outliers, dados ausentes, entre outros) 

para  se  obter  a  base  para  a  avaliação.  Os  atributos  elencados  abaixo  estão  na  mesma 

ordem da figura 7: 

1 - Intensidade da Fluorescência (nm); 

2 - Emissão Máx. (nm); 

3 - Excitação Máx. (nm); 

4 - TSF R1 (nm); 

5 - UCM Total (ppm); 

6 - Alcanos Totais (ppm); 

7 - Metano (ppm); 

8 - Etano (ppm); 

9 - Propano (ppm); 

10 - i-Butano (ppm); 

11 - n-Butano (ppm); 

12 - n-Pentano (ppm). 

 

 

34 

 

A figura 7 é uma matriz de correlação dos dados Piston core. Observa-se que as 

linhas 1 e 5 (Intensidade da Fluorescência e UCM Total), assim como as linhas 2 e 3 

(Emissão  e  Excitação),  possuem  forte  correlação  (aprox.  0,9).  A  correlação  entre  a 

Intensidade  da  Fluorescência  e  UCM  Total  pode  se  dever  à  predominância  de 

hidrocarbonetos (amorfos) indicativos de matéria orgânica recente ou de óleo exsudado 

que foi biodegradado. O grau da maturação da matéria orgânica pode ser determinado 

por  meio  da  intensidade  e  da  cor  da  fluorescência  do  material  analisado  (TISSOT; 

WELTE,  1984).  A  matéria  orgânica  imatura  geralmente  apresenta  fluorescência 

amarela. Quando no início da janela de geração, a coloração se torna laranja e, quando 

matura,  marrom  (MENDONÇA;  MENESES,  2001).  Os  dados  de  gasometria 

apresentaram também boa correlação (aprox. 0,9) corroborando desta maneira com os 

dados  das  variáveis:  Intensidade  da  Fluorescência,  Emissão  Máx.  e  UCM  Total.  As 

variáveis Excitação Máx, TSF R1 e Alcanos Totais apresentaram menor correlação com 

as demais variáveis em estudo (aprox. 0,3). 

 

o
ã
ç
a
l
e
r
r
o
c
 
e
d

 

u
a
r
G

 

Figura 7: Matriz de correlação dos dados piston core da Bacia de Santos 

 

 

 

Baseado  no  gráfico  da  variância  explicada  (Fig.  8),  temos  que  o  primeiro 

componente  principal  explica  cerca  de  69%  (CP1)  da  variação  nos  dados,  o  segundo 

principal componente explica 19% (CP2) e a terceira. 11% (CP3). 

35 

 

 

Figura 8 - Variância Explicada - Componentes Principais (n +1) versus  

X - Variância Percentual 

 

Pode-se  assim  dizer  que  quase  toda  a  informação  relevante  para  o  modelo  em 

estudo (cerca de 99%) pode estar contida nas três primeiras componentes principais. Em 

referência  aos  resultados  da  ACP  (análise  de  componentes  principais)  (Fig.  8),  Zuo 

(2011)  obteve  os  mesmos  resultados  por  meio  da  aplicação  de  análise  estatística 

multivariada.  ACP  é  uma  ferramenta  útil  para  combinar  diversas  variáveis 

correlacionadas  em  uma  única  variável  e,  assim,  para  reduzir  a  dimensionalidade  de 

conjuntos  de  dados  correlacionados  em  componentes  principais  com  base  na 

covariância  ou  correlações  de  variáveis,  que  representam  as  inter-relações  entre  as 

variáveis multidimensionais. 

Na  figura  9  ilustra-se  a  existência  de  diferentes  comportamentos  entre  os 

parâmetros  em  estudo.  Entre  os  parâmetros  de  gasometria  (metano,  etano  e  propano), 

intensidade da fluorescência máx, TSF R1, UCM total, emissão máx e excitação máx, 

 

 

 

apresentam-se  com  comportamentos  distintos  entre  os  mesmos.  Já  os  parâmetros  n-

pentano, n-butano, alcanos totais e i-butano não se correlacionam com os demais. 

36 

 

1,0

Intensidade da Fluorescência Máx (nm)
Intensidade da Fluorescência Máx (nm)
0,5

Propano (ppm)
Propano (ppm)
TSF R1 (nm)
TSF R1 (nm)
Etano (ppm)
Etano (ppm)

Metano (ppm)
Metano (ppm)

UCM Total (ppm)
UCM Total (ppm)

Emissão Máx (nm)
Emissão Máx (nm)
Excitação Max (nm)
Excitação Max (nm)

)

%
5
1
,
1
2
(
 
2
-
P
C

0,0

-0,5

-1,0

n-Pentano (ppm)
n-Pentano (ppm)
n-Butano (ppm)
n-Butano (ppm)

Alcanos Totais (ppm)
Alcanos Totais (ppm)

i-Butano (ppm)
i-Butano (ppm)

-1,0

-0,5

0,0

0,5

1,0

CP-1 (43,86%)

 

Figura 9 - Gráfico de distribuição dos pesos aos parâmetros de piston core para a  

Componente Principal 1 versus Componente Principal 2 

 

As  estatísticas  descritivas  para  os  dados  originais  de  Intensidade  da 

Fluorescência  (nm),  Emissão  Máx.  (nm),  Excitação  Máx.  (nm),  TSF  R1  (nm),  UCM 

Total  (ppm),  Alcanos  Totais  (ppm),  Metano  (ppm),  Etano  (ppm),  Propano  (ppm),  i-

Butano (ppm), n-Butano (ppm) e n-Pentano (ppm) estão apresentadas na Tabela 1. 

Para os dados do i-butano (ppm), o excesso de curtose foi bem superior a um. 

Levando-se em conta que a curtose de uma curva normal é de 3, a curtose dessa série de 

dados  indica  uma  curva  além  do  valor,  tendo  a  função  de  distribuição  um  pico  mais 

elevado e denominado leptocúrtica. 

Existe  uma  estreita  relação  entre  o  valor  das  medidas  de  tendência  central  e  o 

comportamento  da  assimetria,  tendo  a  média  se  apresentado  maior  que  a  mediana, 

demonstrando  a  assimetria  positiva  dos  dados.  Um  expressivo  desvio  padrão  implica 

uma menor representatividade estatística da média dos dados observados. 

 

 

37 

 

O  coeficiente  de  variação  de  n-Pentano  (207,39)  mostra  essa  menor 

representatividade estatística da média dos dados e não permite nenhuma conclusão da 

distribuição dos dados; de acordo com Frizzo e Licht (2007), não indica conveniência 

da transformação dos dados brutos (originais) para seu logaritmo. 

Segundo  Warrick  e  Nielsen  (1980),  pode-se  classificar  a  variabilidade  da 

variável como média (0,12<CV<0,62). 

 

 

 

 

Tabela 1 - Análise estatística descritiva das amostras com os valores originais (não transformados) 

38 

ESTATÍSTICAS 

Intensidade 

da 

Fluorescência 

Emissão 
Máx (nm) 

Excitação 
Máx (nm) 

(nm) 

TSF R1 

UCM Total 

500,00 

500,00 

500,00 

Alcanos 
Totais 
(ppm) 

Metano 
(ppm) 

Etano 
(ppm) 

Propano 
(ppm) 

i-butano 
(ppm) 

500,00 

500,00 

500,00 

500,00 

500,00 

n-Butano 

n-Pentano 

(ppm) 

500,00 

(ppm) 

500,00 

(nm) 

500,00 

81,42 
72,00 
7,00 
234,00 
227,00 
50,00 
105,00 
1,96 

1819,80 
33,82 
42,66 

0,50 

39,50 

326,27 
340,00 
200,00 
458,00 
258,00 
300,00 
344,00 
1,48 

1039,60 
24,80 
32,24 

3,85 

0,00 

217,64 
230,00 
20,00 
430,00 
410,00 
200,00 
230,00 
0,09 
386,00 
14,84 
16,65 

48,28 

170,00 

0,96 
0,82 
0,00 
4,48 
4,48 
0,64 
1,10 
0,03 
0,30 
0,37 
0,56 

9,05 

0,64 

7,82 

Número de 
amostras 
Média 
Mediana 
Valor mínimo 
Valor máximo 
Amplitude 
Quartil inferior 
Quartil superior 
Erro Padrão 
Variância 
Desvio médio 
Desvio padrão 
Excesso de 
Curtose 
Limite Inferior 
(Q1-1,5XAIQ) 
Limite Superior 
(Q3+1,5XAIQ) 
Coeficiente de 
variação 

 

(ppm) 

500,00 

2,91 
2,00 
0,00 
12,00 
12,00 
1,00 
5,00 
0,12 
6,80 
2,13 
2,60 

0,12 

23,00 

89,25 

0,43524 
0,370 
0,01 
2,32 
2,31 
0,22 
0,59 
0,02 
0,11 
0,24 
0,32 

13,22 
9,40 
3,87 
179,03 
175,16 
7,79 
11,52 
0,73 
251,9 
7,14 
15,87 

5,68 

42,33 

0,51 
0,48 
0,00 
2,310 
2,310 
0,37 
0,62 
0,01 
0,10 
0,17 
0,26 

12,68 

0,26 
0,26 
0,00 
0,96 
0,96 
0,19 
0,33 
0,01 
0,00 
0,09 
0,12 

6,68 

0,19 

1,77 

0,35 
0,02 
0,00 
1,21 
1,21 
0,00 
0,04 
0,00 
0,00 
0,03 
0,09 

0,20 
0,09 
0,00 
2,21 
2,21 
0,07 
0,12 
0,02 
0,10 
0,20 
0,36 

0,16 
0,06 
0,00 
3,23 
3,23 
0,04 
0,09 
0,01 
0,10 
0,17 
0,32 

92,09 

12,94 

34,85 

0,00 

1,86 

0,07 

3,44 

0,04 

4,94 

74,32 

120,03 

49,77 

45,19 

254,30 

185,75 

207,39 

 

456,00 

1031,00 

875,00 

4,07 

280,07 

4,09 

52,39 

9,88 

9,03 

58,16 

1,00 

0,205 

1,98 

0,37 

 

39 

De  acordo  com  a  Tabela  1,  para  as  demais  variáveis,  a  média  e  a  mediana  também 

apresentaram  entre  si  valores  próximos,  revelando  uma  variação  mínima.  Os  valores  de 

excesso  de  curtose  apresentaram  valores  positivos  indicando  uma  distribuição  assimétrica 

positiva e um comportamento leptocúrtico da curva de distribuição, tendo a variável i-Butano 

apresentado o maior valor, e para as variáveis Intensidade da Fluorescência e UCM Total, os 

menores  valores  para  o  excesso  de  curtose  respectivamente,  indicando  uma  possível 

distribuição gaussiana. 

Observando os valores do coeficiente de variação (CV), os menores valores também 

são das variáveis: Emissão Máx. e Excitação Máx. e as máximas para i-butano e n-Pentano. 

Segundo  Koch  e  Link  (1971),  para  valores  de  coeficiente  de  variação  menores  que  0,3  ou 

30%, a distribuição é normal ou muito aproximadamente normal, tendo as variáveis: Emissão 

Máx. e Excitação Máx. apresentado valores de CV dentro dessa faixa. Quando é observado 

para a variável com desvios padrão maior do que a média, o uso da distribuição normal fica 

inviabilizado (MACKAY; PATERSON, 1984).  

Desta maneira, segundo Koch e Link (1971), já que ficaram com valores de CV entre 

40% e 70%, não permitem qualquer conclusão para as variáveis estudadas. Segundo Warrick 

e Nielsen (1980), pode-se classificar a variabilidade das variáveis como alta (CV>0,62). 

As estatísticas para as variáveis apontam claramente um distanciamento da hipótese de 

normalidade.  Analisando  estas  hipóteses  pelos  testes  formais  de  normalidade  (Tabela  2), 

pode-se  observar  para  as  variáveis  Emissão  Máx.;  Excitação  Máx.;  Metano;  i-Butano;  n-

Butano  e  n-Pentano  que  não  se  rejeita  a  hipótese  nula  de  que  a  distribuição  é  normal  de 

acordo com K-S (valor em negrito). Para as demais variáveis também não se rejeita hipótese 

nula de ser a distribuição normal, contudo com menores valores. 

 
Tabela 2 - Testes formais de normalidade Kolmogorov-Smirnov (K-S) para os dados originais 

ESTATÍS-
TICAS 

Intensidade 

da 

Fluorescência 

(nm) 
0,109 

K-S 
 

Emissão 

Excitação 

Máx 
(nm) 

0,201 

Máx 
(nm) 

0,29 

TSF 
R1 
(nm) 

UCM 
Total 
(ppm) 

Alcanos 
Totais 
(ppm) 

Metano 
(ppm) 

Etano 
(ppm) 

Propano 
(ppm) 

i-

n-

n-

butano 
(ppm) 

Butano 
(ppm) 

Pentano 
(ppm) 

0,158 

0,17 

0,101 

0,324  0,107 

0,11 

0,36 

0,402 

0,341 

 

 

 

 

 

 

 

 
* Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas.

Figura 10 - Histograma de frequência para as variáveis originais 

 

40 

 

 

 

 

 

 

 

 

 

 
* Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas. 

Figura 10 - Histograma de frequência para as variáveis originais (continuação) 

 

41 

 

 

 

 

 

 

 

 

 

 

Figura 11 - Boxplot para as variáveis originais 

42 

 

 

 

 

 

 

 

 

 

 

Figura 11 - Boxplot para as variáveis originais (continuação) 

43 

 

 

 

 

 

 

 

 
* Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas.

 
Figura 12 - Gráfico de probabilidade para as variáveis originais 

 

 

44 

 

 

 

 

 

 

 

 

 

* Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas. 

Figura 12 - Gráfico de probabilidade para as variáveis originais (continuação) 

 

 

 

45 

 

 

 

 

46 

Como  podemos  verificar  por  meio  dos  histogramas,  boxplots  e  gráficos  de 

probabilidade, a maioria das variáveis não apresentam um ajuste à distribuição normal. Estas 

observações  sugerem  a  existência  significativa  de  outliers  para  estas  variáveis  e  talvez  um 

melhor  ajuste  à  distribuição  lognormal,  como  descrito  por  Ahrens  (1953,  1954a,  1954b, 

1957). 

De acordo com a estatística, valores outliers deveriam ser removidos; no entanto, do 

ponto  de  vista  geoquímico,  estes  valores  extremos  podem  ter  significado,  constituindo 

anomalias geoquímicas. Segundo Reimann et al. (2005), a detecção de dados outliers é uma 

das  principais  tarefas  da  análise  estatística  de  dados  geoquímicos.  Para  minorar  eventuais 

efeitos  nocivos  provocados  por  esses  fenômenos  (existência  de  “outliers”  e  comportamento 

lognormal), foi usada a transformação (ln, log10 e raiz quadrada (Sqrt)) dos dados, evitando 

assim  a  remoção  de  outliers  e  verificando  se  os  dados  geoquímicos  melhor  se  ajustam  ao 

comportamento lognormal. 

 

 
5.1.2 Dados transformados (ln) 
 

As  estatísticas  descritivas  para  os  dados  transformados  (ln)  das  variáveis  estão 

apresentados na Tabela 3. A Tabela mostra que a variação entre a média e mediana de forma 

geral  ficou menor após  a transformação, mas a transformação dos dados não aproximou de 

fato numa distribuição lognormal. 

Os  valores  de  excesso  de  curtose  apresentaram  também  valores  mais  próximos  da 

normalidade, obtendo menores valores excesso de curtose para as variáveis: ln UCM Total; ln 

Alcanos Totais; ln i-butano; ln n-Butano e ln n-Pentano, e maiores valores para as variáveis: 

ln Intensidade da Fluorescência; ln Emissão Máx.; ln Excitação Máx.; ln Metano; ln Etano e 

ln Propano, que no item anterior ficaram próximas da normalidade. As variáveis: ln Emissão 

Máx.; ln Excitação Máx.; ln UCM Total; ln i-butano; ln n-Butano e ln n-Pentano tiveram seus 

valores de média menores que a mediana, apresentando assimetria negativa, ou seja, tiveram 

seus dados levemente concentrados à direita; para as demais variáveis, a assimetria é positiva, 

com maior acúmulo de dados à esquerda. 

 

 

 

Tabela 3 - Análise estatística descritiva das amostras transformadas (ln): 

ln  

Intensidade 

ESTATÍSTICAS 

da 

Fluorescência 

Número de 
amostras 
Média 
Mediana 
Valor mínimo 
Valor máximo 
Amplitude 
Quartil inferior 
Quartil superior 
Erro Padrão 
Variância 
Desvio médio 
Desvio padrão 
Excesso de 
Curtose 
Limite Inferior 
(Q1-1,5XAIQ) 
Limite Superior 
(Q3+1,5XAIQ) 
Coeficiente de 
variação 

(nm) 

500,00 
4,36 
4,30 
1,95 
10,26 
8,31 
3,91 
4,72 
0,03 
0,57 
0,52 
0,75 
9,36 

0,99 

20,11 
0,17 

ln  

ln UCM 

ln Alcanos 

ln 

ln Emissão 
Máx (nm) 

ln Excitação 
Máx (nm) 

TSF R1 

(nm) 

Total 
(ppm) 

500,00 
5,79 
5,83 
5,30 
6,47 
1,17 
5,70 
5,84 
0,01 
0,02 
0,08 
0,12 
5,55 

-2,24 

15,54 
0,02 

500,00 
5,38 
5,44 
3,00 
6,06 
3,07 
5,30 
5,44 
0,01 
0,02 
0,07 
0,13 
228,48 

0,80 

14,53 
0,02 

500,00  500,00 
0,91 
-0,15 
1,10 
-0,21 
-2,45 
-0,69 
4,75 
1,50 
5,45 
3,95 
0,00 
-0,45 
0,09 
1,61 
0,04 
0,02 
0,72 
0,21 
0,35 
0,74 
0,85 
0,46 
2,93 
-0,33 

3,23 

2,34 
-3,00 

1,04 

8,74 
0,94 

Totais 
(ppm) 

500,00 
0,01 
0,01 
0,00 
0,01 
0,01 
0,01 
0,01 
0,00 
0,00 
0,00 
0,00 
2,13 

0,00 

0,02 
0,17 

Metano 
(ppm) 

ln Etano 
(ppm) 

ln Propano 

(ppm) 

500,00 
2,51 
2,24 
1,35 
10,71 
9,36 
2,05 
2,47 
0,05 
1,23 
0,56 
1,11 
24,81 

500,00 
-0,69 
-0,67 
-2,12 
3,54 
5,66 
-0,97 
-0,45 
0,02 
0,23 
0,34 
0,48 
12,46 

0,02 

2,21 

18,54 
0,44 

4,87 
-0,70 

500,00 
-1,34 
-1,35 
-3,32 
2,67 
6,00 
-1,66 
-1,11 
0,02 
0,22 
0,33 
0,47 
13,06 

3,33 

2,90 
-0,35 

 

ln  
i-

butano 
(ppm) 

500,00 
-2,49 
-3,22 
-4,61 
2,24 
6,85 
-3,91 
0,00 
0,07 
2,79 
1,48 
1,67 
-1,17 

(ppm) 

500,00 
-1,95 
-2,30 
-4,83 
1,59 
6,41 
-2,53 
-1,97 
0,05 
1,03 
0,77 
1,01 
0,75 

3,00 

4,72 

3,37 
-0,67 

0,41 
-0,52 

47 

ln  

ln  

n-Butano 

n-Pentano 

(ppm) 

500,00 
-2,29 
-2,81 
-3,91 
3,71 
7,63 
-3,00 
-1,66 
0,05 
1,39 
0,95 
1,18 
1,04 

2,87 

3,91 
-0,51 

 

 

48 

O  valor  máximo  para  a  variável  ln  n-Butano  está  fora  do  intervalo  dado  pelo  limite 

superior  e as variáveis: ln TSF R1; ln UCM Total; ln Etano; ln Propano; ln  i-butano; ln  n-

Butano e ln n-Pentano estão fora do intervalo dado pelo limite inferior, sugerindo possíveis 

candidatos a valores discrepantes. 

Segundo  Warrick  e  Nielsen  (1980),  pode-se  classificar  a  variabilidade  como  média 

(0,12<CV<0,62)  para  as  variáveis:  ln  Intensidade  da  Fluorescência;  ln  Alcanos  Totais;  ln 

Metano,  e  como  alta  (CV>0,62)  para  ln  UCM  Total,  tendo  apresentado  o  valor  mais  baixo 

para ln TSF R1 (-3,00) e valor mais alto para ln UCM Total (0,94). 

Analisando  os  dados  pelos  testes  formais  de  normalidade  (Tabela  4),  pode-se 

confirmar que não se rejeita a hipótese nula de que a distribuição é normal para as variáveis: 

ln emissão máx., ln excitação máx., ln UCM Total, ln alcanos totais, ln metano, ln i-butano, ln 

n-butano e ln n-pentano, as que mais se assemelham com uma distribuição normal pelo teste 

K-S  (valores  em  negrito);  já  para  as  demais  variáveis,  rejeita-se  a  hipótese  nula  de  que  a 

distribuição é lognormal. 

 

Tabela  4  -  Testes  formais  de  normalidade  Kolmogorov-Smirnov  (K-S)  para  os  dados 
transformados 
ESTATÍS-
TICAS 

ln Emissão 
Máx (nm) 

Intensidade 

Excitação 

ln 

ln 

ln 

ln 

Metano 
(ppm) 

ln 

Etano 
(ppm) 

ln 

Propano 
(ppm) 

ln i-
butano 
(ppm) 

ln n-
Butano 
(ppm) 

ln 

Pentano 
(ppm)

0,25 

0,31 

0,07 

0,24 

0,11 

0,28 

0,08 

0,09 

0,27 

0,27 

0,25

ln TSF 

R1 
(nm) 

ln 

UCM 
Total 
(ppm) 

Alcanos 
Totais 
(ppm) 

Máx 
(nm) 

da 

Fluorescência 

(nm) 
0,08 

K-S 

 

Podemos  visualizar  melhor  a  dispersão  dos  dados  através  das  figuras  boxplots, 

histogramas de frequência e de probabilidade para as variáveis transformadas: ln Intensidade 

da  Fluorescência,  ln  TSF  R1,  ln  Etano  e  ln  Propano  (Figura  5.4a,5.4b  e  5.4c, 

respectivamente), as quais tiveram rejeitada a hipótese nula de que a distribuição é lognormal. 

 

 

 

 

 

 

 

 

Figura 13a - Histograma de frequência para as variáveis transformadas (ln): Intensidade da Fluorescência (nm),  

TSF R1 (nm), Etano (ppm) e Propano (ppm) 

 

* Obs.: as curvas em linha vermelha representam a distribuição da curva gaussiana esperada para as variáveis estudadas.

 

49 

 

 

 

 

 

50 

 

 

 

 

 

Figura 13b - Boxplot para as variáveis transformadas (ln): Intensidade da Fluorescência (nm), TSF R1 (nm),  

Etano (ppm) e Propano (ppm) 

 

 

 

 

Figura 13c - Gráfico de probabilidade para as variáveis transformadas (ln): Intensidade da Fluorescência (nm), 

* Obs.: as linhas em vermelho representam a reta probabilidade esperada para as variáveis estudadas. 

TSF R1 (nm), Etano (ppm) e Propano (ppm). 

 

 

51 

 

 

 

 

52 

Fazendo a transformação dos dados por outros métodos (Tabela 5), pode-se verificar 

que os dados transformados (log10) tiveram os mesmos resultados dos testes de normalidade 

para  as  variáveis  transformadas  (Ln).  Já  para  os  dados  transformados  pela  raiz  quadrada 

(Sqrt),  o  teste  de  normalidade  mostra  que  se  rejeita  a  hipótese  nula  de  que  a  distribuição  é 

normal somente para a variável Alcanos Totais (valor em negrito). 

 

Tabela 5 - Testes formais de normalidade Kolmogorov-Smirnov (K-S) para dados originais 

(não transformados) e dados transformados (ln, log10 e Sqrt) 

ESTATÍSTICAS 
K-S 
Intensidade da 
Fluorescência 
(nm) 
Emissão Máx 
(nm) 
Excitação Máx 
(nm) 
TSF R1 (nm) 
UCM Total 
(ppm) 
Alcanos Totais 
(ppm) 
Metano (ppm) 
Etano (ppm) 
Propano (ppm) 
i-Butano (ppm) 
n-Butano (ppm) 
n-Pentano (ppm) 

Orig. 

Ln 

Log10 

Sqrt 

0,11 

0,08 

0,08  0,27 

0,20 

0,29 
0,16 
0,17 

0,10 
0,32 
0,11 
0,11 
0,36 
0,40 
0,34 

0,25 

0,31 
0,07 
0,16 

0,11 
0,28 
0,09 
0,09 
0,21 
0,27 
0,24 

0,25  0,26 

0,31  0,28 
0,07  0,12 
0,16  0,12 

0,11  0,03 
0,28  0,42 
0,09 
0,2 
0,09 
0,2 
0,21  0,27 
0,27  0,32 
0,24  0,29 

 

 

5.1.3 Interpolação pelos modelos: krigagem ordinária, curvatura mínima e inverso do 

         quadrado da distância 

 

Os métodos da krigagem, curvatura mínima e inverso do quadrado da distância para 

cada variável foram ajustados conforme o padrão do software Surfer 8.01 em estudo. 

Com  o  objetivo  de  comparar  graficamente  os  interpoladores,  os  blocos  diagrama  e 

superfície  destas  interpolações  são  mostrados.  Foram  utilizados  os  métodos:  [média  +  1 

desvio padrão], [média + 2 desvio padrão] e [média + 3 desvio padrão] para a determinação 

de  limiares,  onde  a  cor  verde  corresponde  aos  valores  médios  (background)  e  as  cores  de 

laranja a vermelha, aos valores anômalos. 

Os  blocos  diagrama  e  superfície  dos  valores  das  variáreis  nas  figuras  a  seguir, 

estimados pelo método de krigagem, apresentam as mesmas sub-regiões descritas nas análises 

 

 

 

53 

da superfície de valores. Entretanto, foi apresentado um efeito suavizador das diferenças, visto 

que o interpolador de krigagem superestima para baixas medidas e subestima para elevados 

valores, ou seja, tende à média dos dados. 

Esse  resultado  é  obtido  principalmente  pelo  fato  deste  interpolador  ser  não  viciado, 

com  variância  mínima,  pois  é  um  interpolador  ótimo.  A  região  dita  anômala  aparece  bem 

delineada. 

A  interpolação  pelo  método  de  curvatura  mínima  para  as  variáveis  apresentaram 

outras sub-regiões não descritas na  analise da superfície de valores  como se pode observar, 

apresentando uma distribuição espacial menos homogênea que a apresentada pelo método de 

krigagem. Pode-se verificar também uma extrapolação de valores, principalmente nas bordas 

do bloco. 

Já a interpolação pelo método do inverso do quadrado da distância (IQD), os blocos 

diagrama  e  superfície  para  os  valores  das  variáveis  apresentaram  uma  distribuição  espacial 

mais homogênea do que pelo método de curvatura mínima. 

 

 

 

 

a)

b)

c)

 

 

 

Figura 14a - Bloco diagrama interpolado para a intensidade da fluorescência (nm)  
pelos métodos: (a) krigagem ordinária, (b) curvatura mínima e (c) inverso do  

quadrado da distância 

54 

 

 

 

 

 

a)

b)

c)

Figura 14b - Mapas para a intensidade da fluorescência (nm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

55 

 

 

 

a)

b)

c)

 

 

 

Figura 15a - Bloco diagrama interpolado para a emissão máx (nm) pelos métodos:  
(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

56 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 15b - Mapas para emissão máx (nm) pelos métodos: (a) krigagem ordinária,  

(b) curvatura mínima e (c) inverso do quadrado da distância 

57 

 

a)

b)

c)

 

 

 

Figura 16a - Bloco diagrama interpolado para a excitação máx (nm) pelos métodos:  
(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

58 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 16b - Mapas para excitação máx (nm) pelos métodos: (a) krigagem  

ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

59 

 

a)

b)

c)

 

 

 

Figura 17a - Bloco diagrama interpolado para a TSF R1 (nm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

60 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 17b - Mapas para TSF R1 (nm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

61 

 

a)

b)

c)

 

 

 

Figura 18a - Bloco diagrama interpolado para UCM total (ppm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

62 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 18b - Mapas para UCM total (ppm) pelos métodos: (a) krigagem ordinária, (b) 

curvatura mínima e (c) inverso do quadrado da distância. 

 

63 

 

a)

b)

c)

 

 

 

Figura 19a - Bloco diagrama interpolado para alcanos totais (ppm) pelos métodos:  
(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

64 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 19b - Mapas para alcanos totais (ppm) pelos métodos: (a) krigagem 

ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

65 

 

a)

b)

c)

 

 

3 

Figura 20a - Bloco diagrama interpolado para metano (ppm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

66 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 20b - Mapas para metano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

67 

 

a)

b)

c)

 

 

 

Figura 21a - Bloco diagrama interpolado para etano (ppm) pelos métodos: (a) krigagem  

ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

68 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 21b - Mapas para etano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

69 

 

a)

b)

c)

 

 

 

Figura 22a - Bloco diagrama interpolado para propano (ppm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

70 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 22b - Mapas para propano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

71 

 

a)

b)

c)

 

 

 

Figura 23a - Bloco diagrama interpolado para i-butano (ppm) pelos métodos: ( 

a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

72 

 

 

 

 

 

 

a)

b)

c) 

 

 

 

Figura 23b - Mapas para i-butano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

 

 

73 

 

a)

b)

c)

 

 

 

Figura 24a- Bloco diagrama interpolado para n-butano (ppm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

74 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 24b - Mapas para n-butano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância. 

75 

 

a)

b)

c)

 

 

 

Figura 25a- Bloco diagrama interpolado para n-pentano (ppm) pelos métodos:  

(a) krigagem ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

76 

 

 

 

 

 

 

 

a)

b)

c)

 

 

 

Figura 25b - Mapas para n-pentano (ppm) pelos métodos: (a) krigagem  
ordinária, (b) curvatura mínima e (c) inverso do quadrado da distância 

77 

 

 

5.1.4 Comparação entre métodos de interpolação 

 

78 

Pela comparação dos blocos diagramas obtidos, verifica-se que o método de krigagem 

ordinária  apresenta  distribuição  espacial  muito  mais  homogênea  do  que  os  demais.  Esse 

resultado  é  obtido  principalmente  pelo  fato  deste  interpolador  ser  não  tendencioso,  com 

variância mínima. 

O  desempenho  desses  interpoladores  foi  obtido  e  comparado  usando  o  critério  do 

quadrado  médio  do  erro  (QME).  Para  os  valores  estimados  pelos  métodos  do  inverso  do 

quadrado da distância  e  curvatura mínima, esse  critério pode ser  aplicado diretamente, pois 

não são interpoladores ótimos, e a diferença dos valores estimados e os observados não são 

nulos. Entretanto, para o interpolador de krigagem ordinária, por ser ótimo, essa diferença é 

nula; logo, para ter os valores estimados no ponto observado, o método de validação cruzada 

(VIEIRA,  2000;  ISAAKS;  SRIVASTAVA,  1989)  foi  usado.  Esse  método  envolve  a 

estimativa de cada ponto medido, simulando que ele não existe durante a sua estimativa. A 

razão  é  que  krigagem  ordinária  é  um  interpolador  exato,  passando  exatamente  pelo  ponto 

observado, quando esse é usado no cálculo. 

Na  Tabela  6,  apresentam-se  os  resultados  obtidos  para  o  critério  de  comparação 

(QME)  para  as  variáveis.  O  valor  do  critério  deve  ser  próximo  de  zero  se  o  algoritmo  for 

preciso. Altos erros estimados são obtidos para os três interpoladores. 

Para  os  dados  das  variáveis,  o  interpolador  que  apresentou  resultado  mais  acurado 

conforme a tabela a seguir, foi o de krigagem ordinária, seguido pelo inverso do quadrado da 

distância e, por último, pela curvatura mínima. 

 

 

Tabela 6 - Resultados obtidos para o quadrado médio do erro (QME) 

para interpoladores usados na distribuição espacial das variáveis 

79 

Variável 

Intensidade da 
Fluorescência 
(nm) 
Emissão Máx 
(nm) 
Excitação Máx 
(nm) 
TSF R1 (nm) 
UCM Total 
(ppm) 
Alcanos Totais 
(ppm) 
Metano (ppm) 
Etano (ppm) 
Propano (ppm) 
i-butano (ppm) 
n-Butano (ppm) 
n-Pentano 
(ppm) 

Krigagem 

Inverso do 
Quadrado 

Curvatura 

Mínima 

da 

Distância 

17,52 

18,64 

18,43 

33,57 

28,70 

0,002 

0,31 

31,24 

5,18 
0,39 
1,40 
5,22 
3,71 

5,40 

 

33,61 

28,90 

0,04 

0,33 

31,87 

5,15 
0,44 
1,70 
5,88 
3,96 

5,46 

33,75 

29,38 

0,04 

0,38 

31,74 

5,93 
0,48 
1,73 
6,24 
4,68 

5,75 

 

 

5.2 AVALIAÇÃO DA CLUSTERIZAÇÃO FUZZY C-MEANS (FCMC) 
 

O algoritmo da clusterização Fuzzy c-Means (FCMC) particiona o conjunto de dados 

em  um  pré-determinado  “c”-  número  de  clusters.  É  uma  técnica  de  agrupamento  de  dados, 

onde cada ponto de dados de alguma forma pertence a um cluster que é especificado por um 

grau de pertinência. Este método fornece a informação de como os pontos de dados de grupo 

demonstram  como  preencher  um  espaço  multidimensional  em  um  número  específico  em 

diferentes clusters. Clustering é uma ferramenta matemática que tenta descobrir estruturas ou 

certos  padrões  em  um  conjunto  de  dados,  onde  os  objetos  dentro  de  cada  cluster  mostram 

certo  grau  de  semelhança.  Neste  estudo,  a  avaliação  de  agrupamento  FCM  é  considerada 

como  a  estrutura  mais  adequada  em  conjuntos  de  dados  geoquímicos  (ZIAII  et  al.,  2009; 

GATH et al., 1997). 

A avaliação do agrupamento FCM foi realizada a partir do índice de validação PBM 

para determinar qual o número de clusters no conjunto de dados (EVSUKOFF et al., 2004;. 

PAKHIRA  et  al.,  2004).  Para  esclarecimentos  sobre  outros  indicadores,  vide  o  capítulo  3 
 

 

 

80 

sobre inteligência computacional, para determinar o melhor número possível de agrupamentos 

nos dados. Posteriormente, como pode ser visto na Tabela 7, para muitos dos valores “m” do 

parâmetro fuzzy, o índice de validação indica três agrupamentos no conjunto de dados. Assim, 

a classificação foi realizada considerando basicamente três agrupamentos (classes), conforme 

apresentado nas figuras 5.20, 5.21 e 5.22. 

O valor do índice diminui na medida quando o valor de “m” aumenta. Isso se deve ao 

fato de que quanto maior for o valor do parâmetro de fuzzificação, mais imprecisas serão as 

partições geradas, conforme as figuras 26, 27 e 28, adiante. 

 

 

 

 

Tabela 7 - Determinação do número de clusters. Como pode ser visto, para os valores  
             do parâmetro de fuzzificação “m”, o índice de validação indica 3 clusters (em negrito)  
             para o banco de dados de Piston core em estudo 

m = 1,2  m = 1,4  m = 1,6  m = 1,8  m = 2,0  No clusters 
0,1149 

0,0368 

0,0659 

0,0179 

0,0058 

2 

0,1459 

0,0853 

0,0443 

0,0185 

0,0075 

0,5319 

0,0703 

0,0331 

0,0132 

0,0065 

0,4568 

0,0485 

0,0236 

0,0095 

0,0046 

1,2046 

0,0382 

0,0194 

0,0064 

0,0036 

0,4064 

0,2276 

0,0157 

0,0048 

0,0023 

1,5146 

0,2132 

0,0139 

0,0040 

0,0018 

3,3765 

0,1857 

0,0129 

0,0031 

0,0016 

3 

4 

5 

6 

7 

8 

9 

2,3611 

0,1676 

0,0117 

0,0026 

0,0012 

10 

 

81 

 

82 

 

 
Figura 26 - Mapa de Função de Pertinência FCM, CP1 versus CP2  
(Componente Principal 1 versus Componente Principal 2), ilustrando  
três clusters formados pelos valores da função de pertinência “m = 1,2” 

 
Figura 27 - Mapa de Função de Pertinência FCM, CP1 versus CP2  
(Componente Principal 1 versus Componente Principal 2), ilustrando  
três clusters formados pelos valores da função de pertinência “m = 1,6” 

 

 

 

 

83 

 

 

 
Figura 28 - Mapa de Função de Pertinência FCM, CP1 versus CP2  
(Componente Principal 1 versus Componente Principal 2), ilustrando  
três clusters formados pelos valores da função de pertinência “m = 2,0” 

Os resultados na Tabela 7 apresentam que, para valores maiores do parâmetro “m”, o 

índice PBM é menor, uma vez que a partição é mais fuzzy. As partições permitem um registro 

fuzzy a ser atribuído a mais de uma classe, possibilitando transições graduais entre os clusters. 

Desta  maneira,  o  classificador  geo-fuzzy  foi  assim  atribuído  para  classificar  os  clusters 

gerados com “m = 1,6” (parâmetro de fuzzificação). 

 

 

5.3 CLASSIFICAÇÕES DOS RESULTADOS 
 

O classificador geo-fuzzy foi determinado a partir dos resultados de análise de cluster 

para  avaliar  cada  cluster  no  domínio  geográfico.  Para  esta  aplicação,  a  base  da  regra  foi 

gerada usando n = 10 conjuntos fuzzy para cada coordenada, resultando em 100 regras (10) e 

uma  grade  de  62.500  (250  x  250)  pontos  regularmente  espaçados  dentro  do  domínio 

(EVSUKOFF et al., 2004). 

Os  resultados  são  mostrados  nas  figuras  29  e  30  (a  e  b),  nas  quais  os  membros  da 

classe são representados por um grau de cores: o verde representa a participação (0,0) nula e o 

vermelho representa a adesão (1,0) completa. 

 

 

 

84 

 

 

Figura 29 - Mapa do Cluster 1, longitude versus latitude, ilustrando áreas  

anômalas para o cluster 1 

 

 

85 

 

 

Figura 30a - Mapa do Cluster 2, longitude versus latitude, ilustrando áreas  

anômalas para o cluster 2

 

 

86 

 

Figura 30b - Mapa do Cluster 3, longitude versus latitude, ilustrando áreas  

anômalas para o cluster 3. 

 

 

 

 

 

 

87 

As  interpretações  de  cada  cluster  podem  ser  feitas  a  partir  de  seu  centro  de 

coordenadas, mostrado na Tabela 8. As colunas indicam os atributos do piston core utilizados 

para a avaliação dos clusters. 

 
Tabela  8  -  Valores  piston  core  nos  centros  dos  clusters.  A  interpretação  de  cada  cluster  pode  ser 
realizada pelos centros de suas respectivas coordenadas. As linhas indicam os parâmetros piston core 
que foram utilizados para expressar as avaliações dos clusters pelas suas unidades. 

Parâmetros 

Cluster 1  Cluster 2  Cluster 3 

Intensidade da Fluorescência (nm) 

Emissão Máxima (nm) 

Excitação Máxima (nm) 

TSF R1 (nm) 

Total UCM (ppm) 

Alcanos Totais (ppm) 

Metano(ppm) 

Etano (ppm) 

Propano (ppm) 

i-Butano (ppm) 

n-Butano (ppm) 

n-Pentano (ppm) 

365,4 

359,8 

231,1 

2,2 

7,0 

490,5 

323,8 

1,7 

1,3 

1,1 

1,2 

1,3 

1570,8 

2041,6 

83,6 

41,3 

1,6 

9,2 

442,8 

2630,1 

2,6 

2,2 

1,4 

1,4 

3,0 

394,9 

252,0 

2,8 

16,4 

979,2 

2886,6 

3,3 

2,0 

1,5 

1,6 

3,2 

 

Obs.:  ppm  =  partes  por  milhão;  TSF  R1  =  Fluorescência  total  Razão1  (Este  parâmetro 

possibilita uma estimativa qualitativa da razão de hidrocarbonetos de três anéis para dois anéis 

aromáticos); UCM = mistura complexa não resolvida (A quantificação deste parâmetro obtido 

a  partir  da  cromatografia  gasosa  provém  uma  medida  de  concentração  de  hidrocarbonetos 

extraíveis em amostras biodegradadas). 

 

O cluster 1, ilustrado na figura 29, refere-se à concentração mais comum das amostras 

com  menores  concentrações  de  hidrocarbonetos,  nas  quais  poderiam  ser  indicativos  da 

possível  ausência  de  fontes  significativas  em  subsuperfície  ou  a  existência  de  barreiras  de 

permeabilidade entre as fontes e da superfície. 

O cluster 2, apresentado na figura 30a, representa concentrações intermediárias entre 

os cluster 1 e 3. Finalmente, o cluster 3 (Figura 30b) é semelhante ao cluster 2, apresentando 

valores  outliers  apenas  para  o  metano,  que  poderiam  indicar  uma  possível  contribuição  de 

 

 

 

88 

gases biogênicos gerados pela degradação da matéria orgânica. Se no banco de dados deste 

estudo  houvesse,  por  exemplo,  a  indicação  aos  dados  de  isótopos  de  carbono,  poder-se-ia 

comprovar esta indicação. 

Nas áreas dos clusters onde há anomalias com sobreposição dos pontos de piston core 

e  de  poços,  pode  haver  indícios  de  acumulações  na  área.  Para  confirmar  a  existência  deste 

foram utilizadas as informações contidas no banco de dados disponíveis da ANP/BDEP a fim 

de corroborar os campos identificados nas figuras 31; 32 e 33, a seguir. No caso em que não 

existem  anomalias  pode  ser  devido  ao  fato  de  as  rochas  selantes  serem  muito  efetivas  e 

poderem  existir  acumulações  de  petróleo,  ou  mesmo,  ser  grande  a  probabilidade  de  não 

existirem acumulações na área em estudo. 

Nas áreas onde somente existem os pontos de piston core e nenhum poço perfurado 

isto  pode  ser  devido  ao  fato  de  haver  anomalias  com  possíveis  acumulações.  De  outra 

maneira, por não existirem anomalias, pode ter acumulações (mas os hidrocarbonetos não se 

difundem) ou não é grande a probabilidade de que não existam acumulações significativas de 

petróleo. 

 

 

89 

 

 

Figura 31 - Mapa do Cluster 1, longitude versus latitude, ilustrando  

campos identificados em produção para o cluster 1

 

 

90 

 

 

Figura 32 - Mapa do Cluster 2, longitude versus latitude, ilustrando  

campos identificados em produção para o cluster 2

 

 

91 

 

Figura 33 - Mapa do Cluster 3, longitude versus latitude, ilustrando  

campos identificados em produção para o cluster 3 

 

 

 

 

 

 

92 

As  amostras  puderam  ser  agrupadas  de  acordo  com  seus  valores  mais  elevados  de 

adesão. O número absoluto e relativo de amostras agrupadas em cada cluster é apresentado na 

tabela 9. 

 

Tabela 9 - Número de amostras de cada cluster. Os clusters podem ser agrupados de acordo com sua 
maior participação em cada cluster, em valores absolutos e relativos. 

 

Absoluto  Relativo (%) 

Cluster 1 

Cluster 2 

Cluster 3 

151 

126 

173 

34 

28 

38 

 

Os  resultados  na  tabela  9  são  semelhantes  aos  da  área  de  regiões  na  figura  30b.  O 

cluster 3 é o cluster mais comum, agrupando 38% dos dados, enquanto os clusters 1 e 2 são 

os que reagrupam o menor número de amostras. 

Estes resultados podem ser uma indicação da existência de uma região de anomalia no 

agrupamento 3, mas deve ser confirmada por estudos geológicos para maiores detalhes. 

Em exploração geoquímica, a clusterização fuzzy c-means fornece uma forma objetiva 

e  eficaz  para  especificar  litologicamente  as  concentrações  background  na  composição 

geoquímica  de  sedimentos.  Deve  ser  evitado  utilizar  somente  esta  técnica,  pois  poderá 

ocasionar  uma  má  interpretação  de  áreas  anômalas,  que  estão  apenas  relacionadas  com  a 

composição litológica dentro da área de drenagem das amostras (RANTITSCH, 2000). 

 

 

 

6 CONCLUSÕES 

 

93 

Neste  estudo  buscou-se  a  avaliação  de  dados  geoquímicos  de  superfície  com  ênfase 

nos hidrocarbonetos leves de 500 amostras piston core da Bacia de Santos. As amostras foram 

analisadas  por  Fluorescência,  Head  Space  e  Cromatografia  Gasosa.  Foram  construídos 

diversos blocos diagramas, mapas de contorno e mapas de clusterização fuzzy dos parâmetros 

em estudo. 

Os  dados  geoquímicos  de  superfície  não  apresentam  uma  distribuição  lognormal  ou 

normal. Mesmo quando usados outros diferentes métodos de tratamento, não se aproximaram 

de uma distribuição normal. 

Foram  obtidos  melhores  resultados  com  o  interpolador  geoestatístico  de  krigagem 

ordinária do que com os demais interpoladores curvatura mínimo e inverso do quadrado da 

distância, que não ponderam a dependência espacial entre as observações.  

Desta forma a krigagem ordinária indica maior precisão para os locais da previsão da 

distribuição  das  variáveis  estudadas,  inferindo  subsídios  para  delimitar  áreas  com  possíveis 

potenciais petrolíferos, assim como para reduzir o custo de novas pesquisas. 

Foi  apresentada  uma  metodologia  do  geoprocessamento  fuzzy  para  mapas  de 

geoquímica de superfície e estudo de data mining para a Bacia de Santos. 

Os resultados permitiram uma definição mais precisa das áreas anômalas visualizadas 

nos mapas de clusterização fuzzy, tendo em conta todos os parâmetros geoquímicos de forma 

integrada  (em  vez  de  avaliação  das  concentrações  de  cada  gás  de  forma  independente), 

proporcionando uma alternativa a geoestatística padrão. 

 

 

 

7 RECOMENDAÇÕES 
 

94 

As  técnicas  de  inteligência  computacional  contribuem  como  ferramenta  de  apoio  na 

tomada  de  decisão  para  auxiliar  no  aumento  da  confiabilidade  na  exploração  e  da 

minimização do risco exploratório na indústria petrolífera. 

 

Empregar  outros  métodos  para  adquirir  outros  conhecimentos  como,  por  exemplo, 

Regras  de  Associação,  ou  ainda  para  preencher  os  valores  de  algumas  variáveis  que  se 

encontram ausentes, por meio de Regressão Linear. 

 

Aumentar a densidade de amostragem piston core para ter uma maior abrangência da 

área com a finalidade de obter uma maior confiabilidade. 

 

Não foram evidenciados claramente trabalhos aplicados à geoquímica de superfície de 

hidrocarbonetos  gasosos  implementados  com  ferramentas  geoestatísticas,  o  aprendizado 

estatístico  e  geoestatístico.  Também  se  constatou  a  ausência  de  maiores  informações 

interdisciplinares sobre a região estudada, as quais contribuiriam para uma melhor avaliação 

dos dados. 

 

 

 

95 

 

REFERÊNCIAS  
 

ABRAMS,  A.  M.;  DAHDAH,  N.  F.  Surface  sediment  gases  as  indicators  of  subsurface 
hydrocarbons - examining the record in laboratory and field studies. Marine and Petroleum 
Geology, v. 27, p. 273-84, 2010. 

 
ALBA,  J.  M.  F.;  SOUZA,  C.  R.  GIS-based  environmental  risk  assessment  in  the  Ribeira 

Valley. Environmental Earth Sciences, São Paulo, Brazil, v. 59, p. 1139-47, 2010. 

 
AGRAWAL,  R.;  SRIKANT,  R.  Fast  algorithms  for  mining  association  rules  in  large 
databases.  Proceedings  of  the  International  Conference  on  Very  Large  Databases, 
Santiago, Chile, 1994. 

 
AHRENS, L. H.A fundamental law of Geochemistry. Nature, v. 172, p. 1148, 1953. 
 
AHRENS,  L.  H.  The  lognormal  distribution  of  the  elements  (A  fundamental  law  of 
Geochemistry and its subsidiary). Geochimica et Cosmochimica Acta, New York, n. 5, p. 
49-74, 1954a. 

 
AHRENS, L. H. The lognormal distribution of the elements II. Geochimica et Cosmochimica 

Acta, New York, n. 6, p. 121-32, 1954b. 

 
AHRENS, L. H. Lognormal-Type Distribution III. Geochimica et Cosmochimica Acta, n. 11, 

p. 205-13, 1957. 

 
CHAVES, C. J. Avaliação de segmentações urbanas através de inteligência computacional. 
2011. 72 p. Dissertação (Mestrado em Engenharia Civil) – UFRJ/COPPE, Rio de Janeiro, 
2011. 

 
CHERKASSKY, V.; MULLER, F. M. Learning from data: Concepts, Theory and Methods. 

2nd edition, New Jersey: Willey IEEE Press, 2007. 

 
CHRISTENSEN, J. H.; TOMASI, G.; HANSEN, A.B. Chemical Fingerpriting of Petroleum 
Biomarkers Using Time Warping and PCA. Environmental Science Technology, v. 39, p. 
255-60, Jan., 2005. 

 
DBMINER  TECHNOLOGY  INC.  DBMiner  Enterprise  2.0,  2000.  Disponível  em: 

<http://www.dbminer.com>. Acesso em: 5 maio 2013. 

 
DEMBICKI,  H.  Recognizing  and  compensating  for  interference  from  the  sediment’s 
background  organic  matter  and  biodegradation  during  interpretation  of  biomarker  data 
from  seafloor  hydrocarbon  seeps:  An  example  from  the  Marco  Polo  area  seeps,  Gulf  of 
Mexico, USA. Marine and Petroleum Geology, v. 27, p. 1936-51, 2010. 

 
DOMINGUES, H. H. Espaços métricos e introdução à topologia. São Paulo: Atual, 1982.  
 
DUBOIS, D.; PRADE, H. Possibility Theory. New York: Plenum Press, 1988. 
 

 

 

 

96 

EVSUKOFF, A. G.; GONÇALVES, F. T.; BEDREGAL, R. P.; EBECKEN, N. F. F. Fuzzy 
classification of surface geochemistry data applied to the determination of HC anomalies. 
IEEE Joint 2nd International Conference on Soft Computing and Intelligent Systems, 2004. 

 
FAYYAD,  U.;  PIATETSKY-SHAPIRO,  G.;  SMYTH,  P.  From  data  mining  to  knowledge 
discovery:  An  overview. 
In:  FAYYAD,  U.;  SHAPIRO,  G.  P.;  SMYTH,  P.; 
UTHURUSAMY, R. (Eds.). Advances in Knowledge Discovery and Data Mining, p. 1-34, 
Menlo Park (CA): AAAI Press, 1996. p. 1-34. 

 
FRIZZO,  S.  J.;  LICHT,  O.  A.  B.  Estatísticas  uni  e  bivariadas  aplicadas  à  prospecção 
geoquímica.  In:  LICHT,  O.  A.  B.;  MELLO,  C.  S.  B.;  Silva,  C.  R.(Eds.).  Prospecção 
geoquímica  de  depósitos  minerais  metálicos,  não-metálicos,  óleo  e  gás.  Rio  de  Janeiro: 
SBGq - Sociedade Brasileira de Geoquímica / CPRM – Serviço Geológico do Brasil, 2007. 
Cap. 19, p. 595-618. 

 
GATH,  I.;  ISKOZ  A.  S.;  CUTSEM,  B.  V.  M.  Data  induced  metric  and  fuzzy  clustering  of 
non-convex  patterns  of  arbitrary  shape.  Pattern  Recognition  Letters,  v.  18,  p.  541-53, 
1997. 

 
GÜLER, C.; KURT, M. A.; ALPASLAN, M.; AKBULUT, C., Assessment of the impact of 
anthropogenic  activities  on  the  groundwater  hydrology  and  chemistry  in  Tarsus  coastal 
plain  (Mersin,  SE  Turkey)  using  fuzzy  clustering,  multivariate  statistics  and  GIS 
techniques. Journal of Hydrology. Article in Press, 2011. 

 
HAN,  J.;  KAMBER,  M.  Data  Mining:  Concepts  and  Techniques.  San  Francisco:  Morgan 

Kaufmann, 2001. 

 
HAN, J.; KOPERSKI, K.; STEFANOVIC, N. Geominer: a system prototype for spatial data 
mining”.  ACM  SIGMOD  International  Conference  on  Management  of  Data,  Arizona, 
1997. 

 
HOLDER,  L.;  COOK,  D.;  GONZALEZ,  J.;  JONYER,  I.  Structural  pattern  recognition  in 
graphs,  in  pattern  recognition  and  string  matching.  Dordrecht  (Netherlands):  Kluwer 
Academic Publishers, 2002. 

 
HOPPNER,  F.;  KLAWONN,  F.;  KRUSE,  R.;  RUNKLER,  T.  Fuzzy  Cluster  Analysis. 

Chichester (England): Willey, 1999. 

 
ISAAKS, E. H., SRIVASTAVA, R. M. An introduction to applied geoestatistics. New York: 

Oxford University Press, 1989.  

 
JAIN, A.; DUBES, R. Algorithms for clustering data. Englewood Cliffs (USA): Prentice Hall, 

1988. 

 
JIAWEI  H.,  KAMBER  M.  Data  mining:  concepts  and  techniques.  2.ed.  San  Francisco 

(USA): Morgan Kaufmann Publishers, 2006. 

 
KAUFMAN,  L.;  ROUSSEEUW,  P.  J.  Finding  groups  in  data:  an  introduction  to  cluster 

analysis. New York: Willey, 1990. 

 

 

 

 

97 

KDNUGGETS.  Data  Mining  and  Knowledge  Discovery,  2004.  Disponível  em: 

<http://www.kdnuggets.com>. Acesso em: 2 maio 2013. 

 
KECMAN, V. Learning and Soft Computing. Cambridge: MIT Press, 2001. 
 
KHOSHNOODKIA,  M.;  MOHSENI,  H.;  RAHMANI,  O.;  MOHAMMADI,  A.  TOC 
determination  of  Gadvan  Formation  in  South  Pars  Gas  field,  using  artificial  intelligent 
systems and geochemical data. Journal of Petroleum Science & Engineering, v. 78, p. 119-
130, 2011. 

 
KLUSMAN, R. W. Interpretation and display of surface geochemical data. In: SCHUMACHER, D.; 
LESHACK,  L.  A.  (eds).  Surface  exploration  case  histories:  Applications  of  geochemistry, 
magnetics and remote sensing. AAPG Studies/SEG Geophysical References Series, n. 11, p.1-24, 
2002. 

 
KOCH Jr. G. S.; LINK, R. F. Statical analysis of geological data. New York: John Willey & 

Sons Inc, 1971. 

 
LEE, C. C. Fuzzy logic in control systems: Fuzzy logic controller (part II). IEEE Transactions 

on Systems, Man and Cybernetics, v. 20, p. 419-30, 1990. 

 
LOGAN,  A. G.; JONES, A. T.; KENNARD, J.  M.; RYAN, G. J.; ROLLET, N. Australian 
offshore  natural  hydrocarbon  seepage  studies,  a  review  and  re-evaluation.  Marine  and 
Petroleum Geology, v. 27, p. 26-45, 2010. 

 
MACKAY, D.; PATERSON, S. Spatial Concentration Distribution. Env.Sci.  & Technology, 

Washington, v.18, n.1, p. 207A-214A, 1984. 

 
MASSART,  D.  L  et  al.  (Eds.).  Handbook  of  Chemometrics  and  Qualimetrics:  Part  A. 

Amsterdam: Elsevier, 1997 

 
MCQUEEN,  J.  Some  methods  for  classification  and  analysis  of  multivariate  observations.    

5-th Berkeley Symposium on mathematics 1, p. 281 - 298, 1967. 

 
MELLO, C. B. S. de. Apostila de Amostragem. Curso de Geoquímica de Superfície Aplicada 

a Exploração de Hidrocarbonetos. Rio de Janeiro, UFRJ/COPPE/ PEC/ LAMCE, 2003.  

 
MELLO, M. R. Geoquímica do petróleo. Petrobrás / RJ, Cenpes, set. 1984. 
 
MENDONÇA FILHO, J. G.; MENEZES, T. R. Curso de palinofácies e fácies orgânicas. Rio 

de Janeiro: UFRJ, 2001.  

 
MOREIRA, J.  L. P.  et al. Bacia de Santos.  Boletim  de  Geociências  da  Petrobrás, v. 25, p. 

531-549, 2007. 

 
PAKHIRA,  M.  K.;  BANDYOPADHYAY,  S.;  MAULIK,  U.  Validity  index  for  crisp  and 

fuzzy clusters. Pattern Recognition, v. 37, p. 487-501. 2004. 

 
PASADAKIS, N.; OBERMAJER, M.; OSADETZ, K. G. Definition and characterization of 
petroleum  compositional  families  in  Wiliston  Basin,  North  América  using  principal 

 

 

 

98 

component analysis. Organic Geochemistry, v.35, p. 453-68, 2004. 

 
PETERS, K. E.; FOWLER, M. G. Applications of petroleum geochemistry to exploration and 

reservoir management. Organic Geochemistry, v.33, p.5-36, 2002. 

 
PETERS, K. E.; WALTERS, C. C.; MOLDOWAN, J. M.  The  biomarker  guide: biomarker 
and isotopes in petroleum exploration and Earth history. 2 ed. v. 2, Cambridge: Cambridge 
University, 2005. 

 
RANTITSCH,  G.  Application  of  fuzzy  clusters  to  quantify  lithological  background 
concentrations in stream-sediment geochemistry. Journal of Geochemical Exploration, v. 
71, p. 73-82, 2000. 

 
REIMANN,  C.;  FILZMOSER,  P.;  GARRET,  R.  Background  and  threshold:  critical 
comparison of methods of determination. Science of the total environment, n. 346, p. 1-16, 
2005. 

 
REZENDE,  S.  O.  Sistemas  inteligentes:  fundamentos  e  aplicações.  Barueri  (SP):  Manole, 

2005. 

 
ROCHA, C.  L.  Análise  de  fronteiras  de  reservatório  de  petróleo  através  de  geoquímica  de 
superfície e mineração de dados. 2005. Dissertação (Mestrado em Ciências em Engenharia 
Civil) – UFRJ, Rio de Janeiro, 2005. 

 
SARDIÑAS, Z. D. Caracterização geoquímica de asfaltitas cubanas. 2007. Tese (Doutorado 

em Química Orgânica) - UFRJ, Rio de Janeiro, 2007. 

 
SCHUMACHER,  D.,  2011.  Petroleum  Exploration  in  Environmentally  Sensitive  Areas: 
Opportunities for Geochemical and Non-Seismic Geophysical Methods. AAPG Search and 
Discovery  Article  #90129©2011  AAPG  Southwest  Section  Meeting,  Ruidoso,  New 
Mexico, 5-7 June 2011. 

 
SCHUMACHER, D. Surface Geochemical Exploration for oil and  gas:  New life  for  an old 

technology. The Leading Edge, v. 19, p. 258-261, March 2000. 

 
SCHUMACHER,  D.;  CLAVAREAU,  L.  Hydrocarbon  exploration  survey  strategies  for 
frontier  basins.  Search  and  Discovery  Article  #40681  (2011).  Posted  Jan.  18,  2011. 
Adapted  from  oral  presentation  at  AAPG  International  Conference  and  Exhibition, 
Calgary, Alberta, Canada, Sept. 12-15, 2010. 

 
SCHUMACHER, D.; CLAVAREAU, L. Finding new pays in old plays: New applications for 
surface  geochemistry  in  mature  basins.  Search  and  Discovery  Article  #41084  (2012). 
Posted  Nov.  30,  2012.  AAPG  International  Conference  and  Exhibition,  Singapore,  Sept. 
16-19, 2012.  

 
TISSOT, B. P.; WELTE, D. H. Petroleum formation and occurrence. 2. ed., Berlin: Springer-

Verlag, 1984. 

 

 

 

 

99 

VIEIRA,  S.R.  Geoestatística  em  Estudos  de  Variabilidade  Espacial  do  Solo.  In:  NOVAIS,  R.  F.; 
ALVAREZ,  V.  H.;  SCHAEFER,  C.  E.  G.  R.  (Eds.).  Tópicos  em  Ciência  do  Solo.  Viçosa: 
Sociedade Brasileira de Ciência do Solo, v. 1, p.1-54, 2000, 

 
WARRICK, A. W.; NIELSEN, D. R. Spatial Variability of Same Physical Properties of the Soil. In: 
HILL, D. (Ed.) Applications of Soil Physics, New York: Academic Press, 1980. Cap. 13, p. 319-44. 
1980. 

 
WIEDEMANN,  L.  S.  M.  Caracterização  geoquímica  de  óleos  de  bacia  sedimentar 

brasileira. 2006. Tese (Doutorado em Ciências) – UFRJ, Rio de Janeiro, 2006. 

 
ZIAII,  M.;  POUYAN,  ALI  A.;  ZIAEI,  M.  Neuro-fuzzy  modeling  in  mining  geochemistry: 
Identification of  geochemical anomalies.  Journal  of  Geochemical  Exploration, v. 100, p. 
25-36, 2009. 

 
ZUO,  R.  Identifying  geochemical  anomalies  associated  with  Cu  and  Pb-Zn  skarn 
mineralization using principal component analysis and spectrum-area fractal modeling in 
the Gangdese Belt, Tibet (China). Journal of Geochemical Exploration, v. 111, p. 13-22, 
2011. 

 

 

