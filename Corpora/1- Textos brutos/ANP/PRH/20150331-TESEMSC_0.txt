Felipe Codevilla Moraes

Vis√£o computacional em meio subaqu√°tico:

Um estudo sobre detec√ß√£o de pontos de interesse

e classifica√ß√£o utilizando contexto.

Brasil

5 de mar√ßo, 2015

Felipe Codevilla Moraes

Vis√£o computacional em meio subaqu√°tico:

Um estudo sobre detec√ß√£o de pontos de interesse

e classifica√ß√£o utilizando contexto.

Universidade Federal de Rio Grande

Programa de P√≥s gradua√ß√£o em Computa√ß√£o

Mestrado em Engenharia de Computa√ß√£o

Orientador: Nelson Duarte Lopez Filho

Coorientador: Silvia Silva da Costa Botelho

Brasil

5 de mar√ßo, 2015

Um estudo sobre detec√ß√£o de pontos de interesse
e classifica√ß√£o utilizando contexto./ Felipe Codevilla Moraes. ‚Äì Brasil, 5 de mar√ßo,
2015-

Felipe Codevilla Moraes

Vis√£o computacional em meio subaqu√°tico:

Orientador: Nelson Duarte Lopez Filho

Disserta√ß√£o de Mestrado ‚Äì Universidade Federal de Rio Grande
Programa de P√≥s gradua√ß√£o em Computa√ß√£o
Mestrado em Engenharia de Computa√ß√£o, 5 de mar√ßo, 2015.
1. Vis√£o Computacional; 2. Vis√£o Subaqu√°tica.

CDU 02:141:005.7

Felipe Codevilla Moraes

Vis√£o computacional em meio subaqu√°tico:

Um estudo sobre detec√ß√£o de pontos de interesse

e classifica√ß√£o utilizando contexto.

Nelson Duarte Lopez Filho

Orientador

Silvia Silva da Costa Botelho

Co-orientadora

Nuno Estrela Gracias

Convidado

Glauber Acunha Gon√ßalvez

Convidado

Rafael Garcia

Convidado

Brasil

5 de mar√ßo, 2015

Agradecimentos

Entre tantas d√∫vidas , resolvi apostar permanecer onde estava e, ao contr√°rio do

que se espera, n√£o poderia ter acertado mais.

Primeiramente gostaria de agradecer a minha orientadora Silvia Botelho por todas
as brilhantes ideias e oportunidades oferecidas, obviamente nada disso seria poss√≠vel sem
ela.

Agrade√ßo a todos os colegas e amigos onde destaco Luan Silveira, Joel Gaya, Felipe

Guth e, em especial, a ajuda fornecida pelo Pedro Ballester na √∫ltima hora.

Agrade√ßo a banca por comparecer e avaliar este trabalho.
I want to thank all the people from the ViCOROB Lab in Girona for receiving me
so well during the 10 months I spent in Catalonia. Without this experience, the majority
of this thesis would not be possible.

I also want to thank all my classmates and friends from Vibot (and Patryk) for all

the fun and professional adventures we had toguether.

Agrade√ßo o apoio financeiro da Ag√™ncia Nacional do Petr√≥leo, G√°s Natural e Bio-
combust√≠veis ‚Äì ANP ‚Äì , da Financiadora de Estudos e Projetos ‚Äì FINEP ‚Äì e do Minist√©rio
da Ci√™ncia e Tecnologia ‚Äì MCT por meio do Programa de Recursos Humanos da ANP para
o Setor Petr√≥leo e G√°s ‚Äì PRH-ANP/MCT. Um agradecimento especial aos professores
respons√°veis pelo PRH - 27, Maria Isabel e Gilberto Griep.

Por fim, agrade√ßo a minha fam√≠lia pelo apoio e carinho que sempre me deram, em
especial ao meu pai, por sempre servir como um formid√°vel exemplo √©tico em minha vida.

Resumo

A explora√ß√£o e o monitoramento do bentos no ambiente marinho possuem
import√¢ncia econ√¥mica e ambiental crescente na sociedade atual. A qualidade da
tecnologia de obten√ß√£o de imagens √≥ticas subaqu√°ticas tem melhorado consideravel-
mente devido ao advento dos Remotely Operated Vehicles (ROV) e dos Autonomous
Underwater Vehicles (AUVs), o que tem possibilitado a coleta de milhares de dados
visuais do fundo do oceano.

T√©cnicas de vis√£o computacional, atualmente em franca utiliza√ß√£o em am-
bientes terrestres, podem auxiliar a interpreta√ß√£o autom√°tica destas imagens, seja
para minimizar o trabalho de identifica√ß√£o e monitoramento de fei√ß√µes e esp√©cies,
seja para fornecer subs√≠dios a realiza√ß√£o aut√¥noma de miss√µes.

Por√©m devido a presen√ßa do meio l√≠quido, a propaga√ß√£o da luz no meio su-
baqu√°tico apresenta efeitos fotom√©tricos que causam degrada√ß√£o na imagem, emer-
gindo diversas quest√µes a serem tratadas na classifica√ß√£o de imagens subaqu√°ticas,
as quais n√£o est√£o presentes em outros ambientes.

Assim, o objetivo geral deste trabalho √© estudar t√©cnicas de vis√£o computa-
cional, e sua sensibilidade a presen√ßa do meio l√≠quido. De forma mais precisa, duas
t√©cnicas de vis√£o computacional s√£o principalmente tratadas: a detec√ß√£o de pontos
de interesse e a adi√ß√£o das informa√ß√µes de contexto para classifica√ß√£o de objetos em
ambientes subsea.

S√£o aplicados e analisados diferentes algoritmos de detec√ß√£o de pontos de
interesse frente a imagens com diferentes n√≠veis de turbidez. Um novo dataset foi
proposto capaz de fornecer cen√°rios com diferentes n√≠veis de turbidez e objetos em
cena, permitindo o testes m√∫ltiplos dos detectores mais usados na literatura e seu
comportamento frente os fen√¥menos de degrada√ß√£o causados na imagem no meio
subaqu√°tico. Foi encontrado que o algoritmo DoG se mostrou como uma melhor
alternativa para resolver tal problema de forma invariante a escala.

Tamb√©m foi estudada a quest√£o da adi√ß√£o de contexto como forma de me-
lhorar a taxa de acerto da classifica√ß√£o de imagens subaqu√°ticas. Foi proposto um
novo m√©todo para incluir contexto na classifica√ß√£o baseado em Geoestat√≠stica e
comparou-se com outras formas tradicionais de adi√ß√£o de contexto como os Condi-
tional Random Fields (CRF).

Palavras-chaves: Vis√£o Computacional, Geostat√≠stica, Vis√£o Subaqu√°tica.

Abstract

The exploration and monitoring of the benthic sea zone has an important
economic and environmental role in the nowadays society. The quality of the optical
image acquiring technologies has become considerably better. This happened mainly
due to the advent of the Remotely Operated Vehicles (ROV) and the Autonomous
Underwater Vehicles (AUVs) and has opened the possibility to collect thousands of
visual data from the seabed environment.

Computer vision techniques are today being largely used in over-land envi-
ronments and can help the autonomous interpretation of images. These techniques
can help to minimize the work of identifying and monitoring species and objects.
Either having vision as a data acquiring source or to assist the automation of the
operations.

However, due to the presence of the liquid media, the light propagation
in underwater environments has photometric effects that cause degradation of the
image. This degradation develops a lot of issues to be treated on underwater images
that do not exist in other environments.

Thus, the objective of this work is to study computer vision tecniques consid-
ering their sensibility to phenomenas of the underwater environments media. More
precisely, mainly two computer vision techniques are considered: feature point detec-
tion and the adition context information for image classification, both on underwater
images.

Different algorithms for feature point detection are applied for feature point
detection under different turbidity levels. We provide a new dataset capable of
providing different scenarios with different levels of turbidity. This dataset allowed
the test of multiple feature detectors regarding their behavior with respect to the
degradation effects of water turbidity. We found that, in this scenario, the DoG
algorithm is the best alternative to solve scale invariant feature detection problems.
Finally, we studied the issue concerning the addition of context as a way to
improve the accuracy of underwater image classification. We proposed a new method
to include the context information on classification that is based on Geostatistics.
This method was compared with an other traditional form of context addition that
is the Conditional Random Fields (CRF).

Key-words: Computer Vision, Geostatistics, Underwater Vision.

Lista de ilustra√ß√µes

Figura 1 ‚Äì Comportamento da aplica√ß√£o dos kernels Hessian e Harris para uma
imagem teste (1a). (1b) mostra a sa√≠da da medida de Harris (Eq. 1.4).
(1c) mostra a sa√≠da do determinante da matriz Hessian ( Eq. 1.5 )
para a imagem teste. Tanto o Hessian como o Harris tem como sa√≠da
as regi√µes de alta curvatura ( Figura por Sojka (2003)). . . . . . . . . . 31

Figura 2 ‚Äì O processo para gera√ß√£o do espa√ßo de escala pelo DoG. Ao inv√©s de
computar o Laplacian para cada escala, o mesmo √© estimado pela dife-
ren√ßa entre escalas consecutivas. Figura adaptada de (LOWE, 2004).

. 34

Figura 3 ‚Äì Exemplo de um filtro caixa de tamanho 9x9 aplicado para gera√ß√£o de
um espa√ßo de escala equivalente a ùúé = 1.2. Outros espa√ßos podem ser
gerados usando caixas maiores.

. . . . . . . . . . . . . . . . . . . . . . 34

Figura 4 ‚Äì Alguns tipos de filtros utilizados para gera√ß√£o do espa√ßo de escala pelo
CenSurE. O filtro estrela, o filtro hexagonal e o filtro por diferen√ßa de
caixas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

Figura 5 ‚Äì Espa√ßos de escala gerados. Primeira coluna mostra o espa√ßo Gaussiano.
Segunda coluna mostra o filtro m√©dia de caixas usado pelo FastHes-
sian. Terceira coluna mostra um filtro poligonal estrelar de seis lados.
A quarta Coluna mostra o espa√ßo de escala anisotr√≥pico usado pelo
KAZE.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

Figura 6 ‚Äì Janela considerada para a classifica√ß√£o usando contexto. No caso da
integra√ß√£o de contexto diretamente nos classificadores (Fig. 6a), n√£o
s√£o considerada as rela√ß√µes entre a vizinhan√ßa com si pr√≥pria (Fig. 6b).
Ou seja, se existem propriedades correlacionadas na vizinhan√ßa.

. . . . 42

Figura 7 ‚Äì A representa√ß√£o gr√°fica de um modelo CRF. Os quadrados em verme-
lho (ùúôùë¢
ùëñ (ùë•ùëñ, ùúÉùë¢)) s√£o os fatores unit√°rios calculados com o resultado dado
pelo classificador. Os quadrados em azul s√£o os fatores locais computa-
dos em cada aresta e utilizados para introduzir informa√ß√£o contextual.
Os circulos verdes representam os superpixeis sendo classificados.

. . . 44

Figura 8 ‚Äì Tend√™ncias que existem para as classes estarem pr√≥ximas umas das
outras, quanto mais claro, maior √© a tend√™ncia existente. Por exemplo,
√© poss√≠vel perceber que a classe B √© prov√°vel de aparecer perto de uma
classe C mas n√£o pr√≥xima de uma classe E.

. . . . . . . . . . . . . . . 46

Figura 9 ‚Äì Divis√£o especificada em dois n√≠veis de classifica√ß√£o. O n√≠vel un√°rio
ùëÉùë¢(ùêø|ùúÉùë¢) onde somente a informa√ß√£o do superpixel segmentado √© uti-
lizada, apresentado em verde. E o n√≠vel local ùëÉùëô(ùêø|ùëä), onde um de-
terminado contexto local √© inclu√≠do na classifica√ß√£o, representado pelo
circulo azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

Figura 10 ‚ÄìFigura do separador linear obtido pelo treinamento do SVM. Dado os
conjuntos de dados j√° rotulados ( Azuis e Vermelhos), o SVM determina
o separador de m√°xima margem. A sa√≠do num√©rica do SVM j√° √© pr√≥pria
para se ter um certo grau de confian√ßa do classificador.

. . . . . . . . 51

Figura 11 ‚ÄìGr√°fico mostrando a probabilidade de acerto em fun√ß√£o da m√°xima
confian√ßa retornada pelo classificador para um conjunto de dados. Em
vermelho tem-se a fun√ß√£o ùê∂ùëôùëñ treinada a partir do conjunto de dados
em azul. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

Figura 12 ‚ÄìHistograma mostrando a distribui√ß√£o de probabilidades de sa√≠da de
um classificador. Para o caso, a segunda classe, √© a que obteve maior
probabilidade, por√©m existe uma certa incerteza com rela√ß√£o a primeira
classe.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

Figura 13 ‚ÄìDiagrama geral da adi√ß√£o de contexto local utilizando Geoestat√≠stica.
Primeiramente √© medida a variabilidade entre as classes no contexto
espacial. Tanto diretamente atrav√©s das frequ√™ncias de transi√ß√£o na
imagem (taxa de transi√ß√£o medida), quanto atrav√©s da infer√™ncia de
propriedades estat√≠sticas vindas da imagem (taxa de transi√ß√£o mode-
lada). Em seguida s√£o calculados os vetores de transi√ß√£o. Na segunda
parte os vetores s√£o utilizados para gerar pesos para imagem. Com isso,
utilizando os pesos, o sistema SIS computa a adi√ß√£o de contexto local
para cada superpixel.

. . . . . . . . . . . . . . . . . . . . . . . . . . . 54

Figura 14 ‚ÄìMedida feita do n√∫mero de transi√ß√µes que uma classe faz para cada
outra para m√∫ltiplas dist√¢ncias. Foi utilizada um kernel m√≥vel e foram
contadas as transi√ß√µes desde o centro (ponto vermelho) para todas as
dire√ß√µes (representado pelos quadrados)

. . . . . . . . . . . . . . . . . 56

Figura 15 ‚ÄìA transi√ß√£o de probabilidade modelada para um determinado dataset.
O eixo y apresenta a dist√¢ncia em pixeis. As linhas verdes mostram
as propor√ß√µes para cada classe. Pode-se observar uma certa tend√™ncia
na classe Urchin em transitar para categoria de background. Ainda,
percebe-se que a classe de background tem um grande comprimento
m√©dio, dado que sua taxa de decaimento √© bastante alta.

. . . . . . . . 58

Figura 16 ‚ÄìExemplo de uma vizinhan√ßa sendo considerada para um superpixel (
apontado em vermelho). Um raio ùëü √© considerado e ùëÅ pontos s√£o amos-
trados nessa vizinhan√ßa ( em azul). Cada um dos pontos amostrados
ir√° influenciar no potencial do superpixel apontado em vermelho. . . . . 60

Figura 17 ‚ÄìRepresenta√ß√£o gr√°fica do modelo de Geoestat√≠stica (GS). Os fatores
locais s√£o representados em azul e usam a estat√≠stica de probabilidade
de transi√ß√£o computada pela Eq. 3.3. Diferentemente do que no modelo
da Fig. 7, vizinhos de diferentes dist√¢ncias tamb√©m contribuem para
calcular a distribui√ß√£o de cada posi√ß√£o.

. . . . . . . . . . . . . . . . . 61

Figura 18 ‚ÄìTr√™s trajet√≥rias da luz at√© o plano da imagem. O componente direto,
contendo a informa√ß√£o direta da cena. O forward-scattering, contendo
informa√ß√£o da cena espalhada. Por fim, o backscattering contendo in-
forma√ß√µes de fora da cena. . . . . . . . . . . . . . . . . . . . . . . . . . 64

Figura 19 ‚ÄìImagem de exemplo para as degrada√ß√µes do ambiente subaqu√°tico. √â
poss√≠vel ver que existe uma varia√ß√£o conforme a dist√¢ncia e uma perda
significativa da informa√ß√£o de cor. . . . . . . . . . . . . . . . . . . . . . 65
Figura 20 ‚ÄìA sequ√™ncia utilizada para classifica√ß√£o de imagens em meio subaqu√°tico. 66

Figura 21 ‚ÄìA cena criada para avaliar os algoritmos de avalia√ß√£o de features. Ela √©
composta por lampadas fluorescentes e uma camera fotografando fotos
impressas do assoalho do oceano.

. . . . . . . . . . . . . . . . . . . . . 72

Figura 22 ‚ÄìAs imagens utilizadas no teste. As tr√™s imagens foram capturadas nas
Bahamas em condi√ß√µes de turbidez pr√≥ximas do ideal em uma resolu√ß√£o
de 4928x3264 pixeis

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

Figura 23 ‚ÄìAs imagens capturadas sob diferentes n√≠veis de degrada√ß√£o devido a
turbidez, controlado pela adi√ß√£o de leite. Foram fotografadas tr√™s fotos
impressas diferentes, ùëÉ1 (primeira coluna), ùëÉ2 (segunda coluna) e ùëÉ3
(terceira coluna). Na primeira linha foi mostrada a imagem limpa (sem
leite) para cada foto capturada. A segunda linha apresenta o intervalo
de Baixa Turbidez com por volta de 15ml de leite (ùëá4). O intervalo de
M√©dia Turbidez √© mostrado na segunda linha e cont√©m por volta de 50
ml de leite (ùëá10). Finalmente, na ultima (quarta) linha √© mostrado o
intervalo com Alta turbidez tendo por volta de 100 ml de leite (ùëá16).
Quantidade de leite setada para uma caixa com 1000 litros de √°gua. . . 76

Figura 24 ‚ÄìRepetibilidade ( Taxa de Acerto) contra o indice de degrada√ß√£o estru-
tural normalizado (NSDI). As linhas em laranja indicam os intervalos
de degrada√ß√£o. Baixa Turbidez 0 at√© 0.25; M√©dia Turbidez, 0.25 at√©
0.75, e Alta Turbidez de 0.75 at√© 1.

. . . . . . . . . . . . . . . . . . . . 79

Figura 25 ‚ÄìCompara√ß√£o entre a gera√ß√£o de um n√≠vel do kernel do espa√ßo de escala
usado por quatro detectores diferentes. O kernel foi aplicado em n√≠veis
de turbidez diferentes para a imagem ùëÉ1. Sendo que a primeira linha √©
a imagem limpa (ùëá0), a segunda linha √© uma imagem com baixo n√≠vel
de degrada√ß√£o (ùëá4), a terceira linha apresenta uma imagem com m√©dio
n√≠vel de degrada√ß√£o (ùëá10), a quarta linha apresenta imagens do n√≠vel de
degrada√ß√£o alto (ùëá16). Para cada caso √© mostrado o resultado de filtro
equivalente a a aproximadamente um kernel gaussiano de ùúé = 59.0.
Primeira Coluna: Gaussiano puro. Segunda Coluna: Borramento apro-
ximado em caixas . Terceira Coluna: Difus√£o utilizando um pol√≠gono es-
trelar de seis pontas. Quarta Coluna: kernel anisotr√≥pico g2 do KAZE.
√â poss√≠vel ver de certa forma estruturas mais definidas para o esquema
de difus√£o usado pelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008). 81

Figura 26 ‚ÄìPartes manualmente segmentadas utilizadas para treinamento do clas-
sificador. A esquerda s√£o mostrados exemplos de nove amostras usadas
para treinar o dataset Redsea. A direita s√£o apresentadas nove amostras
do dataset Marker.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

Figura 27 ‚ÄìCurvas de confian√ßa geradas no treinamento un√°rio de cada classe para
o dataset Redsea. A curva de confian√ßa ùê∂ùëôùëñ treinada para cada uma das
classes √© mostrada, se bem como o grau de confian√ßa obtido.

. . . . . . 86

Figura 28 ‚ÄìCurvas de confian√ßa geradas no treinamento un√°rio de cada classe para
o dataset Marker. A curva de confian√ßa ùê∂ùëôùëñ treinada para cada uma das
classes √© apresentada, bem como o grau de confian√ßa obtido.

. . . . . . 87

Figura 29 ‚ÄìVetores de transi√ß√£o obtidos na etapa de treinamento para o m√©todo
de Geoestat√≠stica do Cap√≠tulo 3. Os vetores indicam a probabilidade de
uma classe transitar para outra a uma determinada dist√¢ncia. O eixo
x apresenta a dist√¢ncia em pixeis. O eixo ùë¶ dos gr√°ficos apresenta as
probabilidades de transi√ß√£o. Pode-se observar, por exemplo, uma certa
tend√™ncia na classe Urchin em transitar para categoria de background.

88

Figura 30 ‚ÄìMapa tem√°tico dos Mosaicos para o dataset Redsea. As figuras mostram
a porcentagem de acerto relativa ao GroundTruth. As classes s√£o repre-
sentadas pelas seguintes cores: Verde Brain Coral; Amarelo Branchin
Coral; Azul Faviid Coral; Magenta Urchin e sem cor √© o background.
Os seguintes resultados s√£o mostrados.(30a) classifica√ß√£o Un√°ria. (30b)
mostra a classifica√ß√£o Un√°ria baseada nas curvas de confian√ßa. (30c)
classifica√ß√£o com adi√ß√£o de contexto baseada em Geoestat√≠stica. (30d)
classifica√ß√£o com adi√ß√£o de contexto utilizando CRF.

. . . . . . . . . . 92

Figura 31 ‚ÄìMapa tem√°tico dos Mosaicos para o dataset Marker. As figuras mos-
tram a porcentagem de acerto relativa ao GroundTruth. As classes s√£o
representadas pelas seguintes cores: Verde Sand; Amarelo Sea Gorgon;
Azul Corals e sem cor √© o background. Os seguintes resultados s√£o
mostrados.(31a) classifica√ß√£o Un√°ria. (31b) mostra a classifica√ß√£o Un√°-
ria baseada nas curvas de confian√ßa. (31c) classifica√ß√£o com adi√ß√£o de
contexto baseada em Geoestat√≠stica. (31d) classifica√ß√£o com adi√ß√£o de
contexto utilizando CRF.

. . . . . . . . . . . . . . . . . . . . . . . . . 93

Figura 32 ‚ÄìResultados de classifica√ß√£o para os datasets Marker e os datasets Red-
sea. A primeira coluna apresenta a classifica√ß√£o unit√°ria. A segunda
coluna apresenta os resultados de Geoestat√≠stica. A terceira coluna
apresenta os resultados para o CRF. Por fim, a ultima coluna apre-
senta o GroundTruth. Foi utilizada como peso para o potencial local
ùë§ùëô como sendo 0.4 para ambas as abordagens. Na primeira coluna foi
poss√≠vel perceber um resultado melhor para o CRF devido a uma maior
suaviza√ß√£o local. Na segunda linha, o m√©todo de Geoestat√≠stica obteve
melhores resultados devido a suas medidas estat√≠sticas de longa dist√¢n-
cia. Na √∫ltima linha √© mostrado os resultados para o dataset Marker,
onde ambas as abordagens tiveram melhores resultados para esse caso.

94

Lista de tabelas

Tabela 1 ‚Äì A quantidade de leite adicionada para cada n√≠vel de turbidez simulado. 75

Tabela 2 ‚Äì Matriz de covari√¢ncia que mostra as rela√ß√µes de proximidade entre as
classes. Tais medidas s√£o fatores que indicam correla√ß√£o e n√£o distri-
bui√ß√µes de probabilidade. Este resultado √© normalizado ao final.

. . . . 86

Tabela 3 ‚Äì Matriz de covari√¢ncia que mostra as rela√ß√µes de proximidade entre as
classes. Tais medidas s√£o fatores que indicam correla√ß√£o e n√£o distri-
bui√ß√µes de probabilidade. Este resultado √© normalizado ao final.

. . . . 87

Tabela 4 ‚Äì Resultados para a taxa de acerto de diferentes segmentos para o data-
set Redsea. Foram testados diversos segmentos quadrados amostrados
aleatoreamente nos mosaicos. O tamanho do segmento √© especificado
pelo lado do quadrado . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

Sum√°rio

Introdu√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.1 Motiva√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
0.2 Detectores de Pontos de Interesse . . . . . . . . . . . . . . . . . . . . . . . 24
0.3 Classifica√ß√£o de Imagens do Assoalho Oce√¢nico . . . . . . . . . . . . . . . . 24
0.4 Sum√°rio desta Disserta√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

1

Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse . . . . . . . 27
1.1 Detectores de √önica Escala . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.1 Harris . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
1.1.2 Hessian e Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . 30
1.1.3 Compara√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
1.2 Detectores Invariantes a Escala . . . . . . . . . . . . . . . . . . . . . . . . 31
. . . . . . . . . . . . . . . . . . 32
1.2.1 Hessian-Laplace e Hessian-Laplace
1.2.2 Diference-of-Gaussians(DoG)
. . . . . . . . . . . . . . . . . . . . . 33
1.2.3 Fast Hessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
1.2.4 Center Surround Extrema Filters(CenSurE) . . . . . . . . . . . . . 35
1.2.5 KAZE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.2.6 Compara√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

2.2

2 Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de Imagens Utilizando Contexto . 39
2.1 Utiliza√ß√£o do Contexto em Vis√£o Computacional . . . . . . . . . . . . . . . 39
2.1.1 N√≠veis de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.1.2
Intera√ß√µes de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . 40
Integra√ß√£o de Contexto Na Classifica√ß√£o . . . . . . . . . . . . . . . . . . . 41
Integrando contexto com base em Classificadores . . . . . . . . . . 42
2.2.1
Integrando contexto com base em Modelos Probabil√≠sticos Gr√°ficos
2.2.2
42
2.2.2.1 O Problema da Infer√™ncia Estat√≠stica . . . . . . . . . . . . 44
2.2.2.2 Aprendizado de par√¢metros . . . . . . . . . . . . . . . . . 45
2.3 Trabalhos utilizando Modelos Probabil√≠sticos Gr√°ficos
. . . . . . . . . . . 45
2.4 Sum√°rio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

3 Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

. . . . . . . 49
3.1 Vis√£o Geral da Proposta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2 N√≠vel Un√°rio ùëÉùë¢(ùêø|ùúÉùë¢)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
Classificador
. . . . . . . . . . . . . . . . . . . 51
Treinando Curvas de Confian√ßa

3.2.1
3.2.2

3.4.1 Medindo Transi√ß√µes de Probabilidades

3.3 Distribui√ß√£o de Probabilidades . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.4 N√≠vel Local ùëÉùëô(ùêø|ùëä)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
. . . . . . . . . . . . . . . . 54
Taxa de Transi√ß√£o Medida ùëÖùëöùëíùë†
. . . . . . . . . . . . . . 55
3.4.1.1
3.4.1.2
Calculo da Matriz ùëÖùëöùëúùëë . . . . . . . . . . . . . . . . . . . 57
Sequential Indicator Simulation . . . . . . . . . . . . . . . . . . . . 58
. . . . . . . . . . . . . . . . . 59
3.5 Geoestat√≠stica e CRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.6 Sum√°rio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

3.4.2
3.4.3 Computando o Potencial Final ùëÉ(ùêø)

4 Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

. . . . . . . . . . . . . . . 63
4.1 Propriedades de Imagens Subaqu√°ticas . . . . . . . . . . . . . . . . . . . . 63
4.2 Classifica√ß√£o Aut√¥noma de Imagens do fundo Oce√¢nico . . . . . . . . . . . 66
4.2.1 Pr√©-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.1 Contraste . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2.1.2 Corre√ß√£o de Cor
. . . . . . . . . . . . . . . . . . . . . . . 68
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Segmenta√ß√£o
4.2.2
4.2.3 Descritores
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.2.4 Treinamento e Classifica√ß√£o . . . . . . . . . . . . . . . . . . . . . . 70
4.3 Conclus√µes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

5 Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente

Subaqu√°tico . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
5.1 Descri√ß√£o do experimento . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
5.1.1 Cena Montada
5.1.2 Procedimento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.2 Avaliando a degrada√ß√£o causada pela turbidez . . . . . . . . . . . . . . . . 75
5.3 Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.1 Procedimento de Avalia√ß√£o . . . . . . . . . . . . . . . . . . . . . . . 77
5.3.2 Compara√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

5.4 Conclus√µes finais

6 Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica . . . . . . . 83
6.1 Datasets Utilizados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2 Descri√ß√£o do Geral do Sistema . . . . . . . . . . . . . . . . . . . . . . . . 83
6.2.1 Pr√©-Processamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.2
. . . . . . . . . . . . . . . . . . . . . . . 84
6.2.3 Classifica√ß√£o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.2.4 Adi√ß√£o de Contexto . . . . . . . . . . . . . . . . . . . . . . . . . . 84
6.3 Treinamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84

Segmenta√ß√£o e Descri√ß√£o

. . . . . . . . . . . . . . . . . . . . . 84
6.3.1 Treinamento do Classificador
6.3.2 Treinamento Un√°rio
. . . . . . . . . . . . . . . . . . . . . . . . . . 85
6.3.3 Treinamento Potenciais Locais . . . . . . . . . . . . . . . . . . . . . 86
6.4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Sistemas Testados
6.5 Computa√ß√£o do Mapa Tem√°tico . . . . . . . . . . . . . . . . . . . . . . . . 90
6.6 Conclus√µes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

7 Conclus√µes Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1 Detectores de Pontos de Interesse em Imagens Subaqu√°ticas Turvas . . . . 95
7.1.1 Contribui√ß√µes Obtidas
. . . . . . . . . . . . . . . . . . . . . . . . . 95
7.1.2 Limita√ß√µes e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 95
7.2 Adi√ß√£o de Contexto Baseado em Geoestat√≠stica . . . . . . . . . . . . . . . 96
7.2.1 Contribui√ß√µes Obtidas
. . . . . . . . . . . . . . . . . . . . . . . . . 96
7.2.2 Limita√ß√µes e Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . 96

Refer√™ncias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97

Introdu√ß√£o

23

Este trabalho apresenta um estudo sobre t√©cnicas de vis√£o computacional consi-
derando os aspectos fotom√©tricos do meio subaqu√°tico. Dois pontos chaves no processo
s√£o analisados: A extra√ß√£o aut√¥noma de pontos de interesse; e a utiliza√ß√£o do contexto
espacial para a classifica√ß√£o.

0.1 Motiva√ß√£o

Vis√£o computacional √© a ci√™ncia que visa possibilitar √†s m√°quinas a capacidade de

interpreta√ß√£o e representa√ß√£o de informa√ß√µes visuais.

Com tal capacidade, diversas aplica√ß√µes podem ser ent√£o desenvolvidas, como: a
inspe√ß√£o industrial aut√¥noma , a reconstru√ß√£o de cenas em tr√™s dimens√µes, a localiza√ß√£o
de rob√¥s, a rotula√ß√£o ou classifica√ß√£o de objetos em imagens, entre outras. Tais aplica√ß√µes
podem ser implementadas nos mais diversos ambientes, desde o dom√≠nio industrial ou
dom√©stico, em ambientes fechados ou abertos, em localidades sobre a terra ou no fundo
do mar, etc.

Neste trabalho se d√° aten√ß√£o especial ao ambiente marinho, o qual, cobrindo em
torno de 70% da terra, e contendo cerca de 90% de sua biodiversidade, √© de evidente
import√¢ncia. O advento dos Remotely Operated Vehicles(ROV ) e dos Autonomous Un-
derwater Vehicles (AUVs), tem possibilitado a coleta de milhares de imagens para moni-
toramento do oceano, ampliando as possibilidades de aplica√ß√µes em vis√£o computacional
em ambientes subsea

Diversas das aplica√ß√µes para vis√£o computacional em terra podem ser facilmente
extrapoladas para utiliza√ß√£o no meio subaqu√°tico. Como exemplo, tem-se o caso da clas-
sifica√ß√£o aut√¥noma de imagens do assoalho oce√¢nico. Para tal aplica√ß√£o, tem-se o caso dos
recifes de corais, os quais desde 1980 sofrem de massivas perdas devido a polui√ß√£o, pesca
excessiva e esp√©cies invasivas (NEMETH et al., 2008). Uma classifica√ß√£o aut√¥noma √© fun-
damental, dada a grande √°rea monitorada e a necessidade de reduzir o tempo necess√°rio
de especialistas para se classificar as esp√©cies.

O monitoramento √© tamb√©m uma realidade que gera demanda para sistemas rob√≥-
ticos aut√¥nomos. Isso gera margem para utiliza√ß√£o de sistemas visuais nas mais diversas
aplica√ß√µes como: a localiza√ß√£o de rob√¥s subaqu√°ticos, a inspe√ß√£o e rastreio de risers e
flows na ind√∫stria de √≥leo e g√°s, entre outras.

Devido a dificuldade de desenvolvimento e instrumenta√ß√£o subsea, o uso de ROVs
e AUVs √© recente, implicando em uma limitada quantidade de estudos relacionados ao

24

Introdu√ß√£o

dom√≠nio da vis√£o computacional para o ambiente subaqu√°tico. Nesse ambiente existem
desafios espec√≠ficos que n√£o necessitam ser tratados em outros ambientes. A propaga√ß√£o da
luz em meio subaqu√°tico apresenta efeitos fotom√©tricos associados o que causa degrada√ß√£o
na forma√ß√£o da imagem. Efeitos como borramento, espalhamento da informa√ß√£o luminosa
e atenua√ß√£o de cor na imagem, s√£o alguns exemplos que precisam ser considerados em
aplica√ß√µes subaqu√°ticas

Al√©m disso, quando se trata das cenas capturadas em tais ambientes, a monotoni-
cidade do ambiente, dada pela falta de diversifica√ß√£o dos objetos e a falta de estruturas
geom√©tricas bem definidas, muito causada pela eros√£o, dificulta a interpreta√ß√£o visual, o
que por sua vez, acarreta no aumento da complexidade das aplica√ß√µes em vis√£o compu-
tacional.

Neste contexto, o objetivo deste trabalho √© analisar duas aplica√ß√µes fundamentais
para vis√£o computacional em meio subaqu√°tico: a detec√ß√£o de pontos de interesse e a
considera√ß√£o de contexto para classifica√ß√£o de grande extens√µes de mosaicos de imagens
do assoalho oce√¢nico.

0.2 Detectores de Pontos de Interesse

A detec√ß√£o de pontos de interesse √© de fundamental import√¢ncia para diversas
√°reas fundamentais de uso no meio subaqu√°tico, como a classifica√ß√£o de imagens (PAD-
MAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstru√ß√£o 3D (BEALL et al., 2010)
(NICOSEVICI et al., 2009), localiza√ß√£o de rob√¥s (AULINAS et al., 2011) , etc.

Este trabalho prop√µe um novo dataset de imagens subaqu√°ticas, o qual √© usado
para apontar os detectores de pontos de interesse mais adaptados ao meio subaqu√°tico. Tal
dataset deve ser capaz de isolar a degrada√ß√£o causada pelo comportamento da propaga√ß√£o
da luz em meio subaqu√°ticos como a principal fonte de degrada√ß√£o.

Ser√£o testados detectores, considerando diversos paradigmas para detec√ß√£o, com
respeito a sua robustez a degrada√ß√£o das imagens subaqu√°ticas. Um especial tratamento
ser√° dado aos detectores invariantes a escala por sua comprovada baixa performance neste
meio (GARCIA; GRACIAS, 2011).

0.3 Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

A outra aplica√ß√£o analisada diz respeito ao uso do contexto espacial, muito pouco
utilizado para classifica√ß√£o de imagens subaqu√°ticas e, de fundamental import√¢ncia, a
medida que grandes extens√µes passam a ser monitoradas.

Na classifica√ß√£o de grandes extens√µes de recifes de corais, por exemplo, √© natural

0.4. Sum√°rio desta Disserta√ß√£o

25

que as diferentes esp√©cies possam estar inseridas dentro de um contexto. A utiliza√ß√£o da
informa√ß√£o de contexto pode auxiliar a interpreta√ß√£o da cena (BAR, 2004). Assim, analisa-
se diversos algoritmos para a utiliza√ß√£o de contexto em situa√ß√µes e cen√°rios gen√©ricos.

Com isso, este trabalho tem como objetivo tamb√©m propor um novo algoritmo
para adi√ß√£o de contexto inspirado em Geoestat√≠stica, √°rea que modela a variabilidade de
grandezas no espa√ßo geom√©trico, de tal forma o m√©todo proposto seja capaz de mitigar a
falta de informa√ß√£o anotada no meio subaqu√°tico.

0.4 Sum√°rio desta Disserta√ß√£o

O Cap√≠tulo 1 apresenta a fundamenta√ß√£o te√≥rica sobre a detec√ß√£o de pontos de
interesse. Primeiramente, uma defini√ß√£o formal de pontos de interesse √© realizada e suas
principais caracter√≠sticas desejadas s√£o apontadas. S√£o apresentadas as defini√ß√µes dos
detectores Harris e Hessian, Harris-Laplace, Hessian-Laplace, Difference of Gaussians
(DoG), FastHessian, CenSurE e KAZE.

O Cap√≠tulo 2 apresenta o problema de classifica√ß√£o de imagens usando o contexto.
Uma defini√ß√£o de como representar as rela√ß√µes de contexto em uma imagem √© apresentado.
Em seguida √© feita uma revis√£o dos m√©todos de vis√£o computacional os quais incorporam
esses conceitos. Um destaque √© dado aos m√©todos que utilizam os Conditional Random
Field (CRF) para incorporar o contexto.

No Cap√≠tulo 3 √© apresentado um sistema de classifica√ß√£o de imagens baseado em
Geoestat√≠stica, a qual √© uma √°rea da estat√≠stica que busca modelar a variabilidade espacial
de uma determinada grandeza. Nesse cap√≠tulo √© proposta uma extens√£o deste conceito
para adi√ß√£o de informa√ß√£o de contexto na classifica√ß√£o de imagens.

O Cap√≠tulo 4 apresenta os problemas existentes na classifica√ß√£o de imagens su-
baqu√°ticas e tamb√©m, os aspectos especiais que existem para aplica√ß√µes em vis√£o su-
baqu√°tica. Tamb√©m se apresenta uma breve revis√£o dos resultados j√° obtidos na classifi-
ca√ß√£o de mosaicos do bentos sem utiliza√ß√£o do contexto e, tamb√©m, uma vis√£o geral do
sistema proposto por Shihavuddin et al. (2013) o qual foi usado como base para os testes
e resultados.

O Cap√≠tulo 5 apresenta um estudo sobre o comportamento dos detectores apresen-
tados no Cap√≠tulo 1 quanto a sua robustez √† degrada√ß√£o causada em imagens subaqu√°ticas.
√â especificado um experimento realizado para gera√ß√£o de diferentes n√≠veis de degrada√ß√£o
nas imagens. Por fim, s√£o apresentados os detectores mais adaptados ao meio.

O Cap√≠tulo 6 apresenta um estudo de caso da aplica√ß√£o de contexto para classifi-
ca√ß√£o no meio subaqu√°tico. Os resultados gerados para o novo m√©todo proposto baseado
em Geoestat√≠stica s√£o mostrados, e tamb√©m a sua compara√ß√£o com os demais m√©todos

26

Introdu√ß√£o

do estado da arte em adi√ß√£o de contexto.

Por fim, no Cap√≠tulo 7 as conclus√µes deste trabalho s√£o apresentadas.

1 Fundamenta√ß√£o Te√≥rica 1: Detectores de

Pontos de Interesse

27

Este cap√≠tulo apresenta a fundamenta√ß√£o te√≥rica sobre detectores de pontos de
interesse. Formalmente pontos de interesse s√£o definidos como um padr√£o de uma ima-
gem que difere de sua vizinhan√ßa imediata (TUYTELAARS; MIKOLAJCZYK, 2008).
Normalmente s√£o pontos com particularidades de uma imagem as quais possuem alguma
caracter√≠stica visual relevante. Vale notar que, apesar do termo utilizado ser "pontos de
interesse", n√£o √© utilizada a defini√ß√£o matem√°tica de um ponto infinitesimal sendo de-
finidos como pequenas regi√µes. Pontos de interesse servem como √¢ncoras de regi√µes da
imagem, determinando quais posi√ß√µes podem ser descritas para se ter uma representa√ß√£o
confi√°vel da mesma. Distintas aplica√ß√µes fazem uso dos pontos de interesse como: a clas-
sifica√ß√£o de imagens (PADMAVATHI; MUTHUKUMAR; THAKUR, 2010), reconstru√ß√£o
3D (BEALL et al., 2010) (NICOSEVICI et al., 2009), mapeamento e localiza√ß√£o (GIL et
al., 2010) , rastreio (CORKE et al., 2007), etc.

Um exemplo de pontos de interesse seriam as quinas, as quais s√£o respons√°veis
por boa parte do processo de interpreta√ß√£o visual de um objeto (TUYTELAARS; MIKO-
LAJCZYK, 2008). Muitas vezes, os pontos de interesse apresentam uma rela√ß√£o sem√¢ntica
mais estreita com a aplica√ß√£o. Por exemplo, ao classificar faces, as regi√µes do olho ou da
boca s√£o de grande interesse para a classifica√ß√£o.

A utiliza√ß√£o de pontos de interesse locais traz as seguintes vantagens, em contraste

com o uso do contexto geral da imagem:

‚àô Redu√ß√£o significativa do custo computacional;
‚àô Descarte de parte do ru√≠do presente na imagem pois somente os pontos relevantes

s√£o utilizados;

‚àô Obten√ß√£o e uso de apenas caracter√≠sticas mais distintas da imagem;
‚àô Possibilidade de reconhecimento de cenas sem a necessidade de segmenta√ß√£o.

Por√©m, para um ponto de interesse ser eficaz, a presen√ßa de algumas propriedades
s√£o de fundamental import√¢ncia (TUYTELAARS; MIKOLAJCZYK, 2008). Entre as mais
importantes tem-se:

‚àô Repetibilidade: Um ponto de interesse deve representar caracter√≠sticas que possam
ser encontradas em determinados objetos, independente da configura√ß√£o em que tal

28

Cap√≠tulo 1. Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse

objecto foi fotografado. Dado duas imagens de um mesmo objeto ou cena, o que foi
visto em ambas as cenas deve ser detectado como ponto de interesse em ambas as
cenas.

‚àô Distintividade: Um ponto de interesse deve representar caracter√≠sticas que sejam
distintas, com destaque sobre as demais caracter√≠sticas e que sejam especificas de
um determinado objeto. S√≥ assim este objeto pode ser descriminado com rela√ß√£o
aos demais.

A repetibilidade, de fato a propriedade mais importante (TUYTELAARS; MI-
KOLAJCZYK, 2008), pode ser atingida tendo os pontos de interesse sendo invariantes a
determinadas transforma√ß√µes que uma imagem pode sofrer, tais como:

‚àô Rota√ß√£o: Um ponto que pertence a uma cena, deve ser encontrado independente da

orienta√ß√£o que a cena foi capturada.

‚àô Transla√ß√£o: Se o ponto representa o mesma objeto, o mesmo deve ser encontrado

independente da posi√ß√£o na imagem onde ele foi capturado.

‚àô Escala: Independente da dist√¢ncia em que a cena foi capturada, o mesmo ponto

dever√° ser encontrado.

Para outras transforma√ß√µes que a imagem possa sofrer, muitas vezes √© interessante
que um ponto seja somente robusto. Ou seja, capaz de ser encontrado somente at√© um
determinado n√≠vel da transforma√ß√£o. Alguns efeitos, ou transforma√ß√µes, a se ter robustez
s√£o: efeitos de discretiza√ß√£o, artefatos causados por compress√£o, borramento devido a
movimento, ru√≠do branco, distor√ß√£o de perspectiva, etc.

Diversos algoritmos s√£o desenvolvidos para encontrar pontos os quais apresentam
as propriedades acima descritas. S√£o eles chamados os Detectores de Pontos de Interesse.
Os Detectores s√£o desenvolvidos de forma a terem um valor de retorno alto em rela√ß√£o a
certas estruturas presentes na imagens. Define-se estrutura como um determinado padr√£o
com respeito a varia√ß√£o de intensidade luminosa em uma regi√£o da imagem.

Divide-se os Detectores de Pontos de Interesse com respeito as determinadas pro-

priedades as quais os mesmos possuem invari√¢ncia.

Neste trabalho, selecionou-se nove detectores principais encontrados na bibliografia
a serem fundamentados. Primeiramente, na se√ß√£o 1.1, s√£o expostos os detectores capazes
de responder a estruturas possuindo invari√¢ncia a rota√ß√£o e transla√ß√£o. Tais detectores
s√£o chamados tamb√©m de detectores de √∫nica escala pois, n√£o possuindo invari√¢ncia a
escala, somente analisam a imagem em uma √∫nica escala.

1.1. Detectores de √önica Escala

29

Por fim, na se√ß√£o 1.2, s√£o apresentados detectores que convivem tamb√©m com a
invari√¢ncia a escala. Estes simulam m√∫ltiplas escalas de forma a encontrar pontos invari-
antes a escala. Tais detectores s√£o chamados de detectores de m√∫ltipla escala.

1.1 Detectores de √önica Escala

Os detectores apresentados nessa se√ß√£o possuem invari√¢ncia a transla√ß√£o ou rota-
√ß√£o, podendo possuir em algum n√≠vel, tamb√©m invari√¢ncia a escala. Os detectores apre-
sentados podem tamb√©m ter robustez a diversos tipos de ru√≠do.

Normalmente um detector √© implementado como uma fun√ß√£o, ou kernel, o qual √©
convoluida com a imagem e produz uma imagem de sa√≠da a qual apresenta o resultado
da aplica√ß√£o deste kernel.

Como j√° explicado, existem diversas caracter√≠sticas em uma imagem a serem bus-
cadas como pontos de interesse. Neste trabalho, tanto para o caso de √∫nica, como de
m√∫ltipla escala, seleciona-se caracter√≠sticas baseadas na alta curvatura de uma regi√£o,
calculada atrav√©s do gradiente da imagem. Duas estruturas s√£o escolhidas, quinas e blobs.
Ambas s√£o bastante utilizadas como pontos de interesse pelos detectores mais populares.
As quinas, s√£o estruturas que n√£o necessariamente representam uma quina de
fato. S√£o estruturas as quais possuem gradientes de alta intensidade em pelo menos duas
dire√ß√µes distintas.

Blobs s√£o definidos como regi√µes que s√£o diferentes em intensidade da regi√£o ao re-
dor. Normalmente s√£o associados com algum ponto de extremo na intensidade da imagem
(LINDEBERG; EKLUNDH, 1991).

1.1.1 Harris

O detector Harris (HARRIS; STEPHENS, 1988) √© um dos mais populares detec-
tores de quinas encontrados na literatura. Uma quina √© detectada quando existir varia√ß√£o
em duas dire√ß√µes principais de uma fun√ß√£o anal√≠tica de auto-correla√ß√£o na imagem. Tal
fun√ß√£o indica a varia√ß√£o de intensidade em todas as dire√ß√µes para uma imagem ùêº(ùë•, ùë¶) e
pode ser definida pela equa√ß√£o 1.1.

‚é°‚é£

ùëÄ = ùúé2

ùê∑ùëî(ùúéùêº) *

onde:

(1.1)

(1.2)

ùë•(ùë•, ùë¶, ùúéùê∑)
ùêº2

ùêºùë•(ùë•, ùúéùê∑)ùêºùë¶(ùë•, ùë¶, ùúéùê∑)

ùêºùë•(ùë•, ùë¶, ùúéùê∑)ùêºùë¶(ùë•, ùë¶, ùúéùê∑)

ùë¶(ùë•, ùë¶, ùúéùê∑)
ùêº2

‚é§‚é¶

ùêºùë•(ùë•, ùë¶, ùúéùê∑) = ùúï
ùúïùë•

ùëî(ùúéùê∑) * ùêº(ùë•, ùë¶)

30

Cap√≠tulo 1. Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse

e ùëî √© uma fun√ß√£o gaussiana definida por:

ùëî(ùúé) = 1

2ùúãùúé2 ùëí

‚àí ùë•2+ùë¶2
2ùúé2

(1.3)

A quina pode ser computada por uma an√°lise dos autovalores da matriz ùëÄ .
Quando os dois autovalores tiverem valores altos, isso indica a exist√™ncia de uma quina.
Uma maneira de medir a intensidade dos autovalores sem a necessidade de computar os
autovalores de ùëÄ diretamente, √© atrav√©s da medida de Harris dada por:

ùëêùëñùëõ = ùëëùëíùë°(ùëÄ) ‚àí ùëò ùë°ùëüùëéùëêùëú(ùëÄ),

(1.4)

onde ùëò √© uma constante normalmente setada entre 0.04 e 0.06. Quando a medida ùëêùëñùëõ da
Eq. 1.4 for alta, a presen√ßa de quinas tamb√©m o ser√° (HARRIS; STEPHENS, 1988). Um
ponto da imagem √© considerado uma quina, se a sa√≠da da aplica√ß√£o da Eq. 1.4 for maior
que um limiar ùë°.

Harris j√° foi avaliado como sendo o detector com melhor repetibilidade quando
comparado com outros detectores de √∫nica escala (SCHMID; MOHR; BAUCKHAGE,
2000).

1.1.2 Hessian e Laplacian

O detector Hessian, proposto inicialmente por (BEAUDET, 1978), √© um m√©todo
bastante usado para detec√ß√£o de blobs em imagens. Para uma imagem ùêº(ùë•, ùë¶), os blobs
podem ser calculado pelo determinante da matriz Hessiana:

‚é°‚é£ùêºùë•ùë•(ùë•, ùë¶, ùúéùê∑) ùêºùë•ùë¶(ùë•, ùë¶, ùúéùê∑)
‚é§‚é¶

ùêºùë•ùë¶(ùë•, ùë¶, ùúéùê∑) ùêºùë¶ùë¶(ùë•, ùë¶, ùúéùê∑)

ùêª =

(1.5)

O determinante responde aos gradientes em m√∫ltiplas dire√ß√µes da imagem e tende
a revelar blobs de alta curvatura, o que representa uma regi√£o distinta. O detector, deter-
minante de Hessian, ou simplesmente detector Hessian √© dado selecionando os pontos os
quais tem uma sa√≠da com respeito a matriz H maior que um valor de limiar ùë°.

Uma varia√ß√£o do Hessian √© a aplica√ß√£o de um kernel Laplacian o qual √© computado
pelo tra√ßo da matriz ùêª ( ùêºùë•ùë•+ùêºùë¶ùë¶). Por√©m o Laplacian tende tamb√©m a responder a bordas
(TUYTELAARS; MIKOLAJCZYK, 2008). Bordas n√£o s√£o bons pontos de interesse pois,
n√£o possuem uma aceit√°vel invari√¢ncia a rota√ß√£o (TUYTELAARS; MIKOLAJCZYK,
2008).

1.2. Detectores Invariantes a Escala

1.1.3 Compara√ß√£o

31

A Figura 1 mostra um exemplo de aplica√ß√£o do Hessian e Harris em uma imagem.
As blobs podem ser vistos como a √°rea mais elevada em morros de intensidade. As quinas
podem ser juntas "T"ou "L", tamb√©m podendo ter formato mais arredondado.

(a) Original

(b) Harris

(c) Hessian

Figura 1 ‚Äì Comportamento da aplica√ß√£o dos kernels Hessian e Harris para uma imagem
teste (1a). (1b) mostra a sa√≠da da medida de Harris (Eq. 1.4). (1c) mostra a sa√≠da do
determinante da matriz Hessian ( Eq. 1.5 ) para a imagem teste. Tanto o Hessian como
o Harris tem como sa√≠da as regi√µes de alta curvatura ( Figura por Sojka (2003)).

Percebe-se que h√° semelhan√ßa entre ambos, dado que ambos s√£o associados a

regi√µes de alto gradiente.

1.2 Detectores Invariantes a Escala

A no√ß√£o de escala √© crucial na interpreta√ß√£o de uma imagem (LINDEBERG, 1994).
Alguns objetos s√≥ s√£o entidades visuais significativas em uma determinada escala. Sendo
assim, uma modelagem explicita de cada n√≠vel de escala se torna necess√°rio para o pro-

32

Cap√≠tulo 1. Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse

cessamento (LINDEBERG, 1998). Ou seja, uma imagem n√£o mais pode ser representada
como uma matriz ùêº(ùë•, ùë¶) e passa a ter um terceiro componente de escala ùë†, sendo assim
determinada como a fun√ß√£o ùêø(ùë•, ùë¶, ùë†).

Para gerar o conjunto espa√ßos de escala ùêø(ùë•, ùë¶, ùë†), pode-se utilizar o princ√≠pio da
difus√£o (LINDEBERG, 1994). O qual determina que uma fam√≠lia de escalas ùêø pode ser
determinada atrav√©s da equa√ß√£o da difus√£o:

ùúïùúéùêø = 1

2 ‚ñΩ2 ùêø = 1

2(ùúïùë•ùë• + ùúïùë¶ùë¶)ùêø

(1.6)

O que representa o fato de que, √† medida que a escala se torna menos detalhada,

a informa√ß√£o visual tende a se dispersar.

Portanto, para a gera√ß√£o do espa√ßo de escala de uma imagem ùêø(ùë•, ùë¶, ùë†) deve ser
proposta uma equa√ß√£o que atenda a Equa√ß√£o 1.6. Inicialmente, foi adotado que a fun√ß√£o
gaussiana seria a √∫nica a ser uma solu√ß√£o da equa√ß√£o 1.6. Posteriormente, outras fun√ß√µes
foram colocadas como poss√≠veis para gera√ß√£o do espa√ßo de escala (LINDEBERG, 1997).
Considerando determinada uma escala ùë†, definida igual a um par√¢metro de difus√£o ùúé, a
gera√ß√£o de um espa√ßo de escala ùúé √© dada por:

ùêø(ùë•, ùë¶, ùúé) = ùëî(ùë•, ùë¶, ùúé) * ùêº(ùë•, ùë¶)

(1.7)

sendo a fun√ß√£o gaussiana ùëî(ùë•, ùë¶, ùúé) calculada como na Eq.1.3.

De forma a atingir a invari√¢ncia a escala, os detectores passam a considerar essa
fun√ß√£o ùêø(ùë•, ùë¶, ùúé) para se detectar os pontos de interesse. Por√©m, (LINDEBERG, 1994) de-
terminou que √© poss√≠vel realizar a escolha de uma escala, e tal escala ser√° sempre escolhida
independente do ambiente e sem a necessidade de escolha de par√¢metros. Caracterizando
uma escala onde existe invari√¢ncia.

Foi sugerido que os pontos de extremo de fun√ß√µes gradientes das estruturas en-
tre as escalas tem propriedades invariantes. Isso representa a escala com o m√°ximo de
sensibilidade a fun√ß√£o. Tal escala √© chamada de escala caracter√≠stica.

Nesta se√ß√£o apresentam-se alguns detectores invariantes a escala. A ideia de m√°-
ximo de uma determinada fun√ß√£o gradiente entre escalas √© usada por todos os m√©todos
apresentados.

1.2.1 Hessian-Laplace e Hessian-Laplace

Umas primeiras extens√µes para detectores de m√∫ltipla escala foram feitas para as
as fun√ß√µes Harris e Hessian (MIKOLAJCZYK; SCHMID, 2004) Nestes m√©todos, o espa√ßo

1.2. Detectores Invariantes a Escala

33

de escala √© gerado por uma equa√ß√£o gaussiana tal como na Eq. 1.7. Os pontos de extremo
entre um conjunto de escalas ùúéùëõ s√£o computados conforme a Eq. 1.8.

|ùêøùëúùê∫(ùë•, ùë¶, ùúéùëõ)| = ùúé2|ùêøùë•ùë•(ùë•, ùë¶, ùúéùëõ) + ùêøùë¶ùë¶(ùë•, ùë¶, ùúéùëõ)|

(1.8)

sendo a Eq. 1.8 uma representa√ß√£o da fun√ß√£o Laplacian em m√∫ltiplas escalas. Desta forma
, s√£o selecionados os pontos extremos que tem alta reposta a fun√ß√£o Harris, para o caso
do Harris-Laplace ou da fun√ß√£o Hessian para o caso do Hessian-Laplace.

1.2.2 Diference-of-Gaussians(DoG)

O detector DoG √© uma otimiza√ß√£o a aplica√ß√£o do Hessian-Laplace. √â o detector

proposto pelo m√©todo SIFT (LOWE, 2004).

Ao inv√©s de computar o Laplacian para cada escala, neste aplica-se o Laplacian
pela diferen√ßa, ùê∑(ùë•, ùë¶, ùúé), entre m√∫ltiplos n√≠veis do espa√ßo gaussiano ùêø(ùë•, ùë¶, ùúé). Sendo
assim:

ùê∑(ùë•, ùë¶, ùúé) = ùêø(ùë•, ùë¶, ùëòùúé) ‚àí ùêø(ùë•, ùë¶, ùúé)

(1.9)

Diversos n√≠veis de escala s√£o gerados. A cada determinado n√∫mero de imagens,
chamado oitava, √© feito um redimensionamento na imagem. Dentro de uma oitava, as
imagens diferentes s√£o criadas pela aplica√ß√£o do filtro gaussiano. A fun√ß√£o ùê∑ √© gerada a
partir da diferen√ßa entre n√≠veis vizinhos. O processo utilizado pelo algoritmo √© mostrado
na Figura 2.

Para se encontrar a escala caracter√≠stica, basta encontrar o m√°ximo na fun√ß√£o
ùê∑(ùë•, ùë¶, ùúé) variando ùúé. Ao final, os extremos do espa√ßo, os quais tem baixa resposta √†
fun√ß√£o Hessian s√£o eliminados.

1.2.3 Fast Hessian

Trata-se de um m√©todo que busca fazer uma otimiza√ß√£o ainda maior em rela√ß√£o ao
DoG para gera√ß√£o do espa√ßo de escala (BAY et al., 2008). Trata-se de um filtro que n√£o usa
o filtro gaussiano para gera√ß√£o do espa√ßo de escala . Os filtros gaussianos s√£o aproximados
por filtros caixas. Um filtro caixa basicamente computa a m√©dia de uma imagem dado
uma janela de convolu√ß√£o, podendo ser computado rapidamente pela utiliza√ß√£o de Imagens
Integrais (DERPANIS; LEUNG; SIZINTSEV, 2007).

√â poss√≠vel neste caso fazer a abordagem de diferen√ßa de caixas, o que permite
juntar a aplica√ß√£o do filtro Hessian com a gera√ß√£o do espa√ßo de escala. Uma aproxima√ß√£o
do Hessian j√° √© computada diretamente ao se aplicar as diferen√ßas de caixas.

34

Cap√≠tulo 1. Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse

Figura 2 ‚Äì O processo para gera√ß√£o do espa√ßo de escala pelo DoG. Ao inv√©s de computar o
Laplacian para cada escala, o mesmo √© estimado pela diferen√ßa entre escalas consecutivas.
Figura adaptada de (LOWE, 2004).

Para um determinado tamanho de caixa de aresta ùëÅ, a resposta do Hessian √© dada

por:

ùëëùëíùë°(ùêªùëéùëùùëùùëüùëúùë•) = ùê∑ùë•ùë•ùê∑ùë¶ùë¶ ‚àí (0.9ùê∑ùë•ùë¶)2

(1.10)

A Figura 22 mostra um exemplo de filtros ùê∑ùë•ùë• e ùê∑ùë•ùë¶ que s√£o aplicados. Enquanto
aplicar a diferen√ßa entre caixas, produz o Hessian, a computa√ß√£o em blocos aplica a
difus√£o na imagem.

(a) ùê∑ùë•ùë•

(b) ùê∑ùë•ùë¶

Figura 3 ‚Äì Exemplo de um filtro caixa de tamanho 9x9 aplicado para gera√ß√£o de um
espa√ßo de escala equivalente a ùúé = 1.2. Outros espa√ßos podem ser gerados usando caixas
maiores.

Para relacionar com o espa√ßo gaussiano, basta saber que uma imagem de filtro
gaussiano ùúé = 1.2 √© equivalente a utiliza√ß√£o de um filtro caixa 9x9. Ent√£o, para gera√ß√£o

1.2. Detectores Invariantes a Escala

35

do espa√ßo de escala basta gerar a resposta de v√°rios tamanhos de caixa ùëÅ = 9, 11, 13..
etc.

Para encontrar os pontos caracter√≠sticos basta encontrar o m√°ximo para todos os

n√≠veis de escala.

1.2.4 Center Surround Extrema Filters(CenSurE)

O Filtro de centro e arredores (AGRAWAL; KONOLIGE; BLAS, 2008) tem uma
abordagem similar a utilizada pelo detector Fast Hessian, por√©m realizando a diferen√ßa
entre m√∫ltiplos n√≠veis como no caso do DoG. Este processo visa tamb√©m uma aproxima√ß√£o
do Laplacian. Os espa√ßos de escala s√£o criados pela gera√ß√£o de pol√≠gonos de m√∫ltiplos
tamanhos. Tal como o filtro caixa, um filtro poligonal representa a media atrav√©s de uma
janela de convolu√ß√£o.

De maneira similar ao FastHessian, um filtro de pol√≠gono lado ùëÅ = 2 √© equivalente
a um espa√ßo gaussiano de ùúé = 1.88 A Figura 4 mostra alguns tipos de pol√≠gonos usados
para gerar o espa√ßo de escala. Os pol√≠gonos podem ter estruturas estreladas, poligonais,
entre outras.

(a) Estrela

(b) Hex√°gono

(c) Quadrado

Figura 4 ‚Äì Alguns tipos de filtros utilizados para gera√ß√£o do espa√ßo de escala pelo Cen-
SurE. O filtro estrela, o filtro hexagonal e o filtro por diferen√ßa de caixas.

Para gerar o Laplacian uma imagem a qual teve aplicada um filtro maior √© sub-

tra√≠da de uma imagem com um pol√≠gono menor aplicado.

O m√°ximo deste espa√ßo gerado √© encontrado como pontos de interesse.
Por fim uma fun√ß√£o Harris √© aplicada, eliminando os pontos que obtiveram baixa
resposta. Isso segue, pelo fato do Harris ter sido determinado como uma fun√ß√£o com
melhor repetibilidade.

1.2.5 KAZE

A ideia do KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) √© gerar um
espa√ßo de escala suavizando de maneira diferente em locais com alta intensidade de bordas.
Tal abordagem trata-se de uma difus√£o n√£o linear.

Cap√≠tulo 1. Fundamenta√ß√£o Te√≥rica 1: Detectores de Pontos de Interesse

A gera√ß√£o do espa√ßo de escala √© dada pela solu√ß√£o para equa√ß√£o da difus√£o n√£o

36

linear:

= ùëëùëñùë£(ùëê(ùë•, ùë¶, ùë°) ‚ñΩ ùêø),

ùúïùêø
ùúïùë°

(1.11)

Abordagens que aplicam uma difus√£o n√£o linear podem obter resultados melhores
para o caso da segmenta√ß√£o de imagens e remo√ß√£o de ru√≠do (WEICKERT; ROMENY;
VIERGEVER, 1998).

A ideia principal √© que, durante a forma√ß√£o da escala, as bordas das estruturas
devem se manter mais do que de fato acontece com o filtro gaussiano. Desta forma,
primeiramente uma fun√ß√£o ‚ñΩùêº que responde as bordas √© aplicada. Sendo ‚ñΩùêº basicamente
um gradiente da imagem. Com base nessa sa√≠da, uma defini√ß√£o alternativa da fun√ß√£o
gaussiana √© aplicada para gera√ß√£o do espa√ßo de escala . Perona e Malik (1990), descreveram
algumas poss√≠veis formula√ß√µes de fun√ß√µes:
ùëê1 = ùëíùë•ùëù(| ‚ñΩ ùêºùúé|2
ùëò2

), ùëê2 = ùëíùë•ùëù(

(1.12)

1

)

1 + |‚ñΩùêºùúé|2
ùëò2

sendo k um par√¢metro que controla o n√≠vel de difus√£o. Alcantarilla, Bartoli e Davison
(2012) prop√¥s uma terceira formula√ß√£o de kernel:

‚éß‚é®‚é©

ùëê3 =

1
1 ‚àí ùëíùë•ùëù(
(|‚ñΩùêºùúé|/ùëò)8 )

3.315

,| ‚ñΩ ùêºùúé|2 = 0
,| ‚ñΩ ùêºùúé|2 > 0

(1.13)

Levando em conta os kernels definidos, cada n√≠vel do espa√ßo de escala ùêøùëò(ùë•, ùë¶, ùë°)

√© gerado pela aplica√ß√£o da seguinte fun√ß√£o recursiva:

ùêøùëò(ùë•, ùë¶, ùë° + 1) = (ùêº ‚àí (ùë°ùëñ + 1 ‚àí ùë°ùëñ).ùëê(ùë•, ùë¶, ùë°) * ùêøùëò(ùë•, ùë¶, ùë°))‚àí1ùêøùëò(ùë•, ùë¶, ùë°)

(1.14)

onde ùë° √© um par√¢metro de escala temporal facilmente relacionado a ùúé. Ao final, tamb√©m
s√£o desconsideradas as regi√µes que tem baixa resposta a aplica√ß√£o de uma matriz Hessian.

1.2.6 Compara√ß√£o

A Figura 5 apresenta exemplos de gera√ß√£o do espa√ßo de escala baseado em 4
fun√ß√µes diferentes. O gaussiano, utilizado pelo DoG, Harris-Laplace e Hessian-Laplace, a
fun√ß√£o de caixas utilizada pelo FastHessian, uma fun√ß√£o poligonal estrelar de seis lados,
utilizadas pelo CenSurE e a fun√ß√£o de difus√£o anisotr√≥pica utilizado pelo KAZE.

Pode-se perceber que determinadas estruturas se mantem mais que outras para
espa√ßos diferentes. Claramente algumas aplica√ß√µes se beneficiariam do uso de um espa√ßo
de escala diferente. No Cap√≠tulo 5 se estudam os melhores detectores para o campo de
estudo de imagens subaqu√°ticas com presen√ßa de turbidez.

1.2. Detectores Invariantes a Escala

37

ùúé = 3.6

ùúé = 3.6

ùúé = 3.6

ùúé = 3.6

ùúé = 11.6

ùúé = 11.6

ùúé = 11.6

ùúé = 11.6

ùúé = 27.6

ùúé = 27.6

ùúé = 27.6

ùúé = 28.7

ùúé = 59.6

ùúé = 59.6

ùúé = 59.6

ùúé = 57.6

Figura 5 ‚Äì Espa√ßos de escala gerados. Primeira coluna mostra o espa√ßo Gaussiano. Se-
gunda coluna mostra o filtro m√©dia de caixas usado pelo FastHessian. Terceira coluna
mostra um filtro poligonal estrelar de seis lados. A quarta Coluna mostra o espa√ßo de
escala anisotr√≥pico usado pelo KAZE.

2 Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de

Imagens Utilizando Contexto

39

Este cap√≠tulo apresenta a fundamenta√ß√£o te√≥rica utilizada neste trabalho associada
a utiliza√ß√£o de contexto para a classifica√ß√£o de imagens. Inicialmente s√£o postuladas as
defini√ß√µes de como representar as rela√ß√µes de contexto em uma imagem. Tamb√©m √© feita
a defini√ß√£o de classifica√ß√£o de imagens incorporando o conceito de contexto, bem como
uma revis√£o dos m√©todos de vis√£o computacional que os tratam s√£o apresentados. Um
destaque √© dado aos m√©todos que utilizam os Conditional Random Field (CRF).

2.1 Utiliza√ß√£o do Contexto em Vis√£o Computacional

Existem diversos descritores capazes de discriminar os objetos com base em suas
caracter√≠sticas visuais, como textura, cor e forma. Tais caracter√≠sticas buscam capturar a
variabilidade dos objetos para sua classifica√ß√£o (GALLEGUILLOS; BELONGIE, 2010).
Por√©m, estudos envolvendo o sistema perceptivo visual humano trazem novas perspectivas
no que tange a como as t√≠picas configura√ß√µes dos objetos em uma cena podem contribuir
para a percep√ß√£o, de tal forma que o reconhecimento de objetos no sistema visual humano
considera n√£o somente os aspectos locais referentes a interpreta√ß√£o da cena, mas tamb√©m
a situa√ß√£o geral onde um objeto foi encontrado.

Biederman (BIEDERMAN; MEZZANOTTE; RABINOWITZ, 1982) estabelece al-
guns tipos de rela√ß√µes contextuais importantes que s√£o fundamentais para o reconheci-
mento de objetos no sistema visual humano. Estas rela√ß√µes estabelecem n√≠veis sem√¢nticos
tais como: i suporte (onde os objetos tendem a sustentar ou ser sustentados por outros),
interposi√ß√£o (relativo a rela√ß√µes de oclus√£o), ii probabilidade (objetos tendem a aparecer
na mesma situa√ß√£o), iii posi√ß√£o (objetos tendem a ficar em determinada posi√ß√£o relativa
com outros) e iv tamanho (objetos tendem a ter certo tamanho se comparado com outros
em uma dada escala).

V√°rios modelos computacionais j√° fizeram uso destas rela√ß√µes sem√¢nticas as quais
podem ser usadas para classificar objetos. Essas rela√ß√µes normalmente s√£o resumidas em
tr√™s tipos de contexto principais: sem√¢ntico, posi√ß√£o e escala.

O contexto sem√¢ntico, tende a incluir as rela√ß√µes de ocorr√™ncia entre objetos. Ao
encontrar um determinado objeto em uma cena, o qual se possui certeza de sua pre-
sen√ßa, considera-se uma maior probabilidade de presen√ßa de outros objetos. Por exemplo,
a exist√™ncia de um bule de ch√° implica em uma maior probabilidade de exist√™ncia de

40

Cap√≠tulo 2. Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de Imagens Utilizando Contexto

outros utens√≠lios de cozinha como talheres ou um fog√£o (FISCHLER; ELSCHLAGER,
1973) (HANSON; RISEMAN, 1978). Como exemplo, Rabinovich et al. (2007), incorpo-
rou a informa√ß√£o anotada pelos Google Sets indicando objetos que tendem a aparecer em
situa√ß√µes semelhantes de forma a melhorar a classifica√ß√£o.

O contexto de posi√ß√£o indica que os objetos tendem a ter uma rela√ß√£o espacial
na imagem. Como por exemplo, o c√©u em uma imagem tende a estar acima do ch√£o.
J√° o contexto de escala esta associado as rela√ß√µes de tamanho entre objetos na cena
(TORRALBA, 2003) (KUMAR; HEBERT, 2005) (TORRALBA; MURPHY; FREEMAN,
2004). Pois, existe j√°, uma rela√ß√£o de tamanho t√≠pica que os objetos possuem entre eles
(GALLEGUILLOS; BELONGIE, 2010).

Para incluir tais tipos de contexto na classifica√ß√£o de imagens, alguns aspectos
fundamentais devem ser considerados. Primeiramente, qual n√≠vel de contexto ser√° clas-
sificado. Se as rela√ß√µes a serem consideradas ser√£o apenas entre objetos pr√≥ximos, ou
no dom√≠nio geral de uma imagem. Ou ainda, por meio de que tipo de estrutura visual
encontrada na imagem, a intera√ß√£o de contexto ocorre.

2.1.1 N√≠veis de Contexto

Os sistemas que adicionam contexto na classifica√ß√£o normalmente dividem o con-

texto em dois n√≠veis (GALLEGUILLOS; BELONGIE, 2010): local e global.

O contexto local √© onde somente as intera√ß√µes de vizinhan√ßa s√£o utilizadas para
adicionar o contexto a um determinado objeto. O contexto local est√° relacionado aos
objetos que cercam outros objetos. Vale notar que a aplica√ß√£o de contexto √© recursiva, ou
seja, a pr√≥pria vizinhan√ßa possu√≠ tamb√©m suas pr√≥prias rela√ß√µes de contexto. Isso faz que
n√£o somente as rela√ß√µes estritamente pr√≥ximas fa√ßam parte do contexto local.

O contexto global est√° relacionado as intera√ß√µes de contexto presentes ao longo
de toda a imagem utilizada. O contexto global normalmente est√° associado ao ambiente
onde os objetos est√£o posicionados. Por exemplo, se as rela√ß√µes contextuais indicam que os
objetos est√£o em uma cozinha, isso implica em uma alta probabilidade de um dos objetos
ser uma panela.

2.1.2 Intera√ß√µes de Contexto

N√£o necessariamente cada componente da imagem deve ser um objeto com um
conceito sem√¢ntico relacionado. Na literatura se estabelecem tr√™s n√≠veis b√°sicos de inte-
ra√ß√£o nos quais o contexto pode ser integrado (GALLEGUILLOS; BELONGIE, 2010).
Al√©m de objetos, as intera√ß√µes tamb√©m se d√£o entre pixeis ou regi√µes.

A intera√ß√£o em n√≠vel de pixel estabelece que pixeis vizinhos tendem a ter a mesma
classe. Tais intera√ß√µes ajudam a inferir as bordas existentes na imagem. Vale notar a

2.2.

Integra√ß√£o de Contexto Na Classifica√ß√£o

41

utiliza√ß√£o de tais intera√ß√µes s√£o mais computacionalmente intensas, dado que existem
diversas combina√ß√µes entre pixeis da imagem. Ressalta-se que o uso de n√≠veis mais baixos
de contexto n√£o necessariamente implica na perda da informa√ß√£o sem√¢ntica. Ou seja,
encontrar que pixeis de determinado objeto s√£o pr√≥ximos, √© tamb√©m identificar a alta
probabilidade de proximidade de tais objetos.

O conceito de pixel pode ser estendido para o n√≠vel de representa√ß√£o de regi√µes. Ao
utilizar regi√µes, tende-se a reduzir a complexidade levantada pelo grande n√∫mero de pixeis
existentes na imagem. Uma estrutura de regi√£o bastante utilizada √© a considera√ß√£o de pe-
quenas regi√µes adaptadas a estrutura local da imagem. Tais regi√µes chamadas, superpixeis,
capturam a redund√¢ncia dos dados, facilitando a utiliza√ß√£o do contexto (FULKERSON;
VEDALDI; SOATTO, 2009).

J√° a intera√ß√£o em n√≠vel de objetos √© a representa√ß√£o mais natural para reconhe-
cimento de contexto humano (BAR, 2004). Sabendo-se j√° a classe do objeto √© poss√≠vel
treinar as rela√ß√µes de contexto. No trabalho de (TORRALBA; MURPHY; FREEMAN,
2004), os objetos mais f√°ceis de classificar ajudam, atrav√©s do contexto, a obter a classe de
objetos mais dif√≠ceis. Se por um lado usar objetos tende a capturar melhor as intera√ß√µes
existentes na cena, o uso do contexto em n√≠vel de objetos implica j√° o conhecimento pr√©-
vio ( classifica√ß√£o) dos objetos existentes na imagem. A intera√ß√£o entre regi√µes, por outro
lado, ajuda a reduzir a quantidade de combina√ß√µes existentes na intera√ß√£o de pixeis, sem a
necessidade de um conhecimento maior sobre a imagem (GALLEGUILLOS; BELONGIE,
2010).

2.2 Integra√ß√£o de Contexto Na Classifica√ß√£o

Nesta se√ß√£o s√£o apresentadas algumas abordagens para integra√ß√£o do contexto na
classifica√ß√£o de imagens. S√£o escolhidos m√©todos com integra√ß√£o baseada em superpixeis,
com foco para integra√ß√£o local de contexto. Quanto aos tipos de contexto, por considerar
o n√≠vel de intera√ß√£o como superpixeis, os principais tipos integrados s√£o os de posi√ß√£o e
escala.

Dado a representa√ß√£o da imagem como uma matriz ùëÜùëÉ(ùë•, ùë¶) onde cada elemento
ùë†ùëù √© um superpixel, a defini√ß√£o de classifica√ß√£o √© dada pela determina√ß√£o de um r√≥tulo
ùëôùëñ dentre um conjunto poss√≠vel de r√≥tulos ùêø = ùëô1, ùëô2, ...ùëôùëõ para cada ùë†ùëù. Para classifica√ß√µes
sem contexto, apenas o superpixel ùë†ùëù √© considerado, j√° para o caso apresentado nesta
se√ß√£o, a vizinhan√ßa de ùë†ùëù √© tamb√©m importante para determinar um r√≥tulo ùëôùëñ.

Nesta se√ß√£o s√£o especificadas duas formas de incorporar o contexto. Utilizando
a vizinhan√ßa de um superpixel ùë†ùëù diretamente no classificador ou atrav√©s de modelos
probabil√≠sticos gr√°ficos (MPGs).

42

Cap√≠tulo 2. Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de Imagens Utilizando Contexto

2.2.1

Integrando contexto com base em Classificadores

As informa√ß√µes locais advindas de uma an√°lise de contexto podem ser incorporadas
diretamente aos sistemas de classifica√ß√£o, considerando uma janela de contexto em torno
da regi√£o a ser classificada (Figura 6)

Fink e Perona (2003) incorporou o contexto local usando a janela da regi√£o para

treinamento de classificador fracos em um esquema de boosting.

Kruppa e Schiele (2003), visando melhorar a classifica√ß√£o de rostos, incorporou a

descri√ß√£o dos descritores da vizinhan√ßa local da face em um sistema Naive Bayes

O principal problema √© que tais aplica√ß√µes n√£o levam em conta as poss√≠veis corre-
la√ß√µes entre os vizinhos. Este problema √© demonstrado na Figura 6, a vizinhan√ßa s√≥ afeta
o que foi considerado no centro da imagem, sem afetar a si pr√≥pria. Tais problemas s√£o
parcialmente resolvidos criando-se intera√ß√µes mais conectadas, como no caso dos modelos
probabil√≠sticos gr√°ficos a serem explicados na pr√≥xima se√ß√£o.

(a)

(b)

Figura 6 ‚Äì Janela considerada para a classifica√ß√£o usando contexto. No caso da integra√ß√£o
de contexto diretamente nos classificadores (Fig. 6a), n√£o s√£o considerada as rela√ß√µes entre
a vizinhan√ßa com si pr√≥pria (Fig. 6b). Ou seja, se existem propriedades correlacionadas
na vizinhan√ßa.

2.2.2

Integrando contexto com base em Modelos Probabil√≠sticos Gr√°ficos

Nesta se√ß√£o, ser√£o apresentados os principais conceitos associados aos Modelos
Probabil√≠sticos Gr√°ficos (MPGs) e seu uso na integra√ß√£o contextual em classifica√ß√£o de
imagens.

Uma forma natural de representar a depend√™ncia entre vari√°veis √© utilizando os
Modelos Probabilisticos Gr√°ficos (MPGs)(SUTTON; MCCALLUM, 2006). Estes mode-
los representam algumas fatoriza√ß√µes de uma fun√ß√£o de probabilidades como o Markov
Random Fields MRF ou Conditional Random Fields CRF.

2.2.

Integra√ß√£o de Contexto Na Classifica√ß√£o

43

Um MPG √© usado para capturar a correla√ß√µes existentes dentro de um conjunto de
dados. Baseado neste modelo, √© poss√≠vel calcular uma fun√ß√£o potencial. Esta abordagem,
quando baseada em modelos probabil√≠sticos n√£o direcionadas, √© usada no MRF e no CRF
(SUTTON; MCCALLUM, 2006).

O MRF modela a fun√ß√£o de probabilidade ùëù(ùë¶, ùë•) de um dado conjunto de r√≥tulos
ùë¶ e os conjunto de descritores de entrada ùë•. Esse modelo necessita um alto custo compu-
tacional para classifica√ß√£o de imagens (CARBONETTO; FREITAS; BARNARD, 2004).
Ainda, dado que deve seguir a premissa de Markov, nenhuma caracter√≠stica global deve
ser adicionada. Paro caso de Markov, a computa√ß√£o de ùëù(ùë¶, ùë•) necessita a computa√ß√£o
de ùëù(ùë¶) e tamb√©m ùëù(ùë•), o qual n√£o se tem conhecimento sobre, pois est√° relacionado a
probabilidade das descri√ß√µes de entrada aparecerem.

Uma abordagem mais comumente utilizada para classifica√ß√£o de imagens √© o mo-
delo CRF. Neste modelo, somente a distribui√ß√£o condicional, ùëù(ùë¶|ùë•) , √© computada. Nor-
malmente o CRF tem uma melhor associa√ß√£o aos dados, dado que n√£o √© necess√°rio com-
putar a probabilidade a priori para os dados de entrada (ùëù(ùë•)) (SUTTON; MCCALLUM,
2006).

Considerando um dado modelo, √© definida a probabilidade para um conjunto de
r√≥tulos serem atribu√≠dos . Esta probabilidade √© estabelecida como uma fun√ß√£o de um fator
unit√°rio e um fator local. Deste modo, define-se a probabilidade de uma imagem possuir
um certo conjunto de r√≥tulos ùêø = ùëô1, ùëô2, ...ùëôùëõ dado um grafo de um modelo ùê∫ e um conjunto
de par√¢metros ùúÉùë¢ e ùúÉùëô como a Eq. 2.1.

ùëôùëúùëîùëÉ(ùêø|ùê∫, ùúÉ) = ùë§ùë¢

ùë¢‚àëÔ∏Å

ùë•ùëñùúñùëã

ùëñ (ùë•ùëñ, ùúÉùë¢) + ùë§ùëô
ùúôùë¢

ùúñ‚àëÔ∏Å

(ùë•ùëñ,ùë•ùëó)ùúñùúÄ

ùëñùëó(ùë•ùëñ, ùë•ùëó, ùúÉùëô)
ùúôùêø

(2.1)

onde ùëã √© um conjunto de v√©rtices no modelo probabil√≠stico gr√°fico, cada um relacionado
a um superpixel da imagem e ùúÄ √© o conjunto de arestas no grafo de adjac√™ncia ùê∫(ùëã, ùúÄ).
ùëñ (ùë•ùëñ, ùúÉùë¢) √© a distribui√ß√£o de probabilidades a priori de um r√≥tulo, para este caso, o con-
ùúôùë¢
junto de par√¢metros ùúÉùë¢ esta associado com o treinamento da gera√ß√£o da distribui√ß√£o a
priori . ùúôùêø
ùëñ (ùë•ùëñ, ùúÉùëô) √© o fator local associado com a probabilidade de duas classes serem
vizinhas uma da outra. Neste caso, o par√¢metro ùúÉùëô est√° associado as matrizes de covari-
√¢ncia, treinadas para indicar a probabilidades proximidade entre os r√≥tulos do conjuntos
ùêø = ùëô1, ùëô2, ...ùëôùëõ considerando sua conex√£o ùê∫.

Os pesos ùë§ùë¢ e ùë§ùëô facilitam a calibra√ß√£o emp√≠rica do modelo, determinando a im-
port√¢ncia de cada termo na Eq. 2.1. A Figura 7, mostra uma representa√ß√£o visual de
parte da modelagem usando CRF para a aplica√ß√£o de interesse que √© a classifica√ß√£o e
segmenta√ß√£o de imagens.

No modelo CRF tamb√©m √© poss√≠vel incluir diferentes aspectos baseado em proprie-

44

Cap√≠tulo 2. Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de Imagens Utilizando Contexto

Figura 7 ‚Äì A representa√ß√£o gr√°fica de um modelo CRF. Os quadrados em vermelho
(ùúôùë¢
ùëñ (ùë•ùëñ, ùúÉùë¢)) s√£o os fatores unit√°rios calculados com o resultado dado pelo classificador.
Os quadrados em azul s√£o os fatores locais computados em cada aresta e utilizados para
introduzir informa√ß√£o contextual. Os circulos verdes representam os superpixeis sendo
classificados.

dades da imagem. A fun√ß√£o de bordas de Potts (SHOTTON et al., 2009) (FULKERSON;
VEDALDI; SOATTO, 2009) refor√ßa nodos que n√£o s√£o separados por bordas a perten-
cerem a mesma classe. Isto √© implementado incluindo o atributo ùëîùëñùëó em ùúôùêø
ùëñ . Onde ùëîùëñùëó √©
definido pela Eq. 2.2.

‚é°‚é£ùëíùë•ùëù(‚àíùõΩ||ùë•ùëñ ‚àí ùë•ùëó||2)

‚é§‚é¶

(2.2)

ùëîùëñùëó =

1

Onde ùõΩ √© uma fun√ß√£o de contraste dependente da imagem que pode ser facilmente esti-
mada como explicado em (SHOTTON et al., 2009).

2.2.2.1 O Problema da Infer√™ncia Estat√≠stica

Dado um modelo probabil√≠stico gr√°fico e uma fun√ß√£o de probabilidades, uma das
principais dificuldades √© encontrar um conjunto de r√≥tulos ùêø‚Ä≤ que maximize uma fun√ß√£o
de probabilidades como a fun√ß√£o da Eq. 2.1. Em outras palavras, seria encontrar a con-
figura√ß√£o de classifica√ß√£o na imagem mais prov√°vel, dado um modelo probabil√≠stico. Este
problema √© considerado NP-Hard, dado que existe uma combina√ß√£o de r√≥tulos exponen-
cialmente grande. O problema de infer√™ncia √© especialmente dif√≠cil quando se utiliza a
abordagem MRF, dado que existem muito mais casos para computar a distribui√ß√£o de
probabilidades conjunta.

Algumas aproxima√ß√µes s√£o introduzidas de forma reduzir o custo computacional.

2.3. Trabalhos utilizando Modelos Probabil√≠sticos Gr√°ficos

45

Por exemplo, a abordagem loopy belief propagation (LBP) propaga as informa√ß√µes de dis-
tribui√ß√£o de probabilidades dos v√©rtices ao longo do grafo atrav√©s de mensagens e obtem
boa performance (WEISS, 2000), entretanto, a converg√™ncia n√£o pode ser garantida. Ou-
tra estrat√©gia √© o corte de grafos baseado no alpha-cut (BOYKOV; JOLLY, 2001). Este
algoritmo produz melhores resultados apesar de possuir maior complexidade.

2.2.2.2 Aprendizado de par√¢metros

√â necess√°rio estimar os par√¢metros ùúÉùë¢ and ùúÉùëô. Estes par√¢metros s√£o a matriz de
covari√¢ncia que representa as tend√™ncias das classes serem vizinhas (ùúÉùëô), a matriz ùúÉùëô esta
associada √†s rela√ß√µes espaciais entre as classes.

Os par√¢metros podem ser estimados utilizando a t√©cnica de m√°ximo a-posteriori
(MAP). Esta t√©cnica seleciona os par√¢metros que maximizam os resultados para a Eq.
2.1. Isto √© custoso, dado que existe a necessidade de computar a infer√™ncia diversas vezes.
Por√©m, √© poss√≠vel realizar a estimativa, parte a parte, dividindo os par√¢metros os quais
maximizar (SHOTTON et al., 2009), ent√£o reduzindo o custo computacional.

A Figura 10 mostra um exemplo de uma matriz de covari√¢ncia estimada, sendo
quanto mais claro for o quadrado mais relacionadas espacialmente as classes est√£o. √â
poss√≠vel perceber que a classe B tem uma probabilidade muito maior de ficar pr√≥xima ao
C mas n√£o necessariamente a classe E.

2.3 Trabalhos utilizando Modelos Probabil√≠sticos Gr√°ficos

Diversos trabalhos j√° utilizaram os modelos probabl√≠stico gr√°ficos (MPGs) para
adi√ß√£o de contexto. Apresenta-se aqui alguns relevantes para elabora√ß√£o deste trabalho.
Carbonetto, Freitas e Barnard (2004) foi um dos primeiros trabalhos a usar MPGs
para classifica√ß√£o de imagens . O autor utilizou uma vers√£o usando um modelo MRF com
o contexto local e prop√¥s uma forma de reduzir o tempo de infer√™ncia usando uma t√©cnica
de expectation maximization (EM) (DEMPSTER; LAIRD; RUBIN, 1977).

Shotton et al. (2009) utilizou uma combina√ß√£o de descritores diretamente dos
descritores de textura, cor e localiza√ß√£o como fatores un√°rios e adicionou a informa√ß√£o
de contexto local usando a medida de potts. O n√≠vel de intera√ß√£o foi baseado em regi√µes
utilizando um novo esquema de representa√ß√£o de imagens atrav√©s "canais de textura". A
infer√™ncia foi feita utilizando o algoritmo de alpha-cut (BOYKOV; JOLLY, 2001).

Fulkerson, Vedaldi e Soatto (2009), utiliza uma representa√ß√£o usando SIFT (LOWE,
2004) para bag-of-words (SIVIC; ZISSERMAN, 2006) para o fator un√°rio. Como n√≠vel de
intera√ß√£o, foram utilizadas regi√µes baseadas em superpixeis. Em seguida, aplica-se um
sistema CRF similar ao proposto por (SHOTTON et al., 2009).

46

Cap√≠tulo 2. Fundamenta√ß√£o Te√≥rica 2: Classifica√ß√£o de Imagens Utilizando Contexto

Figura 8 ‚Äì Tend√™ncias que existem para as classes estarem pr√≥ximas umas das outras,
quanto mais claro, maior √© a tend√™ncia existente. Por exemplo, √© poss√≠vel perceber que a
classe B √© prov√°vel de aparecer perto de uma classe C mas n√£o pr√≥xima de uma classe E.

Koltun e Vladlen (2011), utiliza um CRF com uma maior conectividade entre os
v√©rtices e utiliza um n√≠vel de intera√ß√£o por pixel. Neste caso, dado o conjunto de pixeis,
cada par poss√≠vel de pixeis √© conectado. O aumento da complexidade de infer√™ncia √©
resolvido com um sistema aproximado baseado em m√©dias.

Boix et al. (2012) prop√µem adicionar o contexto global ao CRF. Para isso, a

Equa√ß√£o 2.1 pode ser extendida para a Eq. 2.3.

ùëôùëúùëîùëÉ(ùêø|ùê∫, ùúÉ) = ùë§ùë¢

ùë¢‚àëÔ∏Å

ùëñ (ùë•ùëñ, ùúÉùë¢) + ùë§ùëô
ùúôùë¢

ùúñ‚àëÔ∏Å

ùë•ùëñùúñùëã

(ùë•ùëñ,ùë•ùëó)ùúñùúÄ

ùúñ‚àëÔ∏Å

(ùë•ùëñ,ùë•ùëî) ùúÄùëî

onde a por√ß√£o ùúôùê∫

(2.3)
ùëñùëî(ùë•ùëñ, ùë•ùëî, ùúÉùëî) representa as conex√µes com um nodo global que, tendo esti-

ùëñùëó(ùë•ùëñ, ùë•ùëó, ùúÉùëô) + ùë§ùëî
ùúôùêø

ùëñùëî(ùë•ùëñ, ùë•ùëî, ùúÉùëî)
ùúôùê∫

2.4. Sum√°rio

47

mado seu conjunto de par√¢metros ùúÉùëî, indica as configura√ß√µes mais prov√°veis entre todas
as por√ß√µes da imagem. Com tal modelo, as rela√ß√µes de contexto global, como o conjunto
t√≠pico de objetos poss√≠veis em cena, podem ser incorporadas.

Por fim, Lucchi et al. (2011) critica o funcionamento do CRF, comparando a
utiliza√ß√£o do CRF com pontos de interesse globais (BOIX et al., 2012), concluindo que
n√£o h√° ganho significativo. Al√©m disso, o contexto local adicionado pelo CRF a tende
apenas melhorar a suaviza√ß√£o da classifica√ß√£o local. Ou seja, dado uma pequena regi√£o
da imagem, as variabilidade de classes √© reduzida.

2.4 Sum√°rio

Este cap√≠tulo apresentou os conceitos de utiliza√ß√£o de contexto para vis√£o compu-
tacional. Apresentou-se em quais n√≠veis o contexto pode ser utilizado, sendo eles globais
ou locais. Tamb√©m foi apresentado quais n√≠veis de intera√ß√£o o contexto podem se dar,
sendo eles no n√≠vel de pixeis, regi√µes ou objetos.

Nesse √¢mbito, formalizou-se a classifica√ß√£o utilizando contexto, considerando o
n√≠vel de intera√ß√£o baseado em regi√µes, no caso, superpixeis. Em seguida, foram apresen-
tadas formas de utilizar o contexto. Primeiramente foram apresentadas formas de aplicar
o contexto diretamente no classificador. Em seguida, foi apresentado o uso de modelos
probabil√≠sticos gr√°ficos para a aplica√ß√£o de contexto.

Por fim, alguns dos principais trabalhos em modelos probabil√≠sticos gr√°ficos foram

apresentados.

3 Classifica√ß√£o Baseada em Contexto utili-

zando Geoestat√≠stica

49

Tendo em vista as limita√ß√µes existentes no CRF (LUCCHI et al., 2011) e o conhe-
cimento obtido atrav√©s de estudos em Geoestat√≠stica, neste cap√≠tulo, busca-se propor um
novo m√©todo para adi√ß√£o de contexto baseado em Geoestat√≠stica.

Tal abordagem agrega duas √°reas com aplica√ß√µes distintas mas conceitos seme-
lhantes. No campo da modelagem geol√≥gica, uma abordagem baseada em geostat√≠stica
primeiramente busca modelar a variabilidade espacial de uma determinada medida com
o objetivo de interpolar este comportamento para √°reas desconhecidas (CARLE; FOGG,
1996). Esta estrat√©gia √© bastante utilizada para aplica√ß√µes como modelagem de reservat√≥-
rios em campos de de extra√ß√£o √≥leo (BEATTIE; MILLS; MAYO, 1998) ou mapeamento
geol√≥gico (PURKIS; VLASWINKEL; GRACIAS, 2012).

Por√©m, neste trabalho busca-se tamb√©m mostrar que este conceito se aplica para
o caso de adi√ß√£o de contexto classifica√ß√£o de imagens. A abordagem apresentada √© capaz
de assegurar a suaviza√ß√£o de estruturas espaciais de maneira similar que o CRF, por√©m,
o m√©todo proposto, tamb√©m considera correla√ß√µes em longa dist√¢ncia entre r√≥tulos.

3.1

Vis√£o Geral da Proposta

A Equa√ß√£o 3.1 apresenta a adi√ß√£o do contexto espacial utilizando Geoestat√≠stica:

ùëÉ(ùêø) = ùë§ùë¢ùëÉùë¢(ùêø|ùúÉùë¢) + ùë§ùëôùëÉùëô(ùêø|ùëä),

(3.1)

sabe-se que a probabilidade, ùëÉ de um dado conjunto de r√≥tulos ùêø, √© dada pela soma
ponderada, pelos pesos ùë§ùë¢ e ùë§ùëô, das probabilidades un√°ria ùëÉùë¢(ùêø|ùúÉùë¢), da parte segmentada,
e a probabilidade do contexto local ùëÉùëô(ùêø|ùëä). A matriz W est√° associada ao peso atribu√≠do
aos superpixeis da vizinhan√ßa. ùúÉùë¢ est√° associado aos par√¢metros de usados para obten√ß√£o
da distribui√ß√£o un√°ria.

Como n√≠vel de intera√ß√£o, parte-se de uma segmenta√ß√£o baseada em superpixeis
em um grid retangular e uniforme onde cada superpixel tem aproximadamente o mesmo
tamanho. O sistema de classifica√ß√£o proposto neste cap√≠tulo, √© mostrado na Figura 10.
Nesta proposta, o n√≠vel de intera√ß√£o, em uma imagem segmentada ocorre atrav√©s de
Turbopixels (LEVINSHTEIN et al., 2009).

No n√≠vel un√°rio ùëÉùë¢(ùêø|ùúÉùë¢), somente as informa√ß√µes visuais descritas de um √∫nico

50

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

Figura 9 ‚Äì Divis√£o especificada em dois n√≠veis de classifica√ß√£o. O n√≠vel un√°rio ùëÉùë¢(ùêø|ùúÉùë¢)
onde somente a informa√ß√£o do superpixel segmentado √© utilizada, apresentado em verde.
E o n√≠vel local ùëÉùëô(ùêø|ùëä), onde um determinado contexto local √© inclu√≠do na classifica√ß√£o,
representado pelo circulo azul.

superpixel s√£o relevantes para a classifica√ß√£o do mesmo. Na se√ß√£o 3.2, mostra-se a compu-
ta√ß√£o do n√≠vel un√°rio e a necessidade do mesmo de produzir uma distribui√ß√£o confi√°vel.
No n√≠vel local ùëÉùëô(ùêø|ùëä), se considera as conex√µes de uma determinada √°rea onde
medidas estat√≠sticas s√£o utilizadas (Circulo Azul Fig. 10). O n√≠vel ùëÉùëô(ùêø|ùëä) √© apresentado
na se√ß√£o 3.4.

3.2 N√≠vel Un√°rio ùëÉùë¢(ùêø|ùúÉùë¢)

Para o sistema proposto, o foco da classifica√ß√£o un√°ria √© obter uma distribui√ß√£o
de probabilidades previa para cada superpixel. Essa probabilidade a priori vai ser usada
para inferir a vizinhan√ßa.

Em um dado superpixel o qual pode ser classificado como um dentre um conjunto
onde ‚àëÔ∏Ä ùëÉùë¢(ùêø|ùúÉùë¢) = 1. Onde ùúÉùë¢ √© conjunto de par√¢metros usados para se ter essa sa√≠da.
de r√≥tulos ùêø = ùëô1, ùëô2..ùëôùëõ busca-se obter uma sa√≠da ùëÉùë¢(ùêø|ùúÉùë¢) = ùëÉùë¢(ùëô1|ùúÉùë¢), ùëÉùë¢(ùëô2|ùúÉùë¢)...ùëÉùë¢(ùëôùëõ|ùúÉùë¢)

Para se chegar em tal resultado, a gera√ß√£o do n√≠vel un√°rio √© dividida em duas
etapas. A primeira corresponde ao treinamento da fun√ß√£o de discrimina√ß√£o ùëì(ùë•), do clas-
sificador. No caso, √© feito o treinamento de um kernel linear para uma Support Vector
Machine (SVM). A segunda etapa √© a determina√ß√£o das curvas de confian√ßa, que corres-
ponde ao grau de certeza da classifica√ß√£o. Ou seja, o grau de certeza ùê∂ùëôùëñ √© dado como uma

3.2. N√≠vel Un√°rio ùëÉùë¢(ùêø|ùúÉùë¢)

51

fun√ß√£o treinada, e √© usado para gerar ùëÉùë¢(ùêø|ùúÉùë¢) (ABFALG et al., 2007).

3.2.1

Classificador

Como classificador, foi utilizado uma Support Vector Machine(SVM) com um ker-
nel linear. A ideia do algoritmo √© encontrar uma fun√ß√£o de hiperplano ùëìùëôùëñ(ùë•), para cada
classe ùëôùëñ que separa linearmente um conjunto de dados previamente rotulados, por√©m
maximizando uma determinada margem. Trata-se de uma abordagem de classifica√ß√£o
supervisionada.

Para dada aplica√ß√£o √© necess√°rio que o classificador produza uma dist√¢ncia de um
objeto √† borda de classe mais pr√≥xima a borda entre classes (ABFALG et al., 2007). Tal
resultado √© obtido diretamente pelo SVM dado que sua fun√ß√£o de hiperplano j√° maximiza
a margem entre classes. A sa√≠do num√©rica do SVM j√° √© pr√≥pria para se ter um certo grau
de confian√ßa do classificador.

Figura 10 ‚Äì Figura do separador linear obtido pelo treinamento do SVM. Dado os conjun-
tos de dados j√° rotulados ( Azuis e Vermelhos), o SVM determina o separador de m√°xima
margem. A sa√≠do num√©rica do SVM j√° √© pr√≥pria para se ter um certo grau de confian√ßa
do classificador.

3.2.2 Treinando Curvas de Confian√ßa

Somente as dist√¢ncias de sa√≠da do SVM (CRISTIANINI; SHAWE-TAYLOR, 2000),
n√£o estabelecem diretamente o grau de confian√ßa de uma classifica√ß√£o (ABFALG et al.,
2007) . Ou seja, uma dist√¢ncia de valor n√∫mero 5 para o SVM pode ser para alguns casos
uma sa√≠da confi√°vel, para outros n√£o. √â necess√°rio treinar para quais dist√¢ncias existe uma

52

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

grande probabilidade da predi√ß√£o ser correta. Isso depende do dataset que foi utilizado,
da classe (r√≥tulo) e tamb√©m do classificador.

O estudo apresentado por Platt (PLATT, 1999) demonstra que comportamento

sigmoidal pode modelar a distribui√ß√£o de probabilidade do SVM.

Sendo assim, para cada classe ùëôùëñ √© feito um ajuste de uma fun√ß√£o sigmoidal ùê∂ùëôùëñ. Esta
fun√ß√£o ùê∂ùëôùëñ n√£o mais retorna uma dist√¢ncia e sim uma probabilidade de uma determinada
entrada na fun√ß√£o ùëìùëôùëñ(ùë•) ser correta.

A Figura 11 apresenta a sa√≠da esperada para a curva de confian√ßa treinada ùê∂ùëôùëñ,
para um dado r√≥tulo ùëôùëñ. Dado um conjunto de valida√ß√£o em que j√° se possui os retornos
ùëìùëôùëñ(ùë•), o treinamento √© feito da seguinte forma: Obt√©m-se os pontos em azul os quais
indicam a porcentagem de acertos que se tem utilizando apenas as parcelas de dados
as quais seu retorno vindo do classificador (ùëìùëôùëñ(ùë•)) √© de no m√°ximo o que √© mostrado
no eixo ùë•. Por exemplo, na Figura 11, para um conjunto de dados com uma dist√¢ncia
do classificador(ùëìùëôùëñ(ùë•)) de at√© dois, tem-se uma porcentagem de acerto de 70%. Dado
esse conjunto de pontos, o algoritmo de Levenberg-Marquardt (MARQUARDT, 1963) de
otimiza√ß√£o √© utilizado para encontrar os coeficientes, ùõºùëò e ùõΩùëò da fun√ß√£o sigmoidal:

ùê∂ùëôùëñ = ùëÅùëôùëñ

0.5

1 + ùëíùë•ùëù(ùõºùëôùëñ * ùëìùëôùëñ(ùë•) + ùõΩùëôùëñ) + 0.5

(3.2)

onde ùëÅùëôùëñ √© uma constante de normaliza√ß√£o para a classe ùëôùëñ. A fun√ß√£o inicia de 0.5 pois √©
a probabilidade inicial de uma classe ser acertada aleatoriamente. A abordagem proposta
contrasta com a proposta apresentada por ABfalg et al. (2007) por propor uma curva de
confian√ßa para cada classe. Isso tamb√©m leva em conta as diferen√ßas existentes em cada
classe. ùúÉùë¢ est√° relacionado aos par√¢metros ùõºùëò e ùõΩùëò de ùëÉùë¢(ùêø|ùúÉùë¢).

Figura 11 ‚Äì Gr√°fico mostrando a probabilidade de acerto em fun√ß√£o da m√°xima confian√ßa
retornada pelo classificador para um conjunto de dados. Em vermelho tem-se a fun√ß√£o
ùê∂ùëôùëñ treinada a partir do conjunto de dados em azul.

3.3. Distribui√ß√£o de Probabilidades
3.3 Distribui√ß√£o de Probabilidades

53

Normalizando o grau de confian√ßa para a dist√¢ncia com rela√ß√£o a todas as classes,
se obt√©m a distribui√ß√£o de probabilidades para um determinado objeto. Sendo assim, um
classificador n√£o mais produz somente uma sa√≠da, mas tamb√©m uma chance de cada item
de um conjunto de dados a pertencer a cada uma das classes. A Figura 12 mostra a sa√≠da
da classifica√ß√£o de um exemplo calculado. Sendo que cada barra representa a chance do
objeto pertencer a tal classe.

Figura 12 ‚Äì Histograma mostrando a distribui√ß√£o de probabilidades de sa√≠da de um clas-
sificador. Para o caso, a segunda classe, √© a que obteve maior probabilidade, por√©m existe
uma certa incerteza com rela√ß√£o a primeira classe.

Observa-se na Figura 12 que a sa√≠da do classificador mostra a classe mais prov√°vel

mas existe uma incerteza significativa para uma segunda classe ser a correta.

3.4 N√≠vel Local ùëÉùëô(ùêø|ùëä)

A Figura 13 mostra o conjunto de passos para calcular os parcelas locais utilizando

o contexto baseado em Geoestat√≠stica.

A primeira parte do m√©todo (lado direito da Figura 13) √© estimar e modelar a
incerteza existente nos conjunto de dados os quais se quer adicionar o contexto. Essa mo-
delagem se da atrav√©s da estimativa da matriz de probabilidade de transi√ß√£o (ùëá) entre os
poss√≠veis r√≥tulos presentes no conjunto de dados. Isso √© feito em uma etapa de treinamento
offline do m√©todo A estimativa √© feita em duas partes que s√£o combinadas: analisando
as frequ√™ncias de transi√ß√µes entre as classes de um conjunto de imagens (CARLE et al.,
1998) e medindo propriedades estat√≠sticas nos dados como propor√ß√µes e espessuras.

54

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

Figura 13 ‚Äì Diagrama geral da adi√ß√£o de contexto local utilizando Geoestat√≠stica. Primei-
ramente √© medida a variabilidade entre as classes no contexto espacial. Tanto diretamente
atrav√©s das frequ√™ncias de transi√ß√£o na imagem (taxa de transi√ß√£o medida), quanto atrav√©s
da infer√™ncia de propriedades estat√≠sticas vindas da imagem (taxa de transi√ß√£o modelada).
Em seguida s√£o calculados os vetores de transi√ß√£o. Na segunda parte os vetores s√£o utiliza-
dos para gerar pesos para imagem. Com isso, utilizando os pesos, o sistema SIS computa
a adi√ß√£o de contexto local para cada superpixel.

A segunda parte do m√©todo √© a gera√ß√£o do contexto local ùëÉùëô(ùêø|ùëä). Deste modo,
para cada superpixel que se deseja computar, a matriz de probabilidades de transi√ß√£o
√© usada para computar os pesos ùëä, para servir como entrada em um sistema de SIS,
Sequential Indicator Simulation (Indicador de simula√ß√£o sequencial) (EMERY, 2004) o
qual computa ùëÉùëô(ùêø|ùëä). Cada um dos processos apontados na Figura 13 s√£o detalhados
no restante desta se√ß√£o.

3.4.1 Medindo Transi√ß√µes de Probabilidades

Primeiramente, um sistema de transi√ß√£o de probabilidades baseado em cadeias de
Markov √© medido. Este modelo representa a variabilidade espacial existente juntamente
com os dados da imagem.

A estrategia proposta √© calcular uma matriz ùëá, onde cada componente √© a fun√ß√£o
ùë°ùëñùëó(‚Ñéùúë) a qual modela a probabilidade de uma classe ùëñ de transitar para a classe ùëó em
uma dist√¢ncia ‚Ñé considerando a dire√ß√£o ùúë. √â necess√°rio obter tal medida para cada par
de classes ùëñ e ùëó presente no conjunto de dados.

Neste m√©todo, assume-se que os dados s√£o isom√≥rficos. Portanto, para uma dada
transi√ß√£o, todas as dire√ß√µes s√£o consideradas como id√™nticas. N√£o obstante, a abordagem
pode ser utilizada em casos n√£o isom√≥rficos, considerando duas ou mais dire√ß√µes, cada
uma com sua pr√≥pria matriz de probabilidade de transi√ß√µes.

Foi assumido que a transi√ß√£o de probabilidades tem um comportamento exponen-

3.4. N√≠vel Local ùëÉùëô(ùêø|ùëä)

55

cial, como proposto por (CARLE et al., 1998). As equa√ß√£o 3.3 mostra como calcular a
transi√ß√£o de probabilidades entre classes diferentes e tamb√©m para a mesma classe ( auto
transi√ß√£o).

ùë°ùëñùëó =

ùë°ùëñùëó = ùëùùëó ‚àí ùëí‚àíùëüùëñùëó ‚Ñéùúë [ùëñ Ã∏= ùëó]

se [ùëñ = ùëó]
se [ùëñ Ã∏= ùëó]

(3.3)

A fun√ß√£o de transi√ß√£o na Equa√ß√£o 3.3 tamb√©m depende da dist√¢ncia ‚Ñé e da probabilidade
a priori da classe ùëùùëó. Cada fator ùëüùëñùëó √© um componente da matriz ùëÖ Essa matriz √© a taxa
de transi√ß√£o entre as classes, para ùëò classes, ùëÖ pode ser calculada como:

‚éß‚é™‚é®‚é™‚é©ùë°ùëñùëó = ùëíùëüùëñùëó ‚Ñéùúë + ùëùùëñ [ùëñ = ùëó]
‚é°‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£

... ùëü1ùëñ
.
.
.
ùëüùëóùëñ
.
.
... ùëüùëòùëñ

ùëü11
.
ùëüùëó1
.
ùëüùëò1

ùëÖ =

‚é§‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶

... ùëü1ùëò
.
.
.
ùëüùëóùëò
.
.
... ùëüùëòùëò

(3.4)

Cada elemento da matriz representa a taxa na qual ocorre a transi√ß√£o, sendo assim:

ùëüùëñùëó = ùúïùë°ùëñùëñ(0))

ùúï‚Ñé

(3.5)

A matriz ùëá n√£o pode ser diretamente calculada a partir dos dados (AGTERBERG,
1988). Para tal, primeiramente, √© necessario estimar a matriz ùëÖ. Carle et al. (1998),
prop√µem obter o calculo de ùëÖ atrav√©s da multiplica√ß√£o elemento a elemento das medidas
da correla√ß√£o entre as configura√ß√µes espaciais diretas (ùëÖùëöùëíùë†) e da medida de conceitos
estat√≠sticos (ùëÖùëöùëúùëë) extra√≠dos das imagens:

ùëÖ = ùëÖùëöùëíùë† * ùëÖùëöùëúùëë.

(3.6)

Esta foi a t√©cnica adotada neste trabalho para calcular ùëÖ, por√©m com algumas
modifica√ß√µes. Na se√ß√£o a seguir, mostra-se o processo para calcular as matrizes ùëÖùëöùëíùë† e
ùëÖùëöùëúùëë.

3.4.1.1 Taxa de Transi√ß√£o Medida ùëÖùëöùëíùë†

ùëÖùëöùëíùë† √© calculado medindo a frequ√™ncia de transi√ß√£o cumulativa da matriz ùêπ. Para
computar ùêπ, foi somado o n√∫mero de vezes que cada classe transita para cada outra classe.
Foi considerado um conjunto de dire√ß√µes e um conjunto de dist√¢ncias ‚Ñé. Tal treinamento √©
feito em um conjunto de imagens j√° previamente classificadas. Este processo √© apresentado
na Figura 14. Foi utilizado um kernel de janela deslizante que iterativamente se desloca
ao longo de toda a imagem.

56

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

Para cada posi√ß√£o do kernel, foram contadas todas as transi√ß√µes que o r√≥tulo do
ponto central do kernel faz. Isto √© feito para diversas dist√¢ncias, o qual √© representado
pelos quadrados coloridos da Fig. 14. Ao final, cada linha de ùêπ √© normalizada.

Figura 14 ‚Äì Medida feita do n√∫mero de transi√ß√µes que uma classe faz para cada outra
para m√∫ltiplas dist√¢ncias. Foi utilizada um kernel m√≥vel e foram contadas as transi√ß√µes
desde o centro (ponto vermelho) para todas as dire√ß√µes (representado pelos quadrados)

A equa√ß√£o 3.7 mostra um exemplo da matriz ùêπ feitas para um "dataset‚Äù exemplo.

‚é°‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£

ùêπ =

0.762 0.007 0.037 0.060 0.132
0.639 0.066 0.048 0.061 0.184
0.607 0.010 0.214 0.052 0.115
0.594 0.006 0.032 0.261 0.104
0.642 0.010 0.036 0.054 0.255

‚é§‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶

(3.7)

(3.9)

A matriz estimada ùêπ √© afetada pelas incertezas nas premissas de probabilidade
assumidas. Por exemplo, a premissa do isomorfismo assumida n√£o √© perfeitamente verda-
deira. Para reduzir o efeito das incertezas e encontrar um padr√£o na representa√ß√£o, uma
an√°lise de autovetores e autovalores √© aplicada na Eq. 3.7 (CARLE; FOGG, 1996).

A partir disso, √© poss√≠vel computar ùëÖùëöùëíùë† aplicando a equa√ß√£o 3.8.

ùêø‚àëÔ∏Å

ùëò=1

ùëÖùëöùëíùë† =

ùúÉùëòùëçùëò

(3.8)

onde o termo ùúÉùëò de ùëò = 1, ..., ùêø denota os autovalores de F e ùëçùëò denota os componentes
espectrais das matrizes desde a analise de auto-vetores. Foi calculado ùëçùëò como mostrado
na Eq. 3.9.

‚àèÔ∏Ä
‚àèÔ∏Ä
ùëöÃ∏=ùëò(ùúÉùëòùêº ‚àí ùêπ)
ùëöÃ∏=ùëò(ùúÉùëö ‚àí ùúÉùëò) ùëò = 1, ..., ùêø

ùëçùëò =

Esta computa√ß√£o consiste em uma medida inicial que congrega as tend√™ncias de
verossimilhan√ßa espacial entre as classes. Contudo, esta medida ainda cont√©m muita im-

3.4. N√≠vel Local ùëÉùëô(ùêø|ùëä)

57

precis√£o para ser usada como entrada para a simula√ß√£o. A medida pode ser ainda mais
estabilizada adicionando a computa√ß√£o de ùëÖùëöùëúùëë assim como mostrado na Eq. 3.6.

3.4.1.2

Calculo da Matriz ùëÖùëöùëúùëë

Computa-se ùëÖùëöùëúùëë utilizando estat√≠sticas extra√≠da dos dados, como: propor√ß√µes das

classes, comprimentos m√©dios das classes e as tend√™ncias de justaposi√ß√£o.

A propor√ß√£o de uma classe ùëôùëñ √© a probabilidade a priori desta classe aparecer. Em
outras palavras, a propor√ß√£o √© a chance de selecionar uma parcela da classe ùëôùëñ aleatoria-
mente da imagem classificada (CARLE; FOGG, 1996).

O comprimento m√©dio √© calculado pela quantidade m√©dia de pixeis cont√≠nuos de
uma certa classe ao longo de uma determinada dire√ß√£o. Como assume-se isomorfismo nos
dados, esta dire√ß√£o √© arbitraria. Considerando em termos de transi√ß√£o de probabilidades,
o comprimento m√©dio ùêø‚Ñéùúë √© a taxa de decaimento da curva de transi√ß√£o da fun√ß√£o ùë°ùëñùëñ(‚Ñéùúë)
na dire√ß√£o ùúë . O comprimento m√©dio √© mostrado na equa√ß√£o 3.10.

‚àíùúïùë°ùëñùëñ(0))

ùúï‚Ñé

= 1
ùêø‚Ñé,ùúë

(3.10)

Isso √© an√°logo a taxa de uma classe transitar para si mesma, como mostrado na

Eq. 3.11 (CARLE; FOGG, 1996).

Àúùëüùëñùëñ = ‚àí 1
ùêø‚Ñé,ùúë

(3.11)

O conceito de tend√™ncia de justaposi√ß√£o modela as probabilidades de uma classe
transitar fora de si mesmo e depois em outra dado uma dist√¢ncia. Considerando ùëüùëñùëñ como
a taxa que a uma certa classe transita para si mesma, ùëüùëñùëó depende das propor√ß√µes de ùëó
como mostrado na Eq. 3.12.

Àúùëüùëó,ùëò(‚Ñéùúë) =

ùëùùëò

ùêøùëóùúë(1 ‚àí ùëùùëó)

(3.12)

Para o caso de um dataset de cinco classes, a matrix ùëÖùëöùëúùëë tem a seguinte estrutura:

‚é°‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£

1
ùêø11
Àúùëü21
Àúùëü31
Àúùëü41
Àúùëü51

Àúùëü11
1
ùêø22
Àúùëü32
Àúùëü42
Àúùëü52

Àúùëü13
Àúùëü23
1
ùêø33
Àúùëü43
Àúùëü53

Àúùëü14
Àúùëü24
Àúùëü34
1
ùêø44
Àúùëü54

Àúùëü15
Àúùëü25
Àúùëü35
Àúùëü45
1
ùêø55

‚é§‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶

ùëÖùëöùëúùëë =

(3.13)

Finalmente, usando ùëÖùëöùëíùë† e ùëÖùëöùëúùëë √© poss√≠vel computar a Eq 3.6. Na Figura 15
s√£o mostradas as transi√ß√µes de probabilidades calculadas para um dataset. Os gr√°ficos

58

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

da Figura 15 foram computados aplicando a Eq. 3.3 variando a dist√¢ncia ‚Ñé. Como um
exemplo, pode-se perceber que o comprimento m√©dio da classe background √© bem alto.
Isso acontece por que o seu decaimento exponencial √© muito baixo.

Figura 15 ‚Äì A transi√ß√£o de probabilidade modelada para um determinado dataset. O
eixo y apresenta a dist√¢ncia em pixeis. As linhas verdes mostram as propor√ß√µes para cada
classe. Pode-se observar uma certa tend√™ncia na classe Urchin em transitar para categoria
de background. Ainda, percebe-se que a classe de background tem um grande comprimento
m√©dio, dado que sua taxa de decaimento √© bastante alta.

3.4.2 Sequential Indicator Simulation

Dado que a matriz de transi√ß√£o ùëá j√° foi calculada para um dataset, o algoritmo
Sequential Indicator Simulation (SIS) tenta simular o ùëÉùëô(ùêø|ùëä) de um superpixel com base
em sua vizinhan√ßa espacial. Para simular os fatores locais de um certo superpixel ùë•0, um
certo n√∫mero ùëÅ de posi√ß√µes aleat√≥rias amostradas ùë•ùõº s√£o computados em torno da regi√£o
em um raio ùëü. Cada uma das posi√ß√µes amostradas vai contribuir para o computar o fator
local, sendo que a contribui√ß√£o √© feita de forma a minimizar a varian√ßa desta vizinhan√ßa
com respeito ao modelo.

Com isso, a probabilidade relacionada com o contexto espacial para cada classe ùëò

3.4. N√≠vel Local ùëÉùëô(ùêø|ùëä)

59

em uma certa parcela ùë•0 √© computada como:

ùëÉùëô(ùë•0 = ùëò|ùëÉùë¢(ùëãùõº)) = ùëÉùë¢(ùë•0 = ùëò)

ùëÅ‚àëÔ∏Å

ùêæ‚àëÔ∏Å

ùõº=1

ùëó=1

ùëÉùë¢(ùëãùõº = ùëó)ùë§ùëóùëò,ùõº

(3.14)

onde ùëÉùë¢ √© a probabilidade a priori (un√°rio) de uma regi√£o, sendo ùëÉùë¢(ùëã0 = ùëò) o superpixel
em quest√£o e ùëÉùë¢(ùëãùõº = ùëó), os amostrados. ùë§ùëóùëò,ùõº √© o peso da posi√ß√£o ùõº para a classe ùëó
transitar para a classe ùëò. Ou seja a probabilidade local de um superpixel √© fun√ß√£o da
distribui√ß√£o do mesmo (ùëÉùë¢(ùëã0 = ùëò)) e o quanto cada posi√ß√£o amostrada contribui para

‚àëÔ∏Äùêø
ùëó=1 ùëÉùë¢(ùëãùõº = ùëó)). O fator √© controlado pelo peso ùë§ùëóùëò,ùõº.

este superpixel (‚àëÔ∏ÄùëÅ

ùõº=1

Os pesos para cada posi√ß√£o amostrada formam o conjunto de matrizes ùëäùëÅ e s√£o

calculados resolvendo o sistema linear da Eq. 3.15 :

‚é°‚é¢‚é¢‚é¢‚é£ ùëá(ùë•1 ‚àí ùë•1)

ùëá(ùë•1 ‚àí ùë•ùëÅ)

.

‚é§‚é•‚é•‚é•‚é¶

... ùëá(ùë•ùëÅ ‚àí ùë•1)
.
... ùëá(ùë•ùëÅ ‚àí ùë•ùëÅ)

.

onde:

.

‚é°‚é¢‚é¢‚é¢‚é£ ùëä1
‚é§‚é•‚é•‚é•‚é¶
‚é°‚é¢‚é¢‚é¢‚é£ùë§11,ùõº

ùëäùëÅ

ùëäùëñ =

.

‚é°‚é¢‚é¢‚é¢‚é£ ùëá(ùë•0 ‚àí ùëã1)

ùëá(ùë•0 ‚àí ùëãùëÅ)

.

‚é§‚é•‚é•‚é•‚é¶ (3.15)

(3.16)

‚é§‚é•‚é•‚é•‚é¶

=

... ùë§1ùêø,ùõº
.

.

ùë§ùêø1,ùõº ... ùë§ùêøùêø,ùõº

A Figura 16 mostra o exemplo de um superpixel arbitr√°rio e sua respectiva regi√£o
amostrada, para a computa√ß√£o do potencial local. Para tal regi√£o a Eq. 3.15 ser√° aplicada
de forma a encontrar o peso para cada uma das posi√ß√µes. O peso encontrado √© o que
tornaria a regi√£o o mais homog√™nea poss√≠vel.

3.4.3 Computando o Potencial Final ùëÉ(ùêø)

Depois de obter uma sa√≠da da curva de confian√ßa para cada superpixel, primeira-
mente se busca os superpixeis com uma sa√≠da bem alta de confian√ßa. Foi decido computar
o potencial local apenas para superpixeis onde a confian√ßa est√° abaixo de um limiar ùë°. O
limiar √© selecionado como a confian√ßa m√°xima, dado pelo conjunto de valida√ß√£o.

O processo do SIS √© repetido para cada superpixel presente na imagem em ordem
aleat√≥ria e os pesos j√° s√£o atualizados. Isso garante que a correla√ß√£o entre a pr√≥pria
vizinhan√ßa seja considerada.

Os pesos s√£o obtidos diretamente pela Eq. 3.15. Dois par√¢metros devem ser escolhi-
dos para este m√©todo, o n√∫mero de amostras ùëÅ e o raio ùëü onde vai ser feita a amostragem.
Experimentos preliminares mostraram que n√£o existe vantagem pratica em usar mais de

60

Cap√≠tulo 3. Classifica√ß√£o Baseada em Contexto utilizando Geoestat√≠stica

Figura 16 ‚Äì Exemplo de uma vizinhan√ßa sendo considerada para um superpixel ( apontado
em vermelho). Um raio ùëü √© considerado e ùëÅ pontos s√£o amostrados nessa vizinhan√ßa ( em
azul). Cada um dos pontos amostrados ir√° influenciar no potencial do superpixel apontado
em vermelho.

25 amostras. Tamb√©m, o raio ùëü passa e se tornar irrelevante a partir de uma certa dis-
t√¢ncia, dado que √†s transi√ß√µes de probabilidade tendem a ser iguais as propor√ß√µes no
limite.

3.5 Geoestat√≠stica e CRF

Tanto as abordagem de CRF, quanto de Geoestat√≠stica (GS) tentam minimizar
uma fun√ß√£o que tenta impor uma certa homogeneidade espacial. Ou seja, superpixeis
pr√≥ximos tendem a ser da mesma classe. A diferen√ßa √© que o modelo de Geoestat√≠stica √©
baseado em uma amostragem o que torna o problema da infer√™ncia mais simples. O modelo
de GS √© tamb√©m an√°logo a um CRF densamente conectado (KOLTUN; VLADLEN, 2011),
mas com amostragens mais esparsas.

A abordagem de GS pode ser vista como uma representa√ß√£o mais esparsa do CRF
por√©m, com medidas estat√≠sticas mais ricas. N√£o obstante, a computa√ß√£o da matriz de
pesos ùëä para a Eq. 3.14 pode ser considerado como a minimiza√ß√£o de uma fun√ß√£o de
energia, usando uma soma ponderada.

Como uma forma de comparar ambos os m√©todos, a Figura 17 mostra o modelo
GS como um modelo gr√°fico probabil√≠stico. O v√©rtice central, em verde claro, √© o caso
atual sendo calculado. Os v√©rtices em verde escuro s√£o aqueles amostrados. Cada vertice
em verde escuro contribui para a distribui√ß√£o do vertice central dependendo das proba-
bilidades de transi√ß√£o estimadas da Fig. 15. Em vermelho s√£o representados os fatores

3.6. Sum√°rio

61

un√°rios de cada quadrado em azul √© a contribui√ß√£o desses mesmos ( fatores locais).

Figura 17 ‚Äì Representa√ß√£o gr√°fica do modelo de Geoestat√≠stica (GS). Os fatores locais
s√£o representados em azul e usam a estat√≠stica de probabilidade de transi√ß√£o computada
pela Eq. 3.3. Diferentemente do que no modelo da Fig. 7, vizinhos de diferentes dist√¢ncias
tamb√©m contribuem para calcular a distribui√ß√£o de cada posi√ß√£o.

3.6 Sum√°rio

Neste Cap√≠tulo apresentou-se um novo m√©todo para adi√ß√£o de contexto na classifi-
ca√ß√£o. O m√©todo foi inspirado nas t√©cnicas de modelagem da variabilidade espacial usada
em Geoestat√≠stica.

Foi feita, por fim, uma compara√ß√£o do m√©todo proposto com o CRF. Acredita-
se que o m√©todo apresentado neste cap√≠tulo tende a se comportar melhor que o CRF
quando existem menos dados de treinamento, e os mesmos dados n√£o possuem padr√µes
bem definidos, como no caso do ambiente subaqu√°tico. Isso pode ser atingido visto que
o m√©todo proposto estima padr√µes de forma para as classes. Sendo assim as rela√ß√µes de
correla√ß√£o espacial, s√£o tamb√©m estimadas com base em um modelo para as classes. O
m√©todo proposto ser√° testado e avaliado no Cap√≠tulo 6.

4 Classifica√ß√£o de Imagens do Assoalho

63

Oce√¢nico

Neste Cap√≠tulo √© apresentado o dom√≠nio de aplica√ß√£o no qual ser√° aplicado o

m√©todo de adi√ß√£o de contexto proposto no Cap√≠tulo 3.

Como apresentado na introdu√ß√£o, o conhecimento sobre as esp√©cies presentes no
fundo do mar, especialmente os recifes de corais, √© de fundamental import√¢ncia para os
especialistas na √°rea.

Ao se fazer monitoramento do assoalho oce√¢nico, assim como para o caso do sen-
soriamento remoto, √© interessante ser capaz de rotular autom√°ticamente cada pixel das
imagens e assim ser capaz de medir propriedades relevantes. O objetivo desta classifica-
√ß√£o √© fazer os chamados mapas tem√°ticos. Tais mapas s√£o a representa√ß√£o final de um
mapa classificado de uma imagem, feito de forma visualmente interpret√°vel. Mapas tem√°-
ticos agregam grandes conjuntos de imagens em mosaicos representando √°reas de grande
extens√£o.

Considerando o ambiente subaqu√°tico, suas propriedades fotom√©tricas demandam
um tratamento especial para contornar a degrada√ß√£o da imagem. Esses desafios pr√≥prios
do meio n√£o s√£o comumente endere√ßados na literatura. Tais propriedades causam proble-
mas como bordas confusas entre objetos, varia√ß√£o na qualidade da imagem, etc.

Neste cap√≠tulo primeiramente √© formalizada as propriedades do meio subaqu√°tico,
o que sera √∫til tamb√©m para cap√≠tulos posteriores. Depois, √© apresentada uma vis√£o geral
dos principais sistemas utilizados para classifica√ß√£o de mosaicos do assoalho oce√¢nico.
Entre os sistemas apresentados, um em especial ser√° detalhado, o qual ser√° utilizado
como um estudo de caso para adi√ß√£o de contexto.

4.1

Propriedades de Imagens Subaqu√°ticas

De forma a obter imagens capturadas em ambiente subaqu√°tico com uma melhor
qualidade visual, √© fundamental o entendimento de sua forma√ß√£o, levando em conta os
aspectos espec√≠ficos que ocorrem no meio subaqu√°tico.

Um modelo de forma√ß√£o de imagens busca descrever os caminhos pelos quais a luz
passa, desde a fonte at√© a sua captura, onde √© formada a imagem. A Figura 18 ilustra
este processo de propaga√ß√£o. Em meios participativos, a irradia√ß√£o, ou seja, a quantidade
de energia luminosa em um pixel, pode ser obtida pelo somat√≥rio de tr√™s componentes as
quais chegam por caminhos distintos. A componente direta, a qual cont√©m a luz sem es-

64

Cap√≠tulo 4. Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

palhamento que veio diretamente do objeto. Muitas vezes, informa√ß√µes que vinham de um
√∫nico ponto s√£o espalhadas entre seus pontos vizinhos causando um efeito de borramento
na imagem. Este fen√¥meno √© chamado espalhamento dianteiro (forward scattering),
representado pela componente forward scattering. O forward-scattering faz com que as
informa√ß√µes visuais da cena fiquem espalhadas, causando um efeito de borramento.

Figura 18 ‚Äì Tr√™s trajet√≥rias da luz at√© o plano da imagem. O componente direto, con-
tendo a informa√ß√£o direta da cena. O forward-scattering, contendo informa√ß√£o da cena
espalhada. Por fim, o backscattering contendo informa√ß√µes de fora da cena.

Por √∫ltimo, tem-se a componente de backscattering, a qual luz chega no plano da
imagem a partir de um ponto que n√£o faz parte da cena observada. Isso acontece devido
√† alguma part√≠cula flutuante que desvia a trajet√≥ria da luz para o plano da imagem. O
backscattering se comporta tal como um ru√≠do aditivo.

Para calcular cada uma das componentes, algumas simplifica√ß√µes devem ser con-
sideradas. Tais simplifica√ß√µes visam tornar o modelo mais simples e trat√°vel computacio-
nalmente, ressaltando somente alguns aspectos principais na forma√ß√£o da imagem.

Primeiramente, se assume o objeto como tendo sua reflectividade uniforme. Assume-
se uma ilumina√ß√£o completa e uniforme da cena. Por fim, pode-se descartar os par√¢metros
da c√¢mera e considerar a captura da luz como sendo tamb√©m uniforme.

Normalmente o efeito causado pelo forward-scattering tende ser desprezado, por
contribuir com uma participa√ß√£o menor que o backscattering na forma√ß√£o da imagem
(TREIBITZ; SCHECHNER, 2006).

A descri√ß√£o final do modelo √© dada pela equa√ß√£o de Koschmieder (KOSCHMI-
EDER, 1924), bastante utilizada para a propaga√ß√£o da luz na n√©voa. Sendo assim, a

4.1. Propriedades de Imagens Subaqu√°ticas

forma√ß√£o de um ponto (ùë•, ùë¶) na imagem √© dado por:

ùêº(ùë•, ùë¶) = ùêΩ(ùë•, ùë¶) ùëí‚àíùëêùëß(ùë•,ùë¶) + ùêµ‚àû(1 ‚àí ùëí‚àíùëêùëß(ùë•,ùë¶)),

65

(4.1)

Sendo ùêΩ(ùë•, ùë¶) a imagem sem degrada√ß√£o e ùëß(ùë•, ùë¶) uma fun√ß√£o da dist√¢ncia para
cada ponto na imagem. Essa equa√ß√£o pode ser interpretada da seguinte forma: quanto
mais distante estiver o objeto maior ser√° o componente backscattering, menos da cena real
ir√° existir na imagem.

Sabe-se que, devido as propriedades do meio subaqu√°tico, existe uma diferen√ßa sig-
nificativa entre a absor√ß√£o e espalhamento dos comprimentos de onda (DUNTLEY, 1963)
Desta forma, o modelo pode ser estendido de forma incorporar diferentes comprimentos
de onda. A equa√ß√£o 4.1 modela a quantidade de luminosidade capturada relativa a um
determinado pixel. Por√©m √© poss√≠vel adequ√°-la para diferentes comprimentos de onda, ou
no caso do padr√£o RGB de representa√ß√£o, dividi-la em tr√™s canais conforme a equa√ß√£o
4.2,

ùêº ùúÜ(ùë•, ùë¶) = ùêΩ ùúÜ(ùë•, ùë¶) ùëí‚àíùëêùúÜùëß(ùë•,ùë¶) + ùêµùúÜ‚àû(1 ‚àí ùëí‚àíùëêùúÜùëß(ùë•,ùë¶)), ùúÜ ùúñ {ùëÖ, ùê∫, ùêµ}

(4.2)

A Figura 19 apresenta uma t√≠pica imagem com alto n√≠vel de turbidez. Turbidez √©
uma propriedade comum no meio aqu√°tico que esta relacionada com a quantidade de luz
que √© absorvida ou espalhada ao inv√©s de ser transmitida em uma linha reta (OMAR;
MATJAFRI, 2009).

Figura 19 ‚Äì Imagem de exemplo para as degrada√ß√µes do ambiente subaqu√°tico. √â poss√≠vel
ver que existe uma varia√ß√£o conforme a dist√¢ncia e uma perda significativa da informa√ß√£o
de cor.

66

Cap√≠tulo 4. Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

√â interessante observar que a degrada√ß√£o n√£o afeta uniformemente a imagem.
Existem n√≠veis de degrada√ß√£o mais altos de acordo com a dist√¢ncia. Al√©m disso, o com-
primento de onda vermelho tende a se perder rapidamente, tendo a cor verde nesse caso
como predominante.

Por fim, vale notar que, fen√¥menos adicionais tamb√©m acontecem. Um exemplo √©
o efeito da "neve submarina", a qual causa aparecimento de pequenos pontos brancos na
imagem. Por estes e outros fatos √© relevante constatar que o meio subaqu√°tico j√° tem uma
alta presen√ßa de ru√≠do (BAZEILLE et al., 2006).

4.2 Classifica√ß√£o Aut√¥noma de Imagens do fundo Oce√¢nico

A Figura 20 mostra uma adapta√ß√£o do que √© usado pela maioria dos frameworks
em vis√£o computacional para cria√ß√£o de mapas tem√°ticos de mosaicos em ambientes
subaqu√°ticos (SHIHAVUDDIN et al., 2013).

Figura 20 ‚Äì A sequ√™ncia utilizada para classifica√ß√£o de imagens em meio subaqu√°tico.

Para classificar os objetos de uma imagem √© necess√°rio passar por diversas etapas.
A seguir s√£o listadas as etapas apresentando algumas das t√©cnicas usadas na literatura:

‚àô Pr√©-processamento: etapa fundamental em ambientes subaqu√°ticos. Normalmente √©
onde corre√ß√µes de cor (PIZARRO et al., 2008) e contraste (JOHNSON-ROBERSON;
KUMAR; WILLAMS, 2007) s√£o aplicadas para atenuar a degrada√ß√£o e ressaltar
aspectos importantes das imagens subaqu√°ticas.

‚àô Segmenta√ß√£o: Nesta etapa a imagem √© super-segmentada em regi√µes com proprie-
dades similares. Tal etapa pode ser evitada, para o caso onde ocorre uma sele√ß√£o
manual do que ser classificado.

‚àô Extra√ß√£o de Descritores: √© onde as caracter√≠sticas relevantes para cada segmento
s√£o extra√≠das e representadas. Diversas abordagens s√£o utilizadas, um exemplo seria
o uso de descritores locais e bag-of-words por Pizarro, Eustice e Singh (2004). Os

4.2. Classifica√ß√£o Aut√¥noma de Imagens do fundo Oce√¢nico

67

descritores de textura e cor s√£o bastante utilizados no meio subaqu√°tico (BEIJBOM
et al., 2012) (STOKES; DEANE, 2009), (MARCOS; SORIANO; SALOMA, 2005).
‚àô Classifica√ß√£o: √© onde se realiza o treinamento do classificador e classifica√ß√£o para os
testes. Diversos classificadores s√£o utilizados como o SVM (PIZARRO; EUSTICE;
SINGH, 2004) ou o LDA (MARCOS; SORIANO; SALOMA, 2005).

‚àô P√≥s-processamento: √© onde informa√ß√µes adicionais s√£o utilizadas para refinar o resul-
tado da classifica√ß√£o. Em (SHIHAVUDDIN et al., 2013) √© feito um simples sistema
de vota√ß√£o para verificar a consist√™ncia da vizinhan√ßa No caso, at√© onde se sabe, n√£o
ocorreram outras aplica√ß√µes de t√©cnicas mais elaboradas para adi√ß√£o de contexto.

Nesta se√ß√£o √© especificado em detalhe cada etapa apresentada elucidando o que
foi utilizado por Shihavuddin et al. (2013) para gera√ß√£o de mapas tem√°ticos. Tal m√©todo
foi escolhido como base para aplica√ß√£o de t√©cnicas para adi√ß√£o de contexto. O mesmo foi
escolhido devido a alta taxa de acerto na classifica√ß√£o quando comparados com diversos
m√©todos do estado da arte (SHIHAVUDDIN et al., 2013). Os algoritmos usados em cada
uma das etapas da Figura 20 s√£o elucidados a seguir.

4.2.1 Pr√©-Processamento

O processo de pr√©-processamento almeja deixar a imagem o mais pr√≥xima poss√≠vel
da cena em qual a mesma foi capturada. Isso √© feito tanto no escopo radiom√©trico quanto
geom√©trico. Ou seja, o objectivo √© tornar, as estruturas geom√©tricas , seu brilho e cor o
mais pr√≥ximos poss√≠vel da cena (GONZALEZ; WOODS, 2006).

Para lidar com o processamento embaixo d‚Äô√°gua, primeiramente, precisa-se consi-
derar todos os princ√≠pios b√°sicos de propaga√ß√£o da luz nesse meio os quais foram colocados
na Se√ß√£o 4.1. (SCHETTINI; CORCHS, 2010)

Seguindo a ideia de que a qualidade visual subjetiva √© importante, pode-se melhor a
qualidade de imagens subaqu√°ticas utilizando t√©cnicas que abordam diretamente os efeitos
degradantes apontados. Esta se√ß√£o apresenta as alternativas existentes para corrigir cada
um dos tipos de degrada√ß√£o.

4.2.1.1 Contraste

Observa-se pela Equa√ß√£o 4.1 que o processo de degrada√ß√£o da imagem em ambiente
subaqu√°tico n√£o √© uniforme ao longo da imagem. O mesmo depende da dist√¢ncia de cada
ponto a c√¢mera.

Nesse contexto, o Shihavuddin et al. (2013) faz o uso do CLAHE (Contrast Limited
Adaptative Histogram Equalization) (ZUIDERVELD, 1994) para corre√ß√£o de contraste.

68

Cap√≠tulo 4. Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

Tal m√©todo faz uma constru√ß√£o de histograma diferente para cada segmento da imagem
e aplica uma equaliza√ß√£o de histograma somente nesse segmento. Al√©m disso, o m√©todo
coloca um limite de intensidade maxima, redistribuindo todos as intensidades que ficam
acima deste limite.

4.2.1.2 Corre√ß√£o de Cor

Como mostrado na se√ß√£o 4.1, existe uma n√£o uniformidade na absor√ß√£o de cada
comprimento de onda no ambiente subaqu√°tico. Isso causa que boa parte da informa√ß√£o
crom√°tica da cena seja perdida.

De forma a obter cores mais pr√≥ximas de realidade existe a necessidade de estimar
tais diferen√ßas de absor√ß√£o. Uma das formas de resolver isso √© considerar que √© poss√≠-
vel obter as diferen√ßas de absor√ß√£o considerando essas diferen√ßas como uma quest√£o de
estimativa da fonte de luz. Colocado de tal forma, o problema, se torna basicamente a
aplica√ß√£o de algoritmos de balanceamento de branco, os quais podem ser uma simples
normaliza√ß√£o.

O m√©todo de (SHIHAVUDDIN et al., 2013) aplicou a premissa de que que o
ponto de maior intensidade da imagem foi causado por reflex√£o perfeita. Desta forma a
ilumina√ß√£o pode ser estimada achando o ponto de maior intensidade da imagem. Sendo
assim, para tornar a cor da imagem balanceada, o ganho para cada pixel pode ser dado
como:

ùëÖùëîùëéùëõ‚Ñéùëú = 1/ùëÖùëöùëéùë•
ùê∫ùëîùëéùëõ‚Ñéùëú = 1/ùê∫ùëöùëéùë•
ùêµùëîùëéùëõ‚Ñéùëú = 1/ùêµùëöùëéùë•

(4.3)

4.2.2 Segmenta√ß√£o

Diversos desafios em classifica√ß√£o de imagens colocam o desafio atual como classi-

ficar os objetos pixel a pixel (FULKERSON; VEDALDI; SOATTO, 2009).

O caso da aplica√ß√£o em sensoriamento remoto, claramente se beneficia deste fato,
onde cada pixel da imagem √© relevante. A quest√£o √© que, devido ao custo computacional,
e ao fato que somente um pixel n√£o possuir grande significado sem√¢ntico para efetuar
a classifica√ß√£o e extrair os descritores, muitas vezes a abordagem de usar segmentos da
imagem, ajuda a melhorar a consist√™ncia.

Existe e a tend√™ncia de muitos autores fazer uma pr√©-segmenta√ß√£o, a qual aparen-
temente n√£o esta relacionada com a classifica√ß√£o final. Por√©m, tal segmenta√ß√£o ajuda a
a garantir que cada parte da imagem sendo classificada tenha uma homogeneidade local.
Tal segmenta√ß√£o √© chamada de segmenta√ß√£o em superpixeis.

4.2. Classifica√ß√£o Aut√¥noma de Imagens do fundo Oce√¢nico

69

Para o caso da abordagem de Shihavuddin et al. (2013), os superpixeis s√£o utiliza-
dos como estrutura de intera√ß√£o. A imagem √© definida como um conjunto de superpixeis
a serem classificados.

Diversos algoritmos existem para a cria√ß√£o de superpixeis. Por√©m, Shihavuddin et
al. (2013) selecionou aquele que tende a manter uma estrutura o mais regular poss√≠vel.
No caso foi utilizado os Turbopixels (LEVINSHTEIN et al., 2009) .

4.2.3 Descritores

Para descrever a imagem foi utilizado majoritariamente descritores de textura.
Textura pode ser definida como a varia√ß√£o dos dados visuais em escalas menores que a
escala observada (PETROU; GARC√çA-SEVILLA, 2006).

O assoalho submarino √© tipicamente texturizado. Observou-se diversos bancos de
dados de corais, e outras estruturas encontradas no meio, e percebe-se que existem sem-
pre oscila√ß√µes na estrutura dos objetos em diferentes escalas. Tal fen√¥meno caracteriza a
exist√™ncia da textura. Al√©m da tend√™ncia existente na literatura em usar textura (SHIHA-
VUDDIN et al., 2013).

Com isso em vista, (SHIHAVUDDIN et al., 2013) utiliza tr√™s descritores como des-
critores de texturas: Gabor Filter, Grey Level Co-occurence Matrix (GLCM) e Completed
Local Binary Pattern (CLBP).

Os Gabor Filters s√£o um grupo de Wavelets 2D que tomam forma de uma gaussiana
2D modulada no espa√ßo 2D (PORTER; CANAGARAJAH, 1997). Basicamente s√£o uma
representa√ß√£o da varia√ß√£o de frequ√™ncia em um segmento da imagem.

O GLCM (HARALICK; SHANMUGAM; DINSTEIN, 1973), utiliza a represen-
ta√ß√£o de padr√µes de varia√ß√µes espaciais dos segmentos da imagem em uma matriz, que
representa a varia√ß√£o de intensidade dos pixeis em diferentes √¢ngulos e dist√¢ncias. Diver-
sos indicadores s√£o computados a partir dessas matrizes como a m√©dia de varia√ß√µes ou a
entropia.

O CLBP (GUO; ZHANG, 2010), √© um descritor de textura invariante a rota√ß√£o o
qual retrata, principalmente, a varia√ß√£o de sinais de um pixel central para com pixeis ao
redor em uma determinada posi√ß√£o.

A utiliza√ß√£o de cor √© complexa dado a perda de cor n√£o uniforme entre os compri-
mentos de onda como mostrado na Se√ß√£o 4.1. Por√©m ainda √© poss√≠vel utilizar um descritor
de cor que possui propriedades importantes como robustez a varia√ß√µes fotom√©tricas causa-
das por sombras, sombreamento e tamb√©m mudan√ßas geom√©tricas como escala e altera√ß√£o
de ponto de vista. (SHIHAVUDDIN et al., 2013) utiliza o trabalho de (WEIJER; SCH-
MID, 2006) que aproximou tais propriedades.

70

Cap√≠tulo 4. Classifica√ß√£o de Imagens do Assoalho Oce√¢nico

Ao final, ao utilizar m√∫ltiplos descritores, se tem uma representa√ß√£o da imagem
com uma grande quantidade de dimens√µes e muitas vezes com um padr√£o pouco evidente.
Para resolver isso √© aplicado normaliza√ß√µes e modifica√ß√µes nos descritores. Por exemplo,
os descritores podem ser manipulados de forma que os mesmos sejam o mais pr√≥ximos a
se tornaram linearmente separ√°veis. Essa modifica√ß√£o √© fundamental para se melhorar a
qualidade da classifica√ß√£o. Por fim, os descritores s√£o normalizados de forma a que todos
os descritores estejam numa escala compat√≠vel.

4.2.4 Treinamento e Classifica√ß√£o

O treinamento foi feito utilizando tr√™s classificadores distintos de forma mutu-
almente exclusiva. Foram utilizados o Support Vector Machine (SVM), o K-nearest-
neighbors e o PDWMD proposto por (STOKES; DEANE, 2009). Cada um destes classi-
ficadores foi utilizado dependendo das caracter√≠sticas dos dados.

Dado que o aprendizado foi feito, novos dados podem ser classificados. √â feito
um mapa tem√°tico baseado na segmenta√ß√£o em superpixeis. Sendo que cada superpixel √©
classificado individualmente.

4.3 Conclus√µes

Neste cap√≠tulo apresentou-se o cen√°rio onde vai ser feito o estudo desta disserta√ß√£o.
Tamb√©m se apresentou alguns m√©todos os quais j√° fizeram classifica√ß√£o de imagens do
bentos.

No cap√≠tulo 6 ser√£o apresentados os resultados de aplica√ß√£o do m√©todo de (SHIHA-
VUDDIN et al., 2013) e ser√° feito o estudo sobre a incorpora√ß√£o de contexto para esse
m√©todo.

5 Testes e Resultados 1: Detec√ß√£o de Pontos

de Interesse em Ambiente Subaqu√°tico

71

Uma das principais contribui√ß√µes desta disserta√ß√£o foi a cria√ß√£o de um experi-
mento para analizar e compreender o comportamento dos detectores de pontos de interesse
quando utilizados em ambiente subaqu√°tico.

Como apresentado no Cap√≠tulo 1, diversos detectores foram desenvolvidos para
serem invariantes a uma serie de fen√¥menos. A ideia √© que o mesmo ponto de interesse
possa ser encontrado independentemente de diversas circunst√¢ncias da cena.

Por√©m, existem fen√¥menos adicionais que atuam sobre a cena no ambiente su-
baquatico os quais devem ser considerados. Quando a luz se propaga neste meio, ela √©
absorvida e espalhada pelos diferentes coeficientes de refra√ß√£o encontrados nas particulas
presentes no meio. Isso espalha a informa√ß√£o capturada e cria o efeito de "enevoado"na
imagem. Tais fen√¥menos foram descritos mais detalhadamente no Cap√≠tulo 4, Se√ß√£o 4.1.
Um estudo feito por Garcia e Gracias (GARCIA; GRACIAS, 2011), comparou
os detectores de pontos de interesse mais populares na literatura. Eles encontraram que
estruturas do tipo blob, obtidos por m√©todos baseados em Hessian (BEAUDET, 1978),
por exemplo, s√£o melhores detectadas tanto para o caso de m√©todos invariantes a escala
como os de √∫nica escala. A justificativa √© que a turbidez da √°gua tende a suavizar quinas e
borrar regi√µes definidas, fazendo com que m√©todos como Harris (HARRIS; STEPHENS,
1988) ou Harris-Laplace (MIKOLAJCZYK; SCHMID, 2004) sejam menos prop√≠cios para
o ambiente. Entretanto, eles avaliaram somente algumas estruturas em uma √∫nica cena.
√â do interesse desta disserta√ß√£o melhorar este estudo. Neste contexto, alguns principais
objetivos s√£o buscados.

Foi proposto um novo dataset no qual √© poss√≠vel utilizar diferentes estruturas
submarinas obtidas atrav√©s da impress√£o de fotos subaqu√°ticas. Estas estruturas foram
refotografadas dentro de um tanque de √°gua onde imagens com a degrada√ß√£o controlada
foram produzidas. Isso √© uma melhoria a tentativas anteriores em termos de diversidade
de elementos visuais. Considerando que a degrada√ß√£o causada por imagens com baixa e
alta turbidez n√£o √© linear, uma contribui√ß√£o √© dividir a an√°lise em diferentes intervalos
de turbidez.

Foram testados detectores de pontos de interesse, considerando diferentes aborda-
gens, com respeito a sua robustez a degrada√ß√£o causada pela turbidez. Foi focado inves-
tigar o problema de que detectores invariantes a escala tendem a ter baixa performance
(GARCIA; GRACIAS, 2011). Isto √© feito atrav√©s da an√°lise de diferentes espa√ßos de es-

72

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

cala. Finalmente, foi indicado o melhor detector invariante para imagens subaqu√°ticas
como sendo o DoG (LOWE, 2004).

Este Cap√≠tulo est√° organizado da seguinte maneira. A se√ß√£o 5.1 apresenta a des-
cri√ß√£o completa do experimento a ser realizado. Tal se√ß√£o mostra todos os detalhes da
experimenta√ß√£o necess√°rios para que o mesmo seja bem sucedido. Tamb√©m explica to-
das as considera√ß√µes feitas para se ter dados aceitaveis. Por fim, a Se√ß√£o 5.3 mostra os
resultados obtidos para tal experimento, e apresenta uma discuss√£o sobre os resultados
encontrados.

5.1 Descri√ß√£o do experimento

Na literatura, poucos s√£o os trabalhos que analisam o comportamento dos detec-
tores de pontos de interesse em ambiente subaqu√°tico. Nesta se√ß√£o, descreve-se todo o
processo de realiza√ß√£o do experimento para que ele seja completamente reproduz√≠vel.

Neste experimento foram capturadas diversas imagens em uma cena onde a √∫nica
modifica√ß√£o entra as cenas √© a degrada√ß√£o causada pela turbidez. O objetivo fundamental
do experimento √© tentar obter o m√°ximo de isolamento desta degrada√ß√£o poss√≠vel. Para
tal, a c√¢mera utilizada deve estar est√°tica e a ilumina√ß√£o deve ser controlada.

5.1.1 Cena Montada

Constru√≠-se uma cena onde as imagens foram colocadas. A Figura 21 mostra a

especifica√ß√£o da cena.

Figura 21 ‚Äì A cena criada para avaliar os algoritmos de avalia√ß√£o de features. Ela √© com-
posta por lampadas fluorescentes e uma camera fotografando fotos impressas do assoalho
do oceano.

Na cena montada existe uma fotografia a ser capturada por uma c√¢mera posicio-
nada a uma dist√¢ncia perpendicular de 0.58ùëêùëö . A fotografia esta posicionada em uma

5.1. Descri√ß√£o do experimento

73

caixa de √°gua de mil litros. Duas lumin√°rias usando l√¢mpadas fluorescentes brancas foram
posicionadas perto do tanque.

Tr√™s fotografias diferentes foram utilizadas, representando o fundo do mar captu-
rado nas Bahamas em condi√ß√µes pr√≥ximas ao ideal de turbidez (ZVULONI et al., 2009). As
diferentes cenas cont√©m os mais variados tipos de textura que podem ser encontradas no
ambiente subaqu√°tico e tamb√©m objetos feitos pelo homem. As fotografias foram impres-
sas usando um "ploter"a laser usando uma m√≠dia de vinil adesivo fosco e a prova d‚Äô√°gua.
Cada fotografia foi impressa num tamanho de 91cm X 60 cm e possuem 4928x3264 pixeis
de resolu√ß√£o. O diferencial desta deste dataset √© que ele cont√©m verdadeiras estruturas
do assoalho oceano, e ainda algumas estruturas feitas pelo homem, sendo o seu princi-
pal problema, a perda de resolu√ß√£o devido a impress√£o e a refotografia. Isso cria uma
perda de resolu√ß√£o de 20 ùëùùëñùë•ùëíùëôùë†/ùëöùëö2 para 4 ùëùùëñùë•ùëíùëôùë†/ùëöùëö2 e adi√ß√£o de algumas pequenas
imperfei√ß√µes devido a erros de impress√£o.

A Figura mostra as imagens que foram impressas, nomea-se cada uma das imagens

como ùëÉ1, ùëÉ2 e ùëÉ3.

A c√¢mera utilizada para a captura foi uma Gopro Hero 3 Black edition. Cada

imagem foi capturada em uma resolu√ß√£o de 12 mega pixels(3000x4000).

5.1.2 Procedimento

Foi decidido simular principalmente o efeito do fen√¥meno de backscattering. Sabe-
se que os motivos que levam a degrada√ß√£o de uma imagem capturada em meio subaqu√°tico
s√£o complexos (DUNTLEY, 1963). Por√©m, neste experimento tentou-se isolar o princi-
pal fen√¥meno que causa a degrada√ß√£o na imagem. Um estudo feito por Narasimhan et
al. (2006) mostra que uma solu√ß√£o de √°gua e leite integral apresenta um alto grau de
backscattering, apontado por alguns como a principal fonte de degrada√ß√£o da imagem
(TREIBITZ; SCHECHNER, 2006). Isso √© causado pelo maior tamanho das part√≠culas do
leite integral que fazem que o √¢ngulo de refra√ß√£o seja maior, aumentando o backscattering.
Foi decidido dividir o experimento em 3 ensaios, cada um contendo uma imagem

diferente.

Cada ensaio foi capturado com 19 n√≠veis de turbidez diferentes, cada um contendo
uma determinada quantidade de leite. Chamou-se cada n√≠vel de turbidez de ùëá1...ùëá19.
Considera-se ùëá0 como o n√≠vel de turbidez com a imagem limpa. A Tabela 1 mostra os n√≠veis
de turbidez e suas respectivas quantidades de leite (Em uma caixa com aproximadamente
1000 litros de √°gua).

Para capturar as imagens, a c√¢mera foi setada para capturar uma foto a cada
10 segundos. Para cada n√≠vel de turbidez foi escolhido um grupo de fotos com o menor
n√≠vel de perturba√ß√£o. Como explicado no Cap√≠tulo 4, Se√ß√£o 4.1, o meio subaqu√°tico √©

74

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

(a) ùëÉ1

(b) ùëÉ2

(c) ùëÉ3

Figura 22 ‚Äì As imagens utilizadas no teste. As tr√™s imagens foram capturadas nas Bahamas
em condi√ß√µes de turbidez pr√≥ximas do ideal em uma resolu√ß√£o de 4928x3264 pixeis

composto por uma certa quantidade de ru√≠do. Em um ambiente controlado, como o que
foi feito √© poss√≠vel, tendo uma sele√ß√£o de fotos em um mesmo n√≠vel de turbidez ùëáùëñ, reduzir
o ru√≠do extraindo mediana entre as imagens iguais (GARCIA; GRACIAS, 2011). Desta
forma busca-se reduzir a degrada√ß√£o na imagem por ru√≠dos que podem ter diversas causas

5.2. Avaliando a degrada√ß√£o causada pela turbidez

75

Imagem (ùëáùëñ) Quantidade de Leite Integral Leite Adicionado

5 ml
5 ml
5 ml
5 ml
5 ml
5 ml
6 ml
6 ml
8 ml
8 ml
8 ml
8 ml
8 ml
8 ml
10 ml
10 ml
10 ml
10 ml
60 ml

T1
T2
T3
T4
T5
T6
T7
T8
T9
T10
T11
T12
T13
T14
T15
T16
T17
T18
T19

5 ml
10 ml
15 ml
20 ml
25 ml
30 ml
36 ml
42 ml
50 ml
58 ml
66 ml
74 ml
82 ml
90 ml
100 ml
110 ml
120 ml
130 ml
190 ml

Tabela 1 ‚Äì A quantidade de leite adicionada para cada n√≠vel de turbidez simulado.

como erro no sensor da c√¢mera, part√≠culas bloqueando totalmente a passagem da luz, etc.
Tenta-se de certa forma isolar significativamente a degrada√ß√£o por turbidez (IDT), como
o principal fen√¥meno da cena.

A Figura 23 apresenta as imagens geradas pelo experimento. Neste caso fez-se
a distin√ß√£o entre diversos intervalos de turbidez. Na Figura 23 √© mostrado um n√≠vel de
turbidez por intervalo, para cada imagem.

5.2 Avaliando a degrada√ß√£o causada pela turbidez

Medir a quantidade de degrada√ß√£o √© fundamental neste experimento de forma a
comparar os detectores somente relativo a este fen√¥meno. A degrada√ß√£o causada pela tur-
bidez √© dependende da quantidade de particulas em suspen√ß√£o na √°gua, e tamb√©m os tipos
de particulas em suspen√ß√£o. Al√©m disso, a quantidade de ilumina√ß√£o e a maneira como a
cena √© iluminada √© tamb√©m fundamental para determina√ß√£o da degrada√ß√£o causada pela
turbidez.

Este conceito difere do conceito de turbidez que esta relacionado somente com a
quantidade de sedimentos flutuantes (SSC) na √°gua os quais espalham a luz. A degrada√ß√£o
causada pela turbidez difere pois ela n√£o esta relacionado somente as part√≠culas presentes
na √°gua e sim a degrada√ß√£o que o SSC causa na cena, levando em conta os par√¢metros

76

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

Figura 23 ‚Äì As imagens capturadas sob diferentes n√≠veis de degrada√ß√£o devido a turbi-
dez, controlado pela adi√ß√£o de leite. Foram fotografadas tr√™s fotos impressas diferentes,
ùëÉ1 (primeira coluna), ùëÉ2 (segunda coluna) e ùëÉ3 (terceira coluna). Na primeira linha foi
mostrada a imagem limpa (sem leite) para cada foto capturada. A segunda linha apre-
senta o intervalo de Baixa Turbidez com por volta de 15ml de leite (ùëá4). O intervalo de
M√©dia Turbidez √© mostrado na segunda linha e cont√©m por volta de 50 ml de leite (ùëá10).
Finalmente, na ultima (quarta) linha √© mostrado o intervalo com Alta turbidez tendo por
volta de 100 ml de leite (ùëá16). Quantidade de leite setada para uma caixa com 1000 litros
de √°gua.

da c√¢mera e o volume de √°gua iluminado.

Uma forma de medir a turbidez √© usando um turbid√≠metro nefel√¥metro, o qual
mede a turbidez pela quantidade de luz espalhada ao emitir um feixe de laser numa
por√ß√£o da √°gua.

Esta alternativas n√£o √© capaz de estimar a degrada√ß√£o causada pela turbidez,
que √© tamb√©m dependente da cena. Com essas considera√ß√µes, Garcia e Gracias (2011)
propuseram a utiliza√ß√£o de uma varia√ß√£o Structural Similarity Index (WANG et al., 2004),
para avaliar a degrada√ß√£o, chamado Structural Degradation Index (SDI). Essa abordagem
avalia a degrada√ß√£o pela perda de informa√ß√£o estrutural, o que de fato esta relacionado

5.3. Resultados

77

com a turbidez. Por√©m, a mesma n√£o tenta isolar a medi√ß√£o do fen√¥meno de absor√ß√£o e
espalhamento como principais causadores da degrada√ß√£o.

Neste trabalho utiliza-se a m√©trica proposta por (GARCIA; GRACIAS, 2011),
por√©m normalizada em fun√ß√£o da imagem completamente turva pelo leite. Tal m√©trica
√© capaz de medir a porcentagem de degrada√ß√£o em fun√ß√£o da imagem onde teve sua
informa√ß√£o visual inicial completamente eliminada. O m√©todo √© explicado na sec√ß√£o 5.3.1

5.3 Resultados

Nesta se√ß√£o s√£o mostradas a compara√ß√µes entre os detectores. Foram comparados
os seguintes detectores, previamente definidos no Cap√≠tulo 1. Para √∫nica escala, Harris
(HARRIS; STEPHENS, 1988), Hessian (BEAUDET, 1978) e Laplacian (TUYTELAARS;
MIKOLAJCZYK, 2008). Com m√∫ltiplas escalas avaliou-se Fast Hessian do SURF (BAY
et al., 2008) e Difference of Gaussians do SIFT (LOWE, 2004). Foram avaliados tamb√©m
outros detectores com propriedades relevantes. Os tr√™s kernels baseados em difus√£o aniso-
tr√≥pica do detector KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012) e o gerado
pelo centro e arredores usando estruturas poligonais CenSurE (AGRAWAL; KONOLIGE;
BLAS, 2008) usando tanto um pol√≠gono convexo de seis lados e um pol√≠gono estrelado de
tamb√©m seis lados.

5.3.1 Procedimento de Avalia√ß√£o

Os resultados s√£o avaliados quanto ao crit√©rio de repetibilidade descrito em (SCH-
MID; MOHR; BAUCKHAGE, 2000). Tal crit√©rio indica a porcentagem dos pontos de
interesse que se repetiram, ou seja, ainda foram encontrados ap√≥s a aplica√ß√£o da trans-
forma√ß√£o.

Primeiramente computa-se ùëÅ = 1000 pontos de interesse para cada detector na
imagem com a turbidez ùëá0 e para todos os n√≠veis ùëá1...ùëá19. Os ùëÅ pontos de interesse
selecionados s√£o os N melhores pontos de interesse segundo o crit√©rio do detector, no caso
Hessian ou Harris. Na imagem com turbidez ùëá0 √© selecionada cada ponto-chave e √© testado
se esse ponto √© resistente na presen√ßa de turbidez. Para esse ponto-chave ser resistente √©
necess√°rio que o mesmo seja encontrado nas imagens turvas sem sofrer um deslocamento
maior que um fator de ùëí = 5 pixeis. Esse valor √© determinado de forma a escolher somente
os melhores pontos de interesse. Subsequentemente, para determinar a repetibilidade de
um certo detector, o n√∫mero de pontos chaves encontrados em cada imagem t√∫rbida s√£o
contados. Considerando essa quest√£o, a repetibilidade quanto ao degrada√ß√£o por turbidez

78

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

(ùëÖ) √© calculada como:

ùëÖ = ùëÅùëñ
ùëÅ0

(5.1)

Onde ùëÅ0 √© o n√∫mero de pontos de interesse na imagem limpa (capturada em ùëá0) e ùëÅùëñ √©
a imagem com a degrada√ß√£o estimada.

Para medir a degrada√ß√£o causada pela turbidez, foi usado uma vers√£o diferente do
SDI (WANG et al., 2004) (GARCIA; GRACIAS, 2011). O √≠ndice SDI n√£o responde com
os mesmos valores para as mesmas quantidades de turbidez. Por esta raz√£o, foi utilizado
uma vers√£o normalizada do SDI. Considerando a imagem ùëá19 como sendo totalmente
degradada, pode-se medir o SDI como uma percentagem da degrada√ß√£o m√°xima, o que
facilita a compara√ß√£o:

ùëÅ ùëÜùê∑ùêºùëñ = ùëÜùê∑ùêºùëñ/ùëÜùê∑ùêºùëÅ

(5.2)

Onde ùëÜùê∑ùêºùëÅ √© o √≠ndice de degrada√ß√£o da imagem ùëá19.

5.3.2 Compara√ß√£o

A Figura 24, mostra os gr√°ficos com os valores de repetibilidade para as tr√™s fotos
impressas (ùëÉ1,ùëÉ2,ùëÉ3) testando multiplos detectores. No eixo ùë• √© mostrado o indice ùëÅ ùëÜùê∑ùêº
e a quantidade de leite adicionada.

Da Figura 24, s√£o mostrados as analises para tr√™s intervalos diferentes de degra-
da√ß√£o causada por turbidez baseado no NSDI . Desde 0 a 0.25 de ùëÅ ùëÜùê∑ùêº foi considerado
como um ambiente de Baixa Turbidez(Fig. 23 segunda linha). Nestes casos a maioria da
informa√ß√£o estrutural √© mantida e o backscattering √© m√≠nimo. No intervalo de 0.25 at√©
0.75 foi considerado como imagens de parte de um intervalo de M√©dia Turbidez( Fig. 23
terceira linha). Nestes n√≠veis, a informa√ß√£o estrutural √© parcialmente mantidas, mas as
bordas passam a ser mal definidas. Ao final, desde 0.75 at√© 1, em Alta Turbidez(Fig. 23
quarta linha), quase nenhuma informa√ß√£o estrutural √© mantida. Nestes n√≠veis, os detec-
tores podem somente fazer uso de algumas poucas pistas visuais que ainda resistiram a
turbidez.

Para todos os intervalos de turbidez, √© poss√≠vel separar claramente os detectores

analisados em quatro grupos.

Os detectores baseados em √∫nica escala (Azul Fig. 24) obtiveram os melhores
resultados em todos os intervalos de turbidez. Comparado com outras compara√ß√µes de
detectores de pontos de interesse (GIL et al., 2010) (CRISTINACCE; COOTES, 2006),
a superioridade dos detectores n√£o invariantes a escala em compara√ß√£o a aqueles que s√£o

5.3. Resultados

79

Figura 24 ‚Äì Repetibilidade ( Taxa de Acerto) contra o indice de degrada√ß√£o estrutural
normalizado (NSDI). As linhas em laranja indicam os intervalos de degrada√ß√£o. Baixa
Turbidez 0 at√© 0.25; M√©dia Turbidez, 0.25 at√© 0.75, e Alta Turbidez de 0.75 at√© 1.

80

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

invariantes a escala, em situa√ß√µes onde a escala n√£o varia, √© mais expressiva. O detector
Harris foi melhor para o caso de ùëÉ1 (Fig. 24a) at√© um n√≠vel m√©dio de turbidez. Ap√≥s isso
o mesmo teve um decaimento maior, quando as estruturas come√ßaram a se perder.

O detector baseado em espa√ßos de escala com difus√£o anisotr√≥pica, obteve os piores
resultados (Vermelho Fig. 24). Isso √© o oposto do que √© mostrado em cenas fora d‚Äô√°gua
(ALCANTARILLA; BARTOLI; DAVISON, 2012). O algoritmo KAZE necessita calcular
as respostas das bordas antes de obter o espa√ßo de escala. Isso √© mais dificil em ambientes
subaqu√°ticos devido a suas propriedades naturais. Por√©m, no intervalo de Baixa Turbidez,
KAZE foi capaz de obter uma repetibilidade maior que o FastHessian e o DoG, dado que
as bordas ainda est√£o bem definidas. Para o caso de M√©dia Turbidez, a taxa de acerto cai
rapidamente, chegando a zero em Alta Turbidez.

Os melhores resultados para n√≠veis de media e alta turbidez, foram, de fato, obtidos
pelo detector DoG (LOWE, 2004). O detector Fast Hessian, possui uma aproxima√ß√£o mais
brusca do espa√ßo de escala a qual tende a produzir artefatos. Por isso, tratou-se do pior
resultado dentre os analisados.

CenSurPoly e o CenSurStar apresentaram resultados similares ao Kaze tendo pi-

ores resultados para n√≠veis mais altos de turbidez.

A Figura 25 mostra a compara√ß√£o de um determinado n√≠vel de espa√ßo de escala
gerado por um kernel gaussiano , um kernel baseado em caixas (FastHessian), um kernel
baseado em pol√≠gonos estrelados (CenSurE) e um gerado pelo filtro anisotr√≥pico (KAZE)
ùëî2 da Eq. 1.12 . Tais kernels s√£o aplicados em m√∫ltiplos n√≠veis de turbidez, sendo que
cada linha da figura apresenta um n√≠vel de turbidez diferente.

√â poss√≠vel perceber que a informa√ß√£o estrutural se mant√©m mais para o pol√≠gono
estrelado. O que justifica o seu estudo, principalmente para o caso de maior turbidez. J√°
o KAZE tamb√©m possui um comportamento interessante, por√©m muito da informa√ß√£o
tende a se perder com a turbidez para um mesmo n√≠vel de escala.

Como mostrado no Cap√≠tulo 4, Se√ß√£o 4.1 , existe um comportamento de borra-
mento regido por um certo fen√¥meno. √â poss√≠vel que fun√ß√µes, como as utilizadas pelo
CenSurE e o KAZE, as quais tendem a n√£o seguir o comportamento do borramento cau-
sado pelas propriedades do meio subaqu√°tico, tendam a manter as estruturas geom√©tricas
, e , ao encontrar pontos que possuem m√°ximo sobre escala, encontrem regi√µes em que
ainda existe informa√ß√£o visual provida pela imagem.

5.4 Conclus√µes finais

Este cap√≠tulo apresentou a avalia√ß√£o a invari√¢ncia a degrada√ß√£o em ambientes
subaqu√°ticos para detectores de pontos de interesse mais utilizados na literatura. Foi

5.4. Conclus√µes finais

81

Figura 25 ‚Äì Compara√ß√£o entre a gera√ß√£o de um n√≠vel do kernel do espa√ßo de escala usado
por quatro detectores diferentes. O kernel foi aplicado em n√≠veis de turbidez diferentes
para a imagem ùëÉ1. Sendo que a primeira linha √© a imagem limpa (ùëá0), a segunda linha
√© uma imagem com baixo n√≠vel de degrada√ß√£o (ùëá4), a terceira linha apresenta uma ima-
gem com m√©dio n√≠vel de degrada√ß√£o (ùëá10), a quarta linha apresenta imagens do n√≠vel de
degrada√ß√£o alto (ùëá16). Para cada caso √© mostrado o resultado de filtro equivalente a a
aproximadamente um kernel gaussiano de ùúé = 59.0. Primeira Coluna: Gaussiano puro.
Segunda Coluna: Borramento aproximado em caixas . Terceira Coluna: Difus√£o utilizando
um pol√≠gono estrelar de seis pontas. Quarta Coluna: kernel anisotr√≥pico g2 do KAZE. √â
poss√≠vel ver de certa forma estruturas mais definidas para o esquema de difus√£o usado
pelo CenSurE (AGRAWAL; KONOLIGE; BLAS, 2008).

proposto um novo dataset, completamente aberto, usando fotos impressas reais as quais
tinham uma quantidade controlada de turbidez.

Foi conclu√≠do que para, imagens subaqu√°ticas, m√©todos de √∫nica escala tem uma
repetibilidade consideravelmente melhor que abordagens de multipla escala. Entre Harris
(HARRIS; STEPHENS, 1988) e Hessian (BEAUDET, 1978), Hessian obteve resultados
melhores principalmente para n√≠veis mais altos de turbidez e em imagens onde h√° pouca
informa√ß√£o estrutural.

82

Cap√≠tulo 5. Testes e Resultados 1: Detec√ß√£o de Pontos de Interesse em Ambiente Subaqu√°tico

Considerando m√∫ltipla escala, foram avaliados novos detectores os quais n√£o usam
os espa√ßos de escala Gaussianos. Foi proposto que nestes espa√ßos diferentes, como os center
surround ou os baseados em difus√£o anisotr√≥pica, a difus√£o n√£o acontece com a mesma
estrutura que o fen√¥meno de degrada√ß√£o da turbidez, assim ent√£o produzindo melhores
resultados, em alguns n√≠veis de turbidez.

Os melhores resultados para m√∫ltipla escala foram obtidos pelo DoG (LOWE,
2004) Tamb√©m mostrou-se que o KAZE (ALCANTARILLA; BARTOLI; DAVISON, 2012)
apresenta resultados relevantes mas tende a perder precis√£o em n√≠veis mais altos de tur-
bidez.

Finalmente, a avalia√ß√£o proposta mostra que um espa√ßo de escala n√£o Gaussiano
pode tamb√©m produzir melhores resultados. Como trabalho futuro, buscar-se-√° explorar
que espa√ßos de escala que consideram a degrada√ß√£o causada pela turbidez de forma a
obter melhores resultados de repetibilidade.

6 Testes e Resultados 2: Contexto em Clas-

sifica√ß√£o Subaqu√°tica

83

Aqui s√£o apresentados os resultados de aplica√ß√£o do m√©todo proposto baseado em
Geoestat√≠stica (no Cap. 3), comparado com outros m√©todos, com e sem a incorpora√ß√£o
do contexto.

O m√©todo ser√° aplicado em mosaicos de imagens do assoalho oce√¢nico, para obten-
√ß√£o de mapas tem√°ticos. As imagens resultantes s√£o a representa√ß√£o final de um mosaico,
feito de forma visualmente interpret√°vel, contendo a classifica√ß√£o realizada de forma pixel-
a-pixel.

O cap√≠tulo apresenta os datasets, compostos por mosaicos, utilizados como caso de
teste para a classifica√ß√£o e tamb√©m as configura√ß√µes utilizadas para os testes e, por fim,
os resultados da classifica√ß√£o dos mosaicos s√£o mostrados.

6.1 Datasets Utilizados

Para avalia√ß√£o dos resultados obtidos foi proposto utilizar dois datasets distintos
de mosaicos de recifes de corais. Cada dataset √© composto por um mosaico obtido pela
jun√ß√£o de centenas de imagens coletadas por especialistas da Universidade de Miami.

O dataset Redsea cont√©m imagens do Mar Vermelho, capturadas em √°guas bastante
rasas perto da cidade de Eilat, como parte de uma pesquisa por ecologistas de recifes
de corais (ZVULONI et al., 2009). Para a classifica√ß√£o, foram considerado cinco classes:
Urchin, Branching Coral, Brain Coral, Favid Coral e o Background. Os mosaicos utilizados
foram capturados a uma resolu√ß√£o de 1.1 ùëùùëñùë•ùëíùëñùë†/ùëöùëö2.

O segundo dataset chamado Marker, foi capturado nas Bahamas. Foi feita a divis√£o
em quatro classes para classifica√ß√£o. General Corals, Sea Gorgons, Sand e Background.
Os mosaicos utilizados foram capturado em uma resolu√ß√£o de 2.2 ùëùùëñùë•ùëíùëñùë†/ùëöùëö2.

6.2 Descri√ß√£o do Geral do Sistema

Nesta se√ß√£o √© descrito uma vers√£o geral do sistema, tanto para a classifica√ß√£o em

n√≠vel un√°rio, quanto os tipos de classifica√ß√£o integrando contexto.

84

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

6.2.1 Pr√©-Processamento

Tanto para os dados do dataset Redsea quanto para o caso do dataset Marker , a
qualidade visual da imagem √© bastante satisfat√≥ria, contendo baixa presen√ßa de degrada-
√ß√£o devido a turbidez. O principal tipo de degrada√ß√£o encontrado √© a varia√ß√£o de cor ao
longo do datasets existentes durante a captura. Para resolver esta quest√£o foi utilizado
CLAHE (ZUIDERVELD, 1994) e uma normaliza√ß√£o de cor em ambos os datasets.

6.2.2 Segmenta√ß√£o e Descri√ß√£o

Os datasets foram segmentados como superpixeis baseados em TurboPixels (LE-
VINSHTEIN et al., 2009). O tamanho do pixel foi escolhido como que para caber em uma
janela de tamanho de aproximadamente 32x32 pixeis.

Para cada superpixel, a combina√ß√£o entre tr√™s descritores de textura foi utilizada.
Filtros de Gabor, CLBP e GLCM. Um kernel mapping √© feito depois para tornar os
descritores mais linearmente separ√°veis. O resultado √© tamb√©m por fim, normalizado.

6.2.3 Classifica√ß√£o

No caso, para todos os testes, foi utilizado um SVM configurado com um kernel

linear.

6.2.4

Adi√ß√£o de Contexto

A adi√ß√£o de contexto √© apresentada feita de duas formas distintas: utilizando os
Conditional Random Fields (CRF) e utilizando o modelo de Geoestat√≠stica, o quais foram
explicados nos Cap√≠tulos 2 e 3.

Para o CRF utilizado o algoritmo de Loopy Belief Propagation(LBP) para realizar
a infer√™ncia estat√≠stica, dado a sua baixa taxa de erros e alta performance (WEISS, 2000).

6.3 Treinamento

Aqui √© descrito como foi realizado o treinamento das partes do sistema onde o

treinamento √© necess√°rio.

6.3.1 Treinamento do Classificador

O treinamento un√°rio diz respeito ao treinamento da fun√ß√£o de discrimina√ß√£o do

classificador.

6.3. Treinamento

85

Tanto para o dataset Redsea quanto para o Marker foram feitas diversas amostra-
gens dos mosaicos existentes para o treinamento do classificador de cada uma das classes.
A Figura 26, mostra exemplos de segmentos usados para o treinamento do classificador
para os dois datasets utilizados. Foram feitas amostras de por volta de 200 segmentos
para cada classe sendo cada uma tendo 64x64 pixeis. As amostras foram indicadas por
especialistas da universidade de Miami.

Figura 26 ‚Äì Partes manualmente segmentadas utilizadas para treinamento do classifica-
dor. A esquerda s√£o mostrados exemplos de nove amostras usadas para treinar o dataset
Redsea. A direita s√£o apresentadas nove amostras do dataset Marker.

6.3.2 Treinamento Un√°rio

Para gerar a curva de confian√ßa, usada para gerar os distribui√ß√£o de probabilida-
des un√°ria tanto para o CRF, quanto para o modelo de Geoest√°tistica, foram tamb√©m
utilizadas amostras do mosaico de treinamento da Figura 26.

As Figuras 27 e 28 mostram as curvas de confian√ßa obtidas para cada um dos
dois datasets em cada uma das classes. O processo de gera√ß√£o das curvas √© descrito no
Cap√≠tulo 3 Se√ß√£o 3.2.

Pelos gr√°ficos das Figuras 27 e 28 percebe-se que determinadas classes se adaptam
melhor que outras a uma curva de confian√ßa, como a classe Sea Gorgon ( Fig. 28c) do
dataset Marker. Para esta classe √© poss√≠vel saber quais dist√¢ncias do classificador que
existe uma grande probabilidade de se acertar a classe, enquanto para outras o modelo
n√£o se adaptou t√£o adequadamente (Fig. 29b).

Entretanto, o principal erro em adapta√ß√£o da curva se da na classe Background
para os dois casos (Fig. 27a e Fig. 29a). Isso se da devido a alta variabilidade intra-classe
inerente a classe Background, a qual cont√©m todos os tipos de objetos que n√£o s√£o de
interesse para classifica√ß√£o.

86

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

(a) Classe Background

(b) Classe Urchin

(c) Classe Branching Coral

(d) Classe Brain Coral

(e) Classe Faviid Coral

Figura 27 ‚Äì Curvas de confian√ßa geradas no treinamento un√°rio de cada classe para o
dataset Redsea. A curva de confian√ßa ùê∂ùëôùëñ treinada para cada uma das classes √© mostrada,
se bem como o grau de confian√ßa obtido.

6.3.3 Treinamento Potenciais Locais

Para treinamento dos potenciais locais foi utilizado cada dataset na sua totalidade.
Para o caso do CRF foi utilizado o algoritmo de treinamento descrito no Cap√≠tulo

2, Se√ß√£o 2.2.2.2 .

As Tabelas 2 e 3 mostram a matriz de covari√¢ncia obtida para cada um dos dois
datasets. Tal matriz est√° relacionada a uma indica√ß√£o de determinada classe estar pr√≥xima
a outra.

Background Urchin Branching Coral Brain Coral Faviid Coral

Classes
Background
Urchin
Branching Coral
Brain Coral
Faviid Coral
Tabela 2 ‚Äì Matriz de covari√¢ncia que mostra as rela√ß√µes de proximidade entre as classes.
Tais medidas s√£o fatores que indicam correla√ß√£o e n√£o distribui√ß√µes de probabilidade. Este
resultado √© normalizado ao final.

0.8559
0.9458
1.3870
0.9461
0.9111

1.9115
0.7844
0.7658
0.8767
0.7612

0.8599
0.9679
0.9897
0.9605
0.9427

0.9094
0.9670
1.0219
1.6384
0.9353

0.8400
1.0424
0.9745
0.8972
1.6972

Os resultados do treinamento dos vetores de transi√ß√£o, necess√°rios para a simula√ß√£o

6.3. Treinamento

87

(a) Classe Background

(b) Classe General Corals

(c) Classe Sea Gorgon

(d) Classe Sand

Figura 28 ‚Äì Curvas de confian√ßa geradas no treinamento un√°rio de cada classe para o da-
taset Marker. A curva de confian√ßa ùê∂ùëôùëñ treinada para cada uma das classes √© apresentada,
bem como o grau de confian√ßa obtido.

Background General Coral

Classes
Background
General Coral
Sea Gorgon
Sand

1.8831
0.9010
0.8905
0.8950

0.8967
0.9544
0.9516
0.8990

Sea Gorgon Sand
0.9086
0.9028
0.8930
1.8773

0.8899
0.9507
0.9738
0.8906

Tabela 3 ‚Äì Matriz de covari√¢ncia que mostra as rela√ß√µes de proximidade entre as classes.
Tais medidas s√£o fatores que indicam correla√ß√£o e n√£o distribui√ß√µes de probabilidade. Este
resultado √© normalizado ao final.

do m√©todo de Geoestat√≠stica, s√£o mostrados na Figura 29 para ambos os datasets testados.
Para ambos os datasets analisados se observa a classe background como sendo
predominante nas estat√≠sticas medidas em ambos os treinamentos. No caso do treinamento
dos vetores de transi√ß√£o (Geoestat√≠stica), tamb√©m foi vista uma tend√™ncia de outras classes
em transitar para o Background (Fig. 29). Algo que, para o treinamento dos potenciais
locais do CRF, indicou principalmente uma tend√™ncia do Background ter proximidade
consigo pr√≥prio.

Para o dataset Redsea, nas rela√ß√µes locais treinadas pelo CRF se observa algumas

tend√™ncias:

88

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

(a) Dataset Redsea

(b) Dataset Marker

Figura 29 ‚Äì Vetores de transi√ß√£o obtidos na etapa de treinamento para o m√©todo de
Geoestat√≠stica do Cap√≠tulo 3. Os vetores indicam a probabilidade de uma classe transitar
para outra a uma determinada dist√¢ncia. O eixo x apresenta a dist√¢ncia em pixeis. O eixo
ùë¶ dos gr√°ficos apresenta as probabilidades de transi√ß√£o. Pode-se observar, por exemplo,
uma certa tend√™ncia na classe Urchin em transitar para categoria de background.

6.4.

Sistemas Testados

89

‚àô As classes Urchin tem uma grande possibilidade de estar pr√≥xima a classe Faviid

Coral;

‚àô Cada classe tem uma forte tend√™ncia de estar pr√≥xima a si pr√≥pria, o que enfatiza

a pouca variabilidade de classes em espa√ßos pequenos;

‚àô Existe algumas tend√™ncias assim√©tricas treinadas, como a grande tend√™ncia da classe

Faviid Coral estar pr√≥xima da classe Urchin, mas n√£o ao contr√°rio.

As transi√ß√µes assim√©tricas, ou seja, uma dada classe A estar pr√≥xima a classe B
mas n√£o B pr√≥xima da A, n√£o s√£o incentivadas pelos potenciais treinados pelo m√©todo de
Geoestat√≠stica.

Considerando as rela√ß√µes treinadas pelo m√©todo de Geoestat√≠stica, existe uma
tend√™ncia forte principalmente de transi√ß√£o da classe Urchin para a classe Faviid Coral e
a classe Background.

Para o dataset Marker, nenhuma outra tend√™ncia de proximidade foi obtida para
o CRF, fora a tend√™ncia de background estar pr√≥ximo de si mesmo. As mesmas tend√™ncias
s√£o observadas para o treinamento dos vetores de transi√ß√£o para o caso da Geoestat√≠stica.

6.4

Sistemas Testados

Quatro sistemas s√£o testados quanto a sua taxa de acerto em rela√ß√£o a classifica√ß√£o
de mosaicos de imagens. Isso foi feito principalmente de forma a avaliar a considera√ß√£o
de contexto, juntamente com a nova proposta apresentada no Cap√≠tulo 3

Inicialmente foi avaliado o sistema Un√°rio, proposto por Shihavuddin et al. (2013)
onde somente as informa√ß√µes un√°rias s√£o consideradas, ou seja, dada a defini√ß√£o de classifi-
ca√ß√£o considerando uma segmenta√ß√£o em regi√µes (SHIHAVUDDIN et al., 2013). Somente
a descri√ß√£o da pr√≥pria regi√£o foi usada para classifica√ß√£o, o sistema √© detalhado no Cap.
4 .

Ap√≥s foi testado e analisado o sistema Un√°rio por√©m baseado em distribui√ß√£o de
probabilidades. Em tal sistema foi feita a classifica√ß√£o apenas considerando a parcela un√°-
ria do sistema com base no modelo em Geoestat√≠stica proposto no Cap. 3. A classifica√ß√£o
de um segmento foi escolhida como o r√≥tulo com m√°xima a probabilidade.

Apresenta-se tamb√©m o sistema, GS, baseado em Geoestat√≠stica proposto no Cap.

3. A classifica√ß√£o de cada segmento (Superpixel) √© dada pela Eq. 3.1, do Cap. 3.

Por fim, apresenta-se os resultados do sistema CRF o qual √© uma implementa√ß√£o

dos Conditional Random Fields , tal qual explicada no Cap 2.

90

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

Todos os sistemas foram implementados em Matlab, para o CRF, foi utilizada a

biblioteca UGM para infer√™ncia estat√≠stica (SCHMIDT et al., 2009).

6.5 Computa√ß√£o do Mapa Tem√°tico

No dataset Redsea, um mosaico de 3256x2939 pixeis foi utilizado para testes. J√°

para dataset Marker,foi utilizado um mosaico de 2592x3963.

As Figuras 30 e 31 mostram os mapas tem√°ticos completos computados para ambos

os datasets.

Observa-se que num caso geral o CRF √© o m√©todo que obt√©m os melhores resulta-
dos. O m√©todo de Geoestat√≠stica √© capaz de melhorar um pouco, por√©m depende muito
de um bom treinamento da distribui√ß√£o de probabilidades de cada segmento.

Para o caso do dataset Marker, a adi√ß√£o de contexto foi mais eficaz para ambos os
casos. Isso ocorre dado que muitas posi√ß√µes geraram resultados com distribui√ß√£o un√°ria
uniforme, ou seja sem uma classe com alta probabilidade. O que contribuiu para adi√ß√£o
de contexto foi, que tais regi√µes, estavam cercadas por locais onde existia uma classe
predominante.

Ao se observar a configura√ß√£o do dataset Redsea se percebe uma tend√™ncia espacial
em se ter "ilhas"de classes envolvidas pela classe background. Dado que a classe background
tem uma alta variabilidade intra-classe, √© bastante complicado se ter uma tend√™ncia forte
para uma classe na distribui√ß√£o un√°ria. Isso dificulta a prolifera√ß√£o da informa√ß√£o de
contexto na regi√£o.

De forma a analisar melhor as diferen√ßas entre o CRF e o m√©todo de Geoestat√≠stica,
√© mostrado na Figura 32 duas √°reas diferentes do mosaico do Redsea para mostrar algumas
vantagens da abordagem com base em GS. √â apresentada a √°rea original da imagem com
a classifica√ß√£o mostrada em cores. Na primeira linha, pode se perceber o grau de acerto
maior para o CRF (Fig. 32c). O CRF tende a melhorar significativamente a suaviza√ß√£o
local das estruturas classificadas. Ou seja, imp√µe que √°reas pequenas devam ter menos
varia√ß√µes de classes. Por esta raz√£o o CRF teve uma boa classifica√ß√£o especialmente para
o caso da classe representada em azul (Faviid Corals).

Por outro lado, na segunda linha, GS (Fig. 32f) obteve um grau de acerto maior.
Dado que o CRF (Fig. 32g) imp√µe mais suavidade local, isso tende a eliminar classes
menores (Fig. 32g). Este caso √© evitado pela GS pelo fato de que a abordagem baseada
em Geostat√≠stica usa estat√≠sticas medidas em longas dist√¢ncias e assim o tamanho da
classe √© considerado. Na terceira linha da Figura 32, s√£o mostrados resultados similares
para o dataset Marker.

Tamb√©m os algoritmos foram testados para m√∫ltiplos segmentos diferentes extra√≠do

6.6. Conclus√µes

91

Tamanho do Segmento

Unitary

GS
CRF
Voting

1700

1100

500
2300 M√©dia
81.1% 78.0% 79% 80.2% 79.7%
81.2% 78.3% 79% 80.2% 79.8%
80.5% 78.9% 79.3% 79.7% 79.8%
78%
78% 78.4% 80.2% 79.2%

Tabela 4 ‚Äì Resultados para a taxa de acerto de diferentes segmentos para o dataset Redsea.
Foram testados diversos segmentos quadrados amostrados aleatoreamente nos mosaicos.
O tamanho do segmento √© especificado pelo lado do quadrado

dos mosaicos. Foram recortadas amostras quadradas aleat√≥rias de diferentes tamanhos.
Para cada tamanho recortado, a tabela 4 mostra a taxa de acerto m√©dia do m√©todo
aplicado em 20 segmentos aleat√≥rios. Tamb√©m foi testado um m√©todo simples de vota√ß√£o
onde um superpixel √© modificado caso a classe de todos os vizinhos seja differente.

No dataset Redsea, para todas as abordagens , n√£o foi percebido mais do que ganhos
marginais quando comparados com a vers√£o unit√°ria. O m√©todo de vota√ß√£o tamb√©m
obteve resultados similares.

6.6 Conclus√µes

Conclui-se que o uso de estat√≠sticas mais ricas, inspiradas pelos conceitos de Geo-
estat√≠sticas, √© ben√©fico e pode conduzir a melhores resultados que o CRF tradicional em
alguns casos.

As melhorias obtidas, foram, no entanto, de pequena magnitude, o que esta ali-
nhado com o que √© discutido em (LUCCHI et al., 2011). Os resultados utilizando contexto
normalmente n√£o melhoram mais do que a suavidade local dos resultados, ou seja, n√£o
mais do que evitam grande varia√ß√£o de classes em uma pequena √°rea. Por√©m ainda √©
poss√≠vel obter melhorias significativas, para alguns datasets como no caso do Marker.

92

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

(a) Unit√°rio 76.83%

(b) Unit√°rio com Curvas de Confian√ßa 75.779%

(c) Geoestat√≠stica 76.16%

(d) CRF 77.32%

(e) Ground Truth

Figura 30 ‚Äì Mapa tem√°tico dos Mosaicos para o dataset Redsea. As figuras mostram a
porcentagem de acerto relativa ao GroundTruth. As classes s√£o representadas pelas se-
guintes cores: Verde Brain Coral; Amarelo Branchin Coral; Azul Faviid Coral; Magenta
Urchin e sem cor √© o background. Os seguintes resultados s√£o mostrados.(30a) classifica-
√ß√£o Un√°ria. (30b) mostra a classifica√ß√£o Un√°ria baseada nas curvas de confian√ßa. (30c)
classifica√ß√£o com adi√ß√£o de contexto baseada em Geoestat√≠stica. (30d) classifica√ß√£o com
adi√ß√£o de contexto utilizando CRF.

6.6. Conclus√µes

93

(a) Unit√°rio 78.04%

(b) Unit√°rio com Curvas de Confian√ßa 78.02%

(c) Geoestat√≠stica 79.2%

(d) CRF 83.26%

(e) Ground Truth

Figura 31 ‚Äì Mapa tem√°tico dos Mosaicos para o dataset Marker. As figuras mostram a
porcentagem de acerto relativa ao GroundTruth. As classes s√£o representadas pelas se-
guintes cores: Verde Sand; Amarelo Sea Gorgon; Azul Corals e sem cor √© o background.
Os seguintes resultados s√£o mostrados.(31a) classifica√ß√£o Un√°ria. (31b) mostra a classifi-
ca√ß√£o Un√°ria baseada nas curvas de confian√ßa. (31c) classifica√ß√£o com adi√ß√£o de contexto
baseada em Geoestat√≠stica. (31d) classifica√ß√£o com adi√ß√£o de contexto utilizando CRF.

94

Cap√≠tulo 6. Testes e Resultados 2: Contexto em Classifica√ß√£o Subaqu√°tica

(a) 0.6985

(b) 0.6988

(c) 0.745

(d) Ground Truth

(e) 0.859

(f) 0.8691

(g) 0.858

(h) Ground Truth

(i) 0.756

(j) 0.77

(k) 0.763

(l) Ground Truth

Figura 32 ‚Äì Resultados de classifica√ß√£o para os datasets Marker e os datasets Redsea. A
primeira coluna apresenta a classifica√ß√£o unit√°ria. A segunda coluna apresenta os resulta-
dos de Geoestat√≠stica. A terceira coluna apresenta os resultados para o CRF. Por fim, a
ultima coluna apresenta o GroundTruth. Foi utilizada como peso para o potencial local ùë§ùëô
como sendo 0.4 para ambas as abordagens. Na primeira coluna foi poss√≠vel perceber um
resultado melhor para o CRF devido a uma maior suaviza√ß√£o local. Na segunda linha, o
m√©todo de Geoestat√≠stica obteve melhores resultados devido a suas medidas estat√≠sticas
de longa dist√¢ncia. Na √∫ltima linha √© mostrado os resultados para o dataset Marker, onde
ambas as abordagens tiveram melhores resultados para esse caso.

7 Conclus√µes Finais

95

Considerando o problema de estender a utiliza√ß√£o de m√©todos de vis√£o computaci-
onal para o cen√°rio subaqu√°tico, esta disserta√ß√£o apresentou o estudo e tratamento para
alguns dos principais problemas existentes no meio.

Foi feito um estudo sobre duas √°reas distintas relevantes para o problema: A detec-
√ß√£o de pontos de interesse e o uso da informa√ß√£o de contexto na classifica√ß√£o de imagens.
Nas se√ß√µes que seguem ser√£o apresentadas as contribui√ß√µes sobre as duas √°reas

distintas analisadas, como tamb√©m as limita√ß√µes das propostas.

7.1 Detectores de Pontos de Interesse em Imagens Subaqu√°ticas

Turvas
No contexto subaqu√°tico, foi feito um estudo sobre como se comportam os m√∫lti-
plos detectores de pontos de interesse sobre a presen√ßa da turbidez, fen√¥meno o qual se
faz presente no meio subaqu√°tico.

7.1.1 Contribui√ß√µes Obtidas

As principais contribui√ß√µes obtidas foram:

‚àô A proposta de um dataset novo contendo imagens reais do assoalho oce√¢nico por√©m

com a turbidez controlada.

‚àô Uma an√°lise geral da repetibilidade dos detectores em meios t√∫rbidos, dividindo a

an√°lise em intervalos de turbidez distintos.

‚àô Dentre os detectores estudados, foi apontado o DoG como o mais robusto detector
para ambientes com presen√ßa de turbidez. Tal detector cont√©m tamb√©m invari√¢ncia
a escala.

‚àô Foi conclu√≠da a possibilidade do uso de espa√ßos n√£o gaussianos para gera√ß√£o de

espa√ßo de escala em meios subaqu√°ticos t√∫rbidos.

7.1.2 Limita√ß√µes e Trabalhos Futuros

O estudo n√£o foi capaz de propor um m√©todo para medir de fato a degrada√ß√£o
causada pela turbidez. A medida utilizada √© capaz de verificar a degrada√ß√£o estrutural o
que n√£o necessariamente est√° associada a turbidez.

96

Cap√≠tulo 7. Conclus√µes Finais

Um outro ponto a ser tratado diz respeito a uma an√°lise mais criteriosa com
respeito a invari√¢ncia a outras transforma√ß√µes como rota√ß√£o ou escala, juntamente com a
robustez √† degrada√ß√£o causada pela turbidez.

7.2 Adi√ß√£o de Contexto Baseado em Geoestat√≠stica

Foi proposto um novo m√©todo para adicionar informa√ß√£o espacial na classifica√ß√£o
de imagens. O m√©todo se baseou nos estudos da √°rea de Geoestat√≠stica. Tal m√©todo foi
aplicado em imagens de mosaicos de recifes de corais. O mesmo foi comparado com as
vers√µes sem a utiliza√ß√£o de contexto e com o modelo dos Conditional Random Fields
(CRF).

Apresentou-se que a adi√ß√£o de contexto pode, em alguns casos, ser ben√©fica para
a classifica√ß√£o de imagens subaqu√°ticas. Obtendo-se um ganho de at√© 5% a mais em taxa
de acerto.

7.2.1 Contribui√ß√µes Obtidas

O trabalho apresentou um novo m√©todo para adi√ß√£o de contexto em imagens su-
baqu√°ticas. O uso de medidas estat√≠sticas mais ricas, como as baseadas em Geoestat√≠stica,
mostrou-se √∫til em algumas situa√ß√µes para adi√ß√£o de informa√ß√£o de contexto.

Tamb√©m essa disserta√ß√£o serve como uma conex√£o entre duas √°reas distintas: a
Geoestat√≠stica e os Modelos Probabil√≠stico Gr√°ficos (MPGs). Acredita-se que atrav√©s desta
intersec√ß√£o, as aplica√ß√µes que fazem uso de Geoestat√≠stica podem tamb√©m se beneficiar
dos MPGs.

7.2.2 Limita√ß√µes e Trabalhos Futuros

Coloca-se que a abordagem apresentada foi aplicada para um cen√°rio subaqu√°tico
espec√≠fico. Uma dire√ß√£o seria a aplica√ß√£o em dataset com classes mais gen√©ricas, os da
Pascal Visual Object Classes Challenge (VOC) (EVERINGHAM et al., 2010).

Os resultados para o m√©todo de Geoestat√≠stica foram satisfat√≥rios por√©m ficaram
abaixo em taxa de acerto quando comparados ao CRF. Apesar da tend√™ncia de se usar os
m√©todos de Geoestat√≠stica para casos onde h√° pouca quantidade de informa√ß√µes (CARLE;
FOGG, 1996).

Existe ainda uma necessidade maior de altera√ß√£o no modelo original de Geoesta-

t√≠stica visando uma melhor adapta√ß√£o para o caso de imagens subaqu√°ticas.

Refer√™ncias

97

ABFALG, J. et al. Multi-represented classification based on confidence estimation. In:
Advances in Knowledge Discovery and Data Mining. [S.l.]: Springer, 2007. p. 23‚Äì34.
Citado 2 vezes nas p√°ginas 51 e 52.
AGRAWAL, M.; KONOLIGE, K.; BLAS, M. R. Censure: Center surround extremas
for realtime feature detection and matching. In: Computer Vision‚ÄìECCV 2008. [S.l.]:
Springer, 2008. p. 102‚Äì115. Citado 4 vezes nas p√°ginas 14, 35, 77 e 81.
AGTERBERG, F. Mathematical geologymathematical geology. In: General Geology.
Springer US, 1988, (Encyclopedia of Earth Science). p. 573‚Äì582. ISBN 978-0-442-22499-8.
Dispon√≠vel em: <http://dx.doi.org/10.1007/0-387-30844-X 76>. Citado na p√°gina 55.
ALCANTARILLA, P. F.; BARTOLI, A.; DAVISON, A. J. Kaze features. In: Computer
Vision‚ÄìECCV 2012. [S.l.]: Springer, 2012. p. 214‚Äì227. Citado 5 vezes nas p√°ginas 35,
36, 77, 80 e 82.
AULINAS, J. et al. Feature extraction for underwater visual slam. In: IEEE. OCEANS,
2011 IEEE-Spain. [S.l.], 2011. p. 1‚Äì7. Citado na p√°gina 24.
BAR, M. Visual objects in context. Nature Reviews Neuroscience, Nature Publishing
Group, v. 5, n. 8, p. 617‚Äì629, 2004. Citado 2 vezes nas p√°ginas 25 e 41.
BAY, H. et al. Speeded-up robust features (surf). Computer vision and image
understanding, Elsevier, v. 110, n. 3, p. 346‚Äì359, 2008. Citado 2 vezes nas p√°ginas 33
e 77.
BAZEILLE, S. et al. Automatic underwater image pre-processing. In: CMM‚Äô06. [S.l.:
s.n.], 2006. p. xx. Citado na p√°gina 66.
BEALL, C. et al. 3d reconstruction of underwater structures. In: IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS). [S.l.: s.n.], 2010. p. 4418‚Äì4423.
Citado 2 vezes nas p√°ginas 24 e 27.
BEATTIE, C.; MILLS, B.; MAYO, V. Development drilling of the tawila field, yemen,
based on three-dimensional reservoir modeling and simulation. In: SPE annual technical
conference. [S.l.: s.n.], 1998. p. 715‚Äì725. Citado na p√°gina 49.
BEAUDET, P. R. Rotationally invariant image operators. In: Proceedings of the 4th
International Joint Conference on Pattern Recognition. Kyoto, Japan: [s.n.], 1978. p.
579‚Äì583. Citado 4 vezes nas p√°ginas 30, 71, 77 e 81.
BEIJBOM, O. et al. Automated annotation of coral reef survey images. In: IEEE.
Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. [S.l.],
2012. p. 1170‚Äì1177. Citado na p√°gina 67.
BIEDERMAN, I.; MEZZANOTTE, R. J.; RABINOWITZ, J. C. Scene perception:
Detecting and judging objects undergoing relational violations. Cognitive psychology,
Elsevier, v. 14, n. 2, p. 143‚Äì177, 1982. Citado na p√°gina 39.

98

Refer√™ncias

BOIX, X. et al. Harmony potentials. International journal of computer vision, Springer,
v. 96, n. 1, p. 83‚Äì102, 2012. Citado 2 vezes nas p√°ginas 46 e 47.
BOYKOV, Y. Y.; JOLLY, M.-P. Interactive graph cuts for optimal boundary & region
segmentation of objects in nd images. In: IEEE. Computer Vision, 2001. ICCV 2001.
Proceedings. Eighth IEEE International Conference on. [S.l.], 2001. v. 1, p. 105‚Äì112.
Citado na p√°gina 45.
CARBONETTO, P.; FREITAS, N. de; BARNARD, K. A statistical model for general
contextual object recognition. In: Computer Vision-ECCV 2004. [S.l.]: Springer, 2004. p.
350‚Äì362. Citado 2 vezes nas p√°ginas 43 e 45.
CARLE, S. F.; FOGG, G. E. Transition probability-based indicator geostatistics.
Mathematical Geology, Springer, v. 28, n. 4, p. 453‚Äì476, 1996. Citado 4 vezes nas
p√°ginas 49, 56, 57 e 96.
CARLE, S. F. et al. Conditional simulation of hydrofacies architecture: a transition
probability/markov approach. Hydrogeologic models of sedimentary aquifers, concepts
in hydrogeology and environmental geology, v. 1, p. 147‚Äì170, 1998. Citado 2 vezes nas
p√°ginas 53 e 55.
CORKE, P. et al. Experiments with underwater robot localization and tracking. In:
Robotics and Automation, 2007 IEEE International Conference on. [S.l.: s.n.], 2007. p.
4556‚Äì4561. ISSN 1050-4729. Citado na p√°gina 27.
CRISTIANINI, N.; SHAWE-TAYLOR, J. An introduction to support vector machines
and other kernel-based learning methods. [S.l.]: Cambridge university press, 2000. Citado
na p√°gina 51.
CRISTINACCE, D.; COOTES, T. F. Feature detection and tracking with constrained
local models. In: CITESEER. BMVC. [S.l.], 2006. v. 2, n. 5, p. 6. Citado na p√°gina 78.
DEMPSTER, A. P.; LAIRD, N. M.; RUBIN, D. B. Maximum likelihood from
incomplete data via the em algorithm. Journal of the royal statistical society. Series B
(methodological), JSTOR, p. 1‚Äì38, 1977. Citado na p√°gina 45.
DERPANIS, K. G.; LEUNG, E. T.; SIZINTSEV, M. Fast scale-space feature
representations by generalized integral images. In: IEEE. Image Processing, 2007. ICIP
2007. IEEE International Conference on. [S.l.], 2007. v. 4, p. IV‚Äì521. Citado na p√°gina
33.
DUNTLEY, S. Q. Light in the sea. JOSA, Optical Society of America, v. 53, n. 2, p.
214‚Äì233, 1963. Citado 2 vezes nas p√°ginas 65 e 73.
EMERY, X. Properties and limitations of sequential indicator simulation. Stochastic
Environmental Research and Risk Assessment, Springer, v. 18, n. 6, p. 414‚Äì424, 2004.
Citado na p√°gina 54.
EVERINGHAM, M. et al. The pascal visual object classes (voc) challenge. International
journal of computer vision, Springer, v. 88, n. 2, p. 303‚Äì338, 2010. Citado na p√°gina 96.
FINK, M.; PERONA, P. Mutual boosting for contextual inference. In: Advances in
neural information processing systems. [S.l.: s.n.], 2003. p. None. Citado na p√°gina 42.

Refer√™ncias

99

FISCHLER, M. A.; ELSCHLAGER, R. A. The representation and matching of pictorial
structures. IEEE Transactions on Computers, Citeseer, v. 22, n. 1, p. 67‚Äì92, 1973.
Citado na p√°gina 40.
FULKERSON, B.; VEDALDI, A.; SOATTO, S. Class segmentation and object
localization with superpixel neighborhoods. In: IEEE. Computer Vision, 2009 IEEE 12th
International Conference on. [S.l.], 2009. p. 670‚Äì677. Citado 4 vezes nas p√°ginas 41, 44,
45 e 68.
GALLEGUILLOS, C.; BELONGIE, S. Context based object categorization: A critical
survey. Computer Vision and Image Understanding, Elsevier, v. 114, n. 6, p. 712‚Äì722,
2010. Citado 3 vezes nas p√°ginas 39, 40 e 41.
GARCIA, R.; GRACIAS, N. Detection of interest points in turbid underwater images.
In: IEEE. OCEANS, 2011 IEEE-Spain. [S.l.], 2011. p. 1‚Äì9. Citado 6 vezes nas p√°ginas
24, 71, 74, 76, 77 e 78.
GIL, A. et al. A comparative evaluation of interest point detectors and local descriptors
for visual slam. Machine Vision and Applications, Springer, v. 21, n. 6, p. 905‚Äì920, 2010.
Citado 2 vezes nas p√°ginas 27 e 78.
GONZALEZ, R. C.; WOODS, R. E. Digital Image Processing (3rd Edition). Upper
Saddle River, NJ, USA: Prentice-Hall, Inc., 2006. ISBN 013168728X. Citado na p√°gina
67.
GUO, Z.; ZHANG, D. A completed modeling of local binary pattern operator for texture
classification. Image Processing, IEEE Transactions on, IEEE, v. 19, n. 6, p. 1657‚Äì1663,
2010. Citado na p√°gina 69.
HANSON, A. R.; RISEMAN, E. M. VISIONS: A computer system for interpreting
scenes. In: HANSON, A. R.; RISEMAN, E. M. (Ed.). Computer Vision Systems. New
York: Academic Press, 1978. Citado na p√°gina 40.
HARALICK, R. M.; SHANMUGAM, K.; DINSTEIN, I. H. Textural features for image
classification. Systems, Man and Cybernetics, IEEE Transactions on, IEEE, n. 6, p.
610‚Äì621, 1973. Citado na p√°gina 69.
HARRIS, C.; STEPHENS, M. A combined corner and edge detector. In: MANCHESTER,
UK. Alvey vision conference. [S.l.], 1988. v. 15, p. 50. Citado 5 vezes nas p√°ginas 29, 30,
71, 77 e 81.
JOHNSON-ROBERSON, M.; KUMAR, S.; WILLAMS, S. Segmentation and
classification of coral for oceanographic surveys: a semi-supervised machine learning
approach. In: IEEE. OCEANS 2006-Asia Pacific. [S.l.], 2007. p. 1‚Äì6. Citado na p√°gina
66.
KOLTUN; VLADLEN. Efficient inference in fully connected crfs with gaussian edge
potentials. In: . [S.l.: s.n.], 2011. Citado 2 vezes nas p√°ginas 46 e 60.
KOSCHMIEDER, H. Theorie der horizontalen Sichtweite. [S.l.]: Keim Nemnich, 1924.
Citado na p√°gina 64.
KRUPPA, H.; SCHIELE, B. Using Local Context to Improve Face Detection. 2003.
Citado na p√°gina 42.

100

Refer√™ncias

KUMAR, S.; HEBERT, M. A hierarchical field framework for unified context-based
classification. In: IEEE. Computer Vision, 2005. ICCV 2005. Tenth IEEE International
Conference on. [S.l.], 2005. v. 2, p. 1284‚Äì1291. Citado na p√°gina 40.

LEVINSHTEIN, A. et al. Turbopixels: Fast superpixels using geometric flows. Pattern
Analysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 31, n. 12, p.
2290‚Äì2297, 2009. Citado 3 vezes nas p√°ginas 49, 69 e 84.

LINDEBERG, T. Scale-space theory: A basic tool for analyzing structures at different
scales. Journal of applied statistics, Taylor & Francis, v. 21, p. 225‚Äì270, 1994. Citado 2
vezes nas p√°ginas 31 e 32.

LINDEBERG, T. On the axiomatic foundations of linear scale-space. [S.l.]: Springer,
1997. Citado na p√°gina 32.

LINDEBERG, T. Feature detection with automatic scale selection. International journal
of computer vision, Springer, v. 30, n. 2, p. 79‚Äì116, 1998. Citado na p√°gina 32.

LINDEBERG, T.; EKLUNDH, J.-O. On the computation of a scale-space primal sketch.
Journal of Visual Communication and Image Representation, v. 2, n. 1, p. 55 ‚Äì 78, 1991.
ISSN 1047-3203. Citado na p√°gina 29.

LOWE, D. G. Distinctive image features from scale-invariant keypoints. International
journal of computer vision, Springer, v. 60, n. 2, p. 91‚Äì110, 2004. Citado 8 vezes nas
p√°ginas 11, 33, 34, 45, 72, 77, 80 e 82.

LUCCHI, A. et al. Are spatial and global constraints really necessary for segmentation?
In: IEEE. Computer Vision (ICCV), 2011 IEEE International Conference on. [S.l.],
2011. p. 9‚Äì16. Citado 3 vezes nas p√°ginas 47, 49 e 91.

MARCOS, M. S. A.; SORIANO, M.; SALOMA, C. Classification of coral reef images
from underwater video using neural networks. Optics express, Optical Society of America,
v. 13, n. 22, p. 8766‚Äì8771, 2005. Citado na p√°gina 67.

MARQUARDT, D. W. An algorithm for least-squares estimation of nonlinear
parameters. Journal of the Society for Industrial & Applied Mathematics, SIAM, v. 11,
n. 2, p. 431‚Äì441, 1963. Citado na p√°gina 52.

MIKOLAJCZYK, K.; SCHMID, C. Scale & affine invariant interest point detectors.
International journal of computer vision, Springer, v. 60, n. 1, p. 63‚Äì86, 2004. Citado 2
vezes nas p√°ginas 32 e 71.

NARASIMHAN, S. G. et al. Acquiring scattering properties of participating media by
dilution. ACM Transactions on Graphics (TOG), ACM, v. 25, n. 3, p. 1003‚Äì1012, 2006.
Citado na p√°gina 73.

NEMETH, R. S. et al. Characterization of deep water reef communities within the
marine conservation district, st. thomas, us virgin islands. 2008. Citado na p√°gina 23.

NICOSEVICI, T. et al. Efficient three-dimensional scene modeling and mosaicing.
Journal of Field Robotics, v. 26, 2009. Citado 2 vezes nas p√°ginas 24 e 27.

Refer√™ncias

101

OMAR, A. F. B.; MATJAFRI, M. Z. B. Turbidimeter design and analysis: a review on
optical fiber sensors for the measurement of water turbidity. Sensors, Molecular Diversity
Preservation International, v. 9, n. 10, p. 8311‚Äì8335, 2009. Citado na p√°gina 65.

PADMAVATHI, G.; MUTHUKUMAR, M.; THAKUR, S. K. Kernel principal component
analysis feature detection and classification for underwater images. In: IEEE. Image
and Signal Processing (CISP), 2010 3rd International Congress on. [S.l.], 2010. v. 2, p.
983‚Äì988. Citado 2 vezes nas p√°ginas 24 e 27.

PERONA, P.; MALIK, J. Scale-space and edge detection using anisotropic diffusion.
Pattern Analysis and Machine Intelligence, IEEE Transactions on, IEEE, v. 12, n. 7, p.
629‚Äì639, 1990. Citado na p√°gina 36.

PETROU, M.; GARC√çA-SEVILLA, P. Image processing - dealing with texture. [S.l.]:
Wiley, 2006. ISBN 978-0-470-02628-1. Citado na p√°gina 69.

PIZARRO, O.; EUSTICE, R.; SINGH, H. Large area 3d reconstructions from underwater
surveys. In: OCEANS ‚Äô04. MTTS/IEEE TECHNO-OCEAN ‚Äô04. [S.l.: s.n.], 2004. v. 2,
p. 678‚Äì687 Vol.2. Citado 2 vezes nas p√°ginas 66 e 67.

PIZARRO, O. et al. Towards image-based marine habitat classification. In: IEEE.
OCEANS 2008. [S.l.], 2008. p. 1‚Äì7. Citado na p√°gina 66.

PLATT, J. C. Probabilistic outputs for support vector machines and comparisons to
regularized likelihood methods. In: CITESEER. Advances in large margin classifiers.
[S.l.], 1999. Citado na p√°gina 52.

PORTER, R.; CANAGARAJAH, N. Robust rotation-invariant texture classification:
wavelet, gabor filter and gmrf based schemes. In: IET. Vision, Image and Signal
Processing, IEE Proceedings-. [S.l.], 1997. v. 144, n. 3, p. 180‚Äì188. Citado na p√°gina 69.

PURKIS, S.; VLASWINKEL, B.; GRACIAS, N. Vertical-to-lateral transitions among
cretaceous carbonate facies: A means to 3-d framework construction via markov analysis.
Journal of Sedimentary Research, SEPM, v. 82, n. 4, p. 232‚Äì243, 2012. Citado na
p√°gina 49.

RABINOVICH, A. et al. Objects in context. In: Proceedings of the International
Conference on Computer Vision (ICCV). [S.l.: s.n.], 2007. Citado na p√°gina 40.

SCHETTINI, R.; CORCHS, S. Underwater image processing: state of the art of
restoration and image enhancement methods. EURASIP Journal on Advances in Signal
Processing, Hindawi Publishing Corp., v. 2010, p. 14, 2010. Citado na p√°gina 67.

SCHMID, C.; MOHR, R.; BAUCKHAGE, C. Evaluation of interest point detectors.
International Journal of computer vision, Springer, v. 37, 2000. Citado 2 vezes nas
p√°ginas 30 e 77.

SCHMIDT, M. W. et al. Optimizing costly functions with simple constraints: A
limited-memory projected quasi-newton algorithm. In: International Conference on
Artificial Intelligence and Statistics. [S.l.: s.n.], 2009. p. None. Citado na p√°gina 90.

102

Refer√™ncias

SHIHAVUDDIN, A. et al. Image-based coral reef classification and thematic mapping.
Remote Sensing, v. 5, n. 4, p. 1809‚Äì1841, 2013. ISSN 2072-4292. Dispon√≠vel em:
<http://www.mdpi.com/2072-4292/5/4/1809>. Citado 7 vezes nas p√°ginas 25, 66, 67,
68, 69, 70 e 89.

SHOTTON, J. et al. Textonboost for image understanding: Multi-class object recognition
and segmentation by jointly modeling texture, layout, and context. International Journal
of Computer Vision, Springer, v. 81, n. 1, p. 2‚Äì23, 2009. Citado 2 vezes nas p√°ginas 44
e 45.
SIVIC, J.; ZISSERMAN, A. Video google: Efficient visual search of videos. In: Toward
Category-Level Object Recognition. [S.l.]: Springer, 2006. p. 127‚Äì144. Citado na p√°gina
45.
SOJKA, E. A new approach to detecting the corners in digital images. In: IEEE. Image
Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on. [S.l.], 2003.
v. 3, p. III‚Äì445. Citado 2 vezes nas p√°ginas 11 e 31.

STOKES, M. D.; DEANE, G. B. Automated processing of coral reef benthic images.
Limnol. Oceanogr.: Methods, v. 7, n. 157, p. 157‚Äì168, 2009. Citado 2 vezes nas p√°ginas
67 e 70.

SUTTON, C.; MCCALLUM, A. An introduction to conditional random fields for
relational learning. Introduction to statistical relational learning, MIT press, p. 93‚Äì128,
2006. Citado 2 vezes nas p√°ginas 42 e 43.
TORRALBA, A. Contextual priming for object detection. International journal of
computer vision, Springer, v. 53, n. 2, p. 169‚Äì191, 2003. Citado na p√°gina 40.

TORRALBA, A.; MURPHY, K. P.; FREEMAN, W. T. Contextual models for object
detection using boosted random fields. In: Advances in neural information processing
systems. [S.l.: s.n.], 2004. p. 1401‚Äì1408. Citado 2 vezes nas p√°ginas 40 e 41.
TREIBITZ, T.; SCHECHNER, Y. Y. Instant 3descatter. In: Proceedings of the 2006
IEEE Computer Society Conference on Computer Vision and Pattern Recognition -
Volume 2. [S.l.: s.n.], 2006. (CVPR ‚Äô06), p. 1861‚Äì1868. Citado 2 vezes nas p√°ginas 64
e 73.

TUYTELAARS, T.; MIKOLAJCZYK, K. Local invariant feature detectors: a survey.
Foundations and Trends R‚óã in Computer Graphics and Vision, Now Publishers Inc., v. 3,
n. 3, p. 177‚Äì280, 2008. Citado 4 vezes nas p√°ginas 27, 28, 30 e 77.

WANG, Z. et al. Image quality assessment: From error visibility to structural similarity.
Image Processing, IEEE Transactions on, IEEE, v. 13, n. 4, p. 600‚Äì612, 2004. Citado 2
vezes nas p√°ginas 76 e 78.

WEICKERT, J.; ROMENY, B. T. H.; VIERGEVER, M. A. Efficient and reliable
schemes for nonlinear diffusion filtering. Image Processing, IEEE Transactions on, IEEE,
v. 7, n. 3, p. 398‚Äì410, 1998. Citado na p√°gina 36.
WEIJER, J. V. D.; SCHMID, C. Coloring local feature extraction. In: Computer
Vision‚ÄìECCV 2006. [S.l.]: Springer, 2006. p. 334‚Äì348. Citado na p√°gina 69.

Refer√™ncias

103

WEISS, Y. Correctness of local probability propagation in graphical models with loops.
Neural computation, MIT Press, v. 12, n. 1, p. 1‚Äì41, 2000. Citado 2 vezes nas p√°ginas
45 e 84.
ZUIDERVELD, K. Contrast limited adaptive histogram equalization. In: ACADEMIC
PRESS PROFESSIONAL, INC. Graphics gems IV. [S.l.], 1994. p. 474‚Äì485. Citado 2
vezes nas p√°ginas 67 e 84.
ZVULONI, A. et al. Spatio-temporal transmission patterns of black-band disease in a
coral community. PLoS One, Public Library of Science, v. 4, n. 4, p. e4993, 2009. Citado
2 vezes nas p√°ginas 73 e 83.

